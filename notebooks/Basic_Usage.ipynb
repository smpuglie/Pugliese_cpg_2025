{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "# Set environment variables for JAX and GPU configuration\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # Use GPU 0\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\n",
    "# Disable XLA optimizations that might cause timing issues\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_triton_gemm_any=false'\n",
    "\n",
    "import jax\n",
    "# Enable persistent compilation cache.\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"/tmp/jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", -1)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 0)\n",
    "jax.config.update(\n",
    "    \"jax_persistent_cache_enable_xla_caches\", \"xla_gpu_per_fusion_autotune_cache_dir\"\n",
    ")\n",
    "import sparse\n",
    "\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "from src.utils import io_dict_to_hdf5 as ioh5\n",
    "from src.utils.plot_utils import *\n",
    "from src.simulation.vnc_sim import *\n",
    "from src.utils.path_utils import *\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm.auto import tqdm\n",
    "# Ensure custom resolvers are registered\n",
    "# This is important when loading saved configs that contain custom interpolations\n",
    "from src.utils.path_utils import register_custom_resolvers\n",
    "register_custom_resolvers()\n",
    "\n",
    "#### Utility Functions ####\n",
    "def print_pytree(pytree):\n",
    "   \"\"\"\n",
    "   path_filter: function that takes key_path tuple and returns True/False\n",
    "   \"\"\"\n",
    "   def process_leaf(key_path, leaf):\n",
    "      print(f\"Key Path: {key_path[0]}, Leaf: {leaf.shape} of type {leaf.dtype if hasattr(leaf, 'dtype') else type(leaf)}\")\n",
    "\n",
    "   return jax.tree.map_with_path(process_leaf, pytree)\n",
    "\n",
    "def print_dict_shapes(data, prefix=\"\", max_depth=10, current_depth=0):\n",
    "   \"\"\"\n",
    "   Recursively print shapes for arrays and values for other types in a dictionary.\n",
    "   \n",
    "   Args:\n",
    "      data: Dictionary or other data structure to inspect\n",
    "      prefix: String prefix for indentation\n",
    "      max_depth: Maximum recursion depth to prevent infinite loops\n",
    "      current_depth: Current recursion depth\n",
    "   \"\"\"\n",
    "   import jax.numpy as jnp\n",
    "   import numpy as np\n",
    "   \n",
    "   if current_depth > max_depth:\n",
    "      print(f\"{prefix}... (max depth reached)\")\n",
    "      return\n",
    "   \n",
    "   if isinstance(data, dict):\n",
    "      for key, value in data.items():\n",
    "         print(f\"{prefix}{key}:\")\n",
    "         print_dict_shapes(value, prefix + \"  \", max_depth, current_depth + 1)\n",
    "   \n",
    "   elif isinstance(data, (list, tuple)):\n",
    "      print(f\"{prefix}Type: {type(data).__name__}, Length: {len(data)}\")\n",
    "      if len(data) > 0:\n",
    "         print(f\"{prefix}First element:\")\n",
    "         print_dict_shapes(data[0], prefix + \"  \", max_depth, current_depth + 1)\n",
    "         if len(data) > 1:\n",
    "               print(f\"{prefix}... ({len(data)-1} more elements)\")\n",
    "   \n",
    "   elif hasattr(data, 'shape'):  # Arrays (JAX, NumPy, etc.)\n",
    "      print(f\"{prefix}Type: {type(data).__name__}, Shape: {data.shape}, Dtype: {data.dtype}\")\n",
    "   \n",
    "   elif isinstance(data, (int, float, bool, str)):\n",
    "      print(f\"{prefix}Type: {type(data).__name__}, Value: {data}\")\n",
    "   \n",
    "   elif hasattr(data, '__dict__'):  # Objects with attributes\n",
    "      print(f\"{prefix}Type: {type(data).__name__}\")\n",
    "      for attr_name in dir(data):\n",
    "         if not attr_name.startswith('_'):  # Skip private attributes\n",
    "               try:\n",
    "                  attr_value = getattr(data, attr_name)\n",
    "                  if not callable(attr_value):  # Skip methods\n",
    "                     print(f\"{prefix}  {attr_name}:\")\n",
    "                     print_dict_shapes(attr_value, prefix + \"    \", max_depth, current_depth + 1)\n",
    "               except:\n",
    "                  print(f\"{prefix}  {attr_name}: <unable to access>\")\n",
    "   \n",
    "   else:\n",
    "      print(f\"{prefix}Type: {type(data).__name__}, Value: {str(data)[:100]}{'...' if len(str(data)) > 100 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If just starting out run: \n",
    "\n",
    "```\n",
    "python test_configs.py experiment.n_replicates=8 paths=YOUR_PATH_YAML \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify experiment and version\n",
    "experiment = 'DNg100_Stim'\n",
    "version = 'debug'\n",
    "\n",
    "#### List available configs ####\n",
    "# base_dir = Path('PATH/TO/YOUR/LOCAL/EXPERIMENTS')  # Change this to your local path where experiments are stored defined from YOUR_PATH_YAML\n",
    "base_dir = Path(f'/data/users/eabe/Pugliese_2025/{experiment}/{version}')\n",
    "run_cfg_list = natsorted(list(Path(base_dir).rglob('run_config.yaml')))\n",
    "for n, run_cfg in enumerate(run_cfg_list):\n",
    "    print(n, run_cfg)\n",
    "\n",
    "###### Load and update config with specified paths template ###### \n",
    "cfg_num = -1\n",
    "\n",
    "# NEW APPROACH: Load config and replace paths using glados.yaml template\n",
    "cfg = load_config_with_path_template(\n",
    "    config_path=run_cfg_list[cfg_num],\n",
    "    paths_template=\"glados\",     # Use YOUR_PATH_YAML.yaml for local paths\n",
    "    experiment=experiment,               # This will override if needed\n",
    "    version=version,                     # Use debug version locally instead of hyak\n",
    ")\n",
    "\n",
    "print(f'âœ… Loaded experiment: {cfg.experiment.name}')\n",
    "\n",
    "# Convert string paths to Path objects and create directories\n",
    "try:\n",
    "    cfg.paths = convert_dict_to_path(cfg.paths)\n",
    "    print(\"âœ… Successfully converted all paths to Path objects and created directories\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Warning: Could not convert all paths: {e}\")\n",
    "    print(\"Proceeding with string paths and manual directory creation...\")\n",
    "    # If conversion fails, create the directories manually\n",
    "    for key, path_str in cfg.paths.items():\n",
    "        if key != 'user' and isinstance(path_str, str):\n",
    "            path_obj = Path(path_str)\n",
    "            path_obj.mkdir(parents=True, exist_ok=True)\n",
    "            cfg.paths[key] = path_obj\n",
    "\n",
    "checkpoint_dir = None\n",
    "if cfg.sim.enable_checkpointing and hasattr(cfg, 'paths'):\n",
    "    checkpoint_dir = Path(cfg.paths.ckpt_dir) / \"checkpoints\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading network configuration...\")\n",
    "W_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "\n",
    "# Prepare parameters\n",
    "load_new_params = True # Set to False to load existing params from neuron_params.h5\n",
    "if load_new_params:\n",
    "    neuron_params_path = None\n",
    "    if 'neuron_params' in vars():\n",
    "        del neuron_params  # Clear existing params to avoid confusion\n",
    "        gc.collect()\n",
    "        jax.clear_caches()\n",
    "        print('Cleared existing neuron_params and JAX caches')\n",
    "else:\n",
    "    neuron_params_path = cfg.paths.ckpt_dir / 'neuron_params.h5'\n",
    "    \n",
    "\n",
    "neuron_params = prepare_neuron_params(cfg, W_table, neuron_params_path)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "mn_mask = jnp.isin(jnp.arange(sim_params.n_neurons), neuron_params.mn_idxs)\n",
    "sim_config = parse_simulation_config(cfg)\n",
    "\n",
    "print_pytree(neuron_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the test config code above you will notice there are n_replicates=8 in the leading dimensions for the biophysical parameters. Input currents have an additional dimension for simulating different stimulation conditions in parallel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Simulation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "stim_idx = 0 # Select which stimulation configuration to simulate\n",
    "param_idx = 0 # Select which parameter replicate to simulate\n",
    "neuron_params_single = jax.tree.map(lambda x: x[param_idx], neuron_params)\n",
    "print_pytree(neuron_params_single)\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "W_reweighted = reweight_connectivity(\n",
    "    neuron_params.W, \n",
    "    sim_params.exc_multiplier, \n",
    "    sim_params.inh_multiplier\n",
    ")\n",
    "\n",
    "# Run the final simulation with pruned network\n",
    "final_results = run_single_simulation(\n",
    "    W_reweighted,\n",
    "    neuron_params_single.tau,\n",
    "    neuron_params_single.a, \n",
    "    neuron_params_single.threshold,\n",
    "    neuron_params_single.fr_cap,\n",
    "    neuron_params_single.input_currents[param_idx]*2,\n",
    "    sim_params.noise_stdv,\n",
    "    sim_params.t_axis,\n",
    "    sim_params.T,\n",
    "    sim_params.dt,\n",
    "    sim_params.pulse_start,\n",
    "    sim_params.pulse_end,\n",
    "    sim_params.r_tol,\n",
    "    sim_params.a_tol,\n",
    "    key\n",
    ")\n",
    "final_results.block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"\\nðŸŽ¯ Final simulation results:\")\n",
    "print('Final results shape:', final_results.shape)\n",
    "print('Simulation time (s):', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = final_results\n",
    "w_table = pd.read_csv(cfg.experiment.dfPath,index_col=0)\n",
    "mn_mask = jnp.isin(jnp.arange(sim_params.n_neurons), neuron_params.mn_idxs)\n",
    "nonmns_idxs = jnp.where((jnp.sum(R,axis=-1)>0.01) & ~mn_mask)[0]\n",
    "mn_idxs = jnp.where((jnp.sum(R,axis=-1)>0.01) & mn_mask)[0]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(18, 6))\n",
    "ax = axs[0]\n",
    "for i in nonmns_idxs:\n",
    "    ax.plot(R[i])\n",
    "ax.set_title(\"Non-Motor Neurons\")\n",
    "ax.set_xlabel(\"Time (ms)\")\n",
    "\n",
    "ax = axs[1]\n",
    "for i in mn_idxs:\n",
    "    ax.plot(R[i])\n",
    "ax.set_title(\"Motor Neurons\")\n",
    "ax.set_xlabel(\"Time (ms)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vmap for parallel simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you ran the `test_config.py`, we will now run a 'batch' of simulations in parallel with vmap using the `process_batch_baseline` funciton. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.simulation.vnc_sim import process_batch_baseline\n",
    "start_time = time.time()\n",
    "batch_inds = jnp.arange(sim_params.n_param_sets * sim_params.n_stim_configs)\n",
    "jit_batch_sim = jax.jit(process_batch_baseline)\n",
    "# Run the final simulation with pruned network\n",
    "final_results = jit_batch_sim(\n",
    "    neuron_params,\n",
    "    sim_params,\n",
    "    batch_inds\n",
    ")\n",
    "final_results.block_until_ready()\n",
    "end_time = time.time()\n",
    "print(\"\\nðŸŽ¯ Final simulation results:\")\n",
    "print('Final results shape:', final_results.shape)\n",
    "print('Simulation time (s):', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_idx = 2\n",
    "R = final_results[sim_idx]\n",
    "w_table = pd.read_csv(cfg.experiment.dfPath,index_col=0)\n",
    "mn_mask = jnp.isin(jnp.arange(sim_params.n_neurons), neuron_params.mn_idxs)\n",
    "nonmns_idxs = jnp.where((jnp.sum(R,axis=-1)>0.01) & ~mn_mask)[0]\n",
    "mn_idxs = jnp.where((jnp.sum(R,axis=-1)>0.01) & mn_mask)[0]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(18, 6))\n",
    "ax = axs[0]\n",
    "for i in nonmns_idxs:\n",
    "    ax.plot(R[i])\n",
    "ax.set_title(\"Non-Motor Neurons\")\n",
    "ax.set_xlabel(\"Time (ms)\")\n",
    "\n",
    "ax = axs[1]\n",
    "for i in mn_idxs:\n",
    "    ax.plot(R[i])\n",
    "ax.set_title(\"Motor Neurons\")\n",
    "ax.set_xlabel(\"Time (ms)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoints are saved when running large scale simulations, in case they are ever interuppted you can resume the simulations from where you left off. Each checkpoint contains all the simulations up until that point. For example, checkpoint_500 will contain simulations 0-500, and will resume start at 501. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_checkpoint, base_name = find_latest_checkpoint(checkpoint_dir)\n",
    "print(latest_checkpoint)\n",
    "checkpoint_state, adjusted_neuron_params, metadata = load_checkpoint(\n",
    "    latest_checkpoint, base_name, neuron_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_idx = 785\n",
    "R = checkpoint_state.results_dict[sim_idx]\n",
    "w_table = pd.read_csv(cfg.experiment.dfPath,index_col=0)\n",
    "mn_mask = jnp.isin(jnp.arange(sim_params.n_neurons), neuron_params.mn_idxs)\n",
    "nonmns_idxs = jnp.where((jnp.sum(R,axis=-1)>0.01) & ~mn_mask)[0]\n",
    "mn_idxs = jnp.where((jnp.sum(R,axis=-1)>0.01) & mn_mask)[0]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(18, 6))\n",
    "for i in nonmns_idxs:\n",
    "    axs[0].plot(R[i])\n",
    "axs[0].set_title(\"Non-Motor Neurons\")\n",
    "for i in mn_idxs:\n",
    "    axs[1].plot(R[i])\n",
    "axs[1].set_title(\"Motor Neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = jnp.asarray([checkpoint_state.results_dict[sim_idx] for sim_idx in checkpoint_state.results_dict.keys()])[None,...]\n",
    "min_circuit = jnp.asarray([checkpoint_state.mini_circuits_dict[sim_idx] for sim_idx in checkpoint_state.mini_circuits_dict.keys()], dtype=jnp.bool_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pruning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.sim_utils import compute_oscillation_score, neuron_oscillation_score\n",
    "\n",
    "results = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_Rs.npz\").todense().astype(np.float32)\n",
    "min_circuit = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_mini_circuits.npz\").todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[0,0]\n",
    "# R = final_results\n",
    "w_table = pd.read_csv(cfg.experiment.dfPath,index_col=0)\n",
    "mn_mask = jnp.isin(jnp.arange(sim_params.n_neurons), neuron_params.mn_idxs)\n",
    "nonmns_idxs = jnp.where((jnp.sum(R,axis=-1)>0.01) & ~mn_mask)[0]\n",
    "mn_idxs = jnp.where((jnp.sum(R,axis=-1)>0.01) & mn_mask)[0]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(18, 6))\n",
    "for i in nonmns_idxs:\n",
    "    axs[0].plot(R[i])\n",
    "axs[0].set_title(\"Non-Motor Neurons\")\n",
    "for i in mn_idxs:\n",
    "    axs[1].plot(R[i])\n",
    "axs[1].set_title(\"Motor Neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.sim_utils import compute_oscillation_score\n",
    "clip_start = 250# int(sim_params.pulse_start / sim_params.dt) + 200\n",
    "def compute_osc_score_all(R, mn_mask, clip_start=250):\n",
    "    # Get active MN activity using JAX-compatible approach\n",
    "    max_frs = jnp.max(R[..., clip_start:], axis=-1)\n",
    "    active_mask = ((max_frs > 0.01) & mn_mask)\n",
    "\n",
    "    # Compute oscillation score\n",
    "    oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "    return oscillation_score\n",
    "\n",
    "\n",
    "# osc_score_all = osc_vmap(results[0], mn_mask, clip_start)\n",
    "osc_score_all = []\n",
    "for replicate in tqdm(range(results.shape[1])):\n",
    "    osc_score = compute_osc_score_all(results[0,replicate], mn_mask, clip_start=clip_start)\n",
    "    osc_score_all.append(osc_score)\n",
    "osc_score_all = jnp.array(osc_score_all)\n",
    "n_neurons_mini = jnp.array([len(jnp.where(min_circuit[n] & ~mn_mask)[0]) for n in range(min_circuit.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[jnp.where(min_circuit[n] & ~mn_mask)[0] for n in range(min_circuit.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(osc_score_all, n_neurons_mini )\n",
    "plt.axvline(x=0.25,c='k',ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnc-closedloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
