{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from src.vnc import run_vnc_simulation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "import jax\n",
    "# jax.config.update(\"jax_enable_x64\", True)\n",
    "# Configure JAX for better performance\n",
    "jax.config.update(\"jax_enable_x64\", False)  # Use float32 for better GPU performance\n",
    "# jax.config.update(\"jax_platforms\", \"cuda\")  # Prefer GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # Use GPU 0\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\n",
    "\n",
    "# Disable XLA optimizations that might cause timing issues\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_triton_gemm_any=false'\n",
    "\n",
    "import sparse\n",
    "from natsort import natsorted\n",
    "from src.utils import io_dict_to_hdf5 as ioh5\n",
    "from src.utils.plot_utils import *\n",
    "from src.simulation.vnc_sim import *\n",
    "from src.utils.path_utils import *\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm.auto import tqdm\n",
    "# Ensure custom resolvers are registered\n",
    "# This is important when loading saved configs that contain custom interpolations\n",
    "from src.utils.path_utils import register_custom_resolvers\n",
    "register_custom_resolvers()\n",
    "\n",
    "\n",
    "def print_pytree(pytree):\n",
    "   \"\"\"\n",
    "   path_filter: function that takes key_path tuple and returns True/False\n",
    "   \"\"\"\n",
    "   def process_leaf(key_path, leaf):\n",
    "      print(f\"Key Path: {key_path[0]}, Leaf: {leaf.shape}\")\n",
    "\n",
    "   return jax.tree.map_with_path(process_leaf, pytree)\n",
    "\n",
    "def print_dict_shapes(data, prefix=\"\", max_depth=10, current_depth=0):\n",
    "   \"\"\"\n",
    "   Recursively print shapes for arrays and values for other types in a dictionary.\n",
    "   \n",
    "   Args:\n",
    "      data: Dictionary or other data structure to inspect\n",
    "      prefix: String prefix for indentation\n",
    "      max_depth: Maximum recursion depth to prevent infinite loops\n",
    "      current_depth: Current recursion depth\n",
    "   \"\"\"\n",
    "   import jax.numpy as jnp\n",
    "   import numpy as np\n",
    "   \n",
    "   if current_depth > max_depth:\n",
    "      print(f\"{prefix}... (max depth reached)\")\n",
    "      return\n",
    "   \n",
    "   if isinstance(data, dict):\n",
    "      for key, value in data.items():\n",
    "         print(f\"{prefix}{key}:\")\n",
    "         print_dict_shapes(value, prefix + \"  \", max_depth, current_depth + 1)\n",
    "   \n",
    "   elif isinstance(data, (list, tuple)):\n",
    "      print(f\"{prefix}Type: {type(data).__name__}, Length: {len(data)}\")\n",
    "      if len(data) > 0:\n",
    "         print(f\"{prefix}First element:\")\n",
    "         print_dict_shapes(data[0], prefix + \"  \", max_depth, current_depth + 1)\n",
    "         if len(data) > 1:\n",
    "               print(f\"{prefix}... ({len(data)-1} more elements)\")\n",
    "   \n",
    "   elif hasattr(data, 'shape'):  # Arrays (JAX, NumPy, etc.)\n",
    "      print(f\"{prefix}Type: {type(data).__name__}, Shape: {data.shape}, Dtype: {data.dtype}\")\n",
    "   \n",
    "   elif isinstance(data, (int, float, bool, str)):\n",
    "      print(f\"{prefix}Type: {type(data).__name__}, Value: {data}\")\n",
    "   \n",
    "   elif hasattr(data, '__dict__'):  # Objects with attributes\n",
    "      print(f\"{prefix}Type: {type(data).__name__}\")\n",
    "      for attr_name in dir(data):\n",
    "         if not attr_name.startswith('_'):  # Skip private attributes\n",
    "               try:\n",
    "                  attr_value = getattr(data, attr_name)\n",
    "                  if not callable(attr_value):  # Skip methods\n",
    "                     print(f\"{prefix}  {attr_name}:\")\n",
    "                     print_dict_shapes(attr_value, prefix + \"    \", max_depth, current_depth + 1)\n",
    "               except:\n",
    "                  print(f\"{prefix}  {attr_name}: <unable to access>\")\n",
    "   \n",
    "   else:\n",
    "      print(f\"{prefix}Type: {type(data).__name__}, Value: {str(data)[:100]}{'...' if len(str(data)) > 100 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /data/users/eabe/Pugliese_2025/DNb08_Stim_Prune/hyak/run_id=28357547/logs/run_config.yaml\n",
      "1 /data/users/eabe/Pugliese_2025/DNb08_Stim_Prune/hyak/run_id=28851757/logs/run_config.yaml\n",
      "2 /data/users/eabe/Pugliese_2025/DNb08_Stim_Prune/hyak/run_id=28920181/experiment.seed=1/logs/run_config.yaml\n",
      "3 /data/users/eabe/Pugliese_2025/DNb08_Stim_Prune/hyak/run_id=28920181/experiment.seed=2/logs/run_config.yaml\n",
      "üìÅ Loading config from: /data/users/eabe/Pugliese_2025/DNb08_Stim_Prune/hyak/run_id=28920181/experiment.seed=1/logs/run_config.yaml\n",
      "‚úÖ Loaded experiment: DNb08_Stim_Prune\n",
      "‚úÖ Successfully converted all paths to Path objects and created directories\n"
     ]
    }
   ],
   "source": [
    "experiment = 'DNb08_Stim_Prune'\n",
    "version = 'hyak'\n",
    "# base_dir = Path(f'/gscratch/portia/eabe/Pugliese_2025/{experiment}/{version}')\n",
    "base_dir = Path(f'/data/users/eabe/Pugliese_2025/{experiment}/{version}')\n",
    "run_cfg_list = natsorted(list(Path(base_dir).rglob('run_config.yaml')))\n",
    "for n, run_cfg in enumerate(run_cfg_list):\n",
    "    print(n, run_cfg)\n",
    "\n",
    "# ###### Load and update config with specified paths template ###### \n",
    "\n",
    "cfg_num = -2\n",
    "# print(f'\\nüìÅ Loading config {cfg_num}: {run_cfg_list[cfg_num]}')\n",
    "\n",
    "# NEW APPROACH: Load config and replace paths using glados.yaml template\n",
    "cfg = load_config_with_path_template(\n",
    "    config_path=run_cfg_list[cfg_num],\n",
    "    paths_template=\"glados\",    # Use glados.yaml for local paths\n",
    "    experiment=experiment,      # This will override if needed\n",
    "    version=version,           # Use debug version locally instead of hyak\n",
    ")\n",
    "\n",
    "print(f'‚úÖ Loaded experiment: {cfg.experiment.name}')\n",
    "\n",
    "# Convert string paths to Path objects and create directories\n",
    "try:\n",
    "    cfg.paths = convert_dict_to_path(cfg.paths)\n",
    "    print(\"‚úÖ Successfully converted all paths to Path objects and created directories\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Warning: Could not convert all paths: {e}\")\n",
    "    print(\"Proceeding with string paths and manual directory creation...\")\n",
    "    # If conversion fails, create the directories manually\n",
    "    for key, path_str in cfg.paths.items():\n",
    "        if key != 'user' and isinstance(path_str, str):\n",
    "            path_obj = Path(path_str)\n",
    "            path_obj.mkdir(parents=True, exist_ok=True)\n",
    "            cfg.paths[key] = path_obj\n",
    "\n",
    "checkpoint_dir = None\n",
    "if cfg.sim.enable_checkpointing and hasattr(cfg, 'paths'):\n",
    "    checkpoint_dir = Path(cfg.paths.ckpt_dir) / \"checkpoints\"\n",
    "# print(f\"\\nüéØ Final paths configuration:\")\n",
    "# for key, value in cfg.paths.items():\n",
    "#     print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network configuration...\n",
      "Loaded neuron parameters from /data/users/eabe/Pugliese_2025/DNb08_Stim_Prune/hyak/run_id=28920181/experiment.seed=1/ckpt/neuron_params.h5\n",
      "Key Path: .W, Leaf: (4604, 4604)\n",
      "Key Path: .tau, Leaf: (512, 4604)\n",
      "Key Path: .a, Leaf: (512, 4604)\n",
      "Key Path: .threshold, Leaf: (512, 4604)\n",
      "Key Path: .fr_cap, Leaf: (512, 4604)\n",
      "Key Path: .input_currents, Leaf: (1, 512, 4604)\n",
      "Key Path: .seeds, Leaf: (512, 2)\n",
      "Key Path: .exc_dn_idxs, Leaf: (933,)\n",
      "Key Path: .inh_dn_idxs, Leaf: (385,)\n",
      "Key Path: .exc_in_idxs, Leaf: (1484,)\n",
      "Key Path: .inh_in_idxs, Leaf: (1658,)\n",
      "Key Path: .mn_idxs, Leaf: (144,)\n",
      "Key Path: .W_mask, Leaf: (512, 4604, 4604)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuronParams(W=None, tau=None, a=None, threshold=None, fr_cap=None, input_currents=None, seeds=None, exc_dn_idxs=None, inh_dn_idxs=None, exc_in_idxs=None, inh_in_idxs=None, mn_idxs=None, W_mask=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading network configuration...\")\n",
    "W_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "# Prepare parameters\n",
    "neuron_params = prepare_neuron_params(cfg, W_table, cfg.paths.ckpt_dir / 'neuron_params.h5')\n",
    "# neuron_params = prepare_neuron_params(cfg, W_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "mn_mask = jnp.isin(jnp.arange(sim_params.n_neurons), neuron_params.mn_idxs)\n",
    "sim_config = parse_simulation_config(cfg)\n",
    "\n",
    "print_pytree(neuron_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([], shape=(0,), dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.where(neuron_params.W_mask[0,0] & ~mn_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([], shape=(0,), dtype=int32),)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.where(neuron_params.W_mask[0,:,0] & ~mn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparse.load_npz(checkpoint_dir / f\"results_checkpoint_batch_{checkpoint_dict['batch_index']}/batch_{checkpoint_dict['batch_index']}.npz\").todense().astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.sim_utils import compute_oscillation_score, neuron_oscillation_score\n",
    "\n",
    "results = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_Rs.npz\").todense().astype(np.float32)\n",
    "# results = sparse.load_npz('/data/users/eabe/Pugliese_2025/prune_test/hyak/run_id=27996612/ckpt/prune_test_mini_circuits.npz').todense().astype(np.float32)\n",
    "min_circuit = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_mini_circuits.npz\").todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_params_single = jax.tree.map(lambda x: x[9], neuron_params)\n",
    "print_pytree(neuron_params_single)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_dn_idxs, inh_dn_idxs, exc_in_idxs, inh_in_idxs, mn_idxs = extract_shuffle_indices(W_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del neuron_params\n",
    "gc.collect()\n",
    "jax.clear_caches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([  86,   86,   86,   86,   86,   86,  693,  693,  693,  693,  693,\n",
       "        693, 1211, 1211, 1211, 1211, 1211, 1211, 1579, 1579, 1579, 1579,\n",
       "       1579, 1579, 2534, 2534, 2534, 2534, 2534, 2534, 4458, 4458, 4458,\n",
       "       4458, 4458, 4458], dtype=int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_mask = min_circuit[param_idx, :, None] * min_circuit[param_idx, None, :]\n",
    "jnp.where(W_mask & ~mn_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([0.02389682, 0.01815102, 0.02244319, ..., 0.0181357 , 0.02148832,\n",
       "        0.02064551], dtype=float32),\n",
       " Array([0.02151372, 0.01700386, 0.04764691, ..., 7.706089  , 4.3621635 ,\n",
       "        4.0351987 ], dtype=float32),\n",
       " Array([365.9173   , 446.7128   , 148.4126   , ...,   1.2389305,\n",
       "          1.6549523,   2.2148035], dtype=float32),\n",
       " Array([214.88704, 215.78058, 198.13695, ..., 202.02287, 199.36125,\n",
       "        214.48334], dtype=float32),\n",
       " Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_idx = 9\n",
    "stim_idx = 0\n",
    "W_mask_new = jnp.ones((min_circuit.shape[-1],min_circuit.shape[-1]), dtype=jnp.bool_)\n",
    "W_mask_new = (W_mask_new * min_circuit[param_idx, :, None] * min_circuit[param_idx, None, :]).astype(jnp.bool_)\n",
    "jnp.where(W_mask_new & ~mn_mask)[0]\n",
    "neuron_params_single.tau,neuron_params_single.a,neuron_params_single.threshold,neuron_params_single.fr_cap,neuron_params_single.input_currents[param_idx]*2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_idx = 9\n",
    "stim_idx = 0\n",
    "W_mask_new = jnp.ones((min_circuit.shape[-1],min_circuit.shape[-1]), dtype=jnp.bool_)\n",
    "W_mask_new = (W_mask_new * min_circuit[param_idx, :, None] * min_circuit[param_idx, None, :]).astype(jnp.bool_)\n",
    "key = jax.random.PRNGKey(9 + 12345)\n",
    "W_reweighted = reweight_connectivity(\n",
    "    W_mask_new, \n",
    "    sim_params.exc_multiplier, \n",
    "    sim_params.inh_multiplier\n",
    ")\n",
    "\n",
    "# Run the final simulation with pruned network\n",
    "final_results = run_single_simulation(\n",
    "    W_reweighted,\n",
    "    neuron_params_single.tau,\n",
    "    neuron_params_single.a, \n",
    "    neuron_params_single.threshold,\n",
    "    neuron_params_single.fr_cap,\n",
    "    neuron_params_single.input_currents[param_idx]*2,\n",
    "    sim_params.noise_stdv,\n",
    "    sim_params.t_axis,\n",
    "    sim_params.T,\n",
    "    sim_params.dt,\n",
    "    sim_params.pulse_start,\n",
    "    sim_params.pulse_end,\n",
    "    sim_params.r_tol,\n",
    "    sim_params.a_tol,\n",
    "    key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Motor Neurons')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R = final_results#[0,9]\n",
    "w_table = pd.read_csv(cfg.experiment.dfPath,index_col=0)\n",
    "# 10093 = bdn2, 10707 = exc 1, 11751 = exc 2, 13905 = inh 1\n",
    "# nonmns_idxs = w_table.loc[(w_table[\"bodyId\"]==10093) | (w_table[\"bodyId\"]==10707) | (w_table[\"bodyId\"]==11751) | (w_table[\"bodyId\"]==13905)].index\n",
    "# mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "nonmns_idxs = jnp.where(~mn_mask)[0]\n",
    "mn_idxs = jnp.where(mn_mask)[0]\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(18, 6))\n",
    "for i in nonmns_idxs:\n",
    "    axs[0].plot(R[i])\n",
    "axs[0].set_title(\"Non-Motor Neurons\")\n",
    "for i in mn_idxs:\n",
    "    axs[1].plot(R[i])\n",
    "axs[1].set_title(\"Motor Neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.10858517, dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([  31,  277,  617, 1167], dtype=int32),\n",
       " Array([  31,  277,  617, 1167], dtype=int32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_circuit = jnp.stack([((jnp.sum(results[:,n],axis=-1)>0) & ~mn_mask) for n in range(results.shape[1])],axis=1)\n",
    "min_circuit.shape\n",
    "[jnp.where(min_circuit[0,n] & ~mn_mask)[0] for n in range(min_circuit.shape[1])]\n",
    "# sparse.save_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_mini_circuits.npz\", sparse.COO.from_numpy(min_circuit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4604, 4604)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(min_circuit[9, :, None] * min_circuit[9, None, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([], shape=(0,), dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.where(neuron_params.W_mask[9,0,:] & ~mn_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_mask_init = jnp.ones((cfg.experiment.n_replicates,min_circuit.shape[-1],min_circuit.shape[-1]), dtype=jnp.bool_)\n",
    "idx = 9\n",
    "W_mask_new = (W_mask_init * min_circuit[idx, :, None] * min_circuit[idx, None, :]).astype(jnp.bool_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([  86,   86,   86,   86,   86,   86,  693,  693,  693,  693,  693,\n",
       "        693, 1211, 1211, 1211, 1211, 1211, 1211, 1579, 1579, 1579, 1579,\n",
       "       1579, 1579, 2534, 2534, 2534, 2534, 2534, 2534, 4458, 4458, 4458,\n",
       "       4458, 4458, 4458], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.where(W_mask_new[0,:] & ~mn_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147f7628f3dc4625aeec5c1cac6d25c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.sim_utils import compute_oscillation_score\n",
    "clip_start = 250# int(sim_params.pulse_start / sim_params.dt) + 200\n",
    "def compute_osc_score_all(R, mn_mask, clip_start=250):\n",
    "    # Get active MN activity using JAX-compatible approach\n",
    "    max_frs = jnp.max(R[..., clip_start:], axis=-1)\n",
    "    active_mask = ((max_frs > 0.01) & mn_mask)\n",
    "\n",
    "    # Compute oscillation score\n",
    "    oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "    return oscillation_score\n",
    "\n",
    "\n",
    "# osc_score_all = osc_vmap(results[0], mn_mask, clip_start)\n",
    "osc_score_all = []\n",
    "for replicate in tqdm(range(results.shape[1])):\n",
    "    osc_score = compute_osc_score_all(results[0,replicate], mn_mask, clip_start=clip_start)\n",
    "    osc_score_all.append(osc_score)\n",
    "osc_score_all = jnp.array(osc_score_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons_mini = jnp.array([len(jnp.where(min_circuit[n] & ~mn_mask)[0]) for n in range(min_circuit.shape[0])])\n",
    "# jnp.where(min_circuit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4604)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_circuit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([  86,  277,  617, 1211, 2534, 4458], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.where(min_circuit[0] & ~mn_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([  86,  277,  617, 1211, 2534, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  630,  693,  696, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1078, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2275], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  693, 1211, 1579, 2534, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1078, 1208, 1211, 1921, 2409, 4458],      dtype=int32),\n",
       " Array([ 495, 1078, 1211, 2275, 2591, 4456, 4458], dtype=int32),\n",
       " Array([  86,  280,  617,  693, 1211, 2409, 4458], dtype=int32),\n",
       " Array([ 277,  617, 1167, 1211, 2534, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  703,  773, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  149,  150,  244,  277,  302,  332,  495,  614,\n",
       "         617,  630,  693, 1078, 1182, 1211, 1521, 1579, 1750, 1921, 2043,\n",
       "        2275, 2309, 2340, 2409, 2520, 2534, 2535, 2585, 2591, 2656, 2760,\n",
       "        2888, 2997, 3001, 3005, 3264, 3283, 4256, 4331, 4370, 4456, 4458],      dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2275, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 614,  693, 1078, 1211, 2409, 2534, 4458], dtype=int32),\n",
       " Array([1211, 2340, 2591, 2936, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2275, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 2340], dtype=int32),\n",
       " Array([ 134,  495,  693, 1211, 1579, 2340, 2534, 2591, 4456], dtype=int32),\n",
       " Array([1211, 2275, 2534, 3264, 4456, 4458], dtype=int32),\n",
       " Array([  86,  693, 1211, 2275, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  149,  150,  244,  277,  280,  302,  325,  332,\n",
       "         373,  495,  519,  535,  614,  617,  630,  693,  696,  703,  773,\n",
       "        1078, 1182, 1208, 1211, 1277, 1283, 1508, 1521, 1579, 1750, 1785,\n",
       "        1921, 1949, 1952, 2011, 2043, 2275, 2280, 2309, 2340, 2376, 2409,\n",
       "        2418, 2499, 2520, 2534, 2535, 2585, 2591, 2593, 2596, 2656, 2760,\n",
       "        2777, 2888, 3001, 3005, 3178, 3223, 3264, 3283, 3296, 3317, 3380,\n",
       "        3421, 4256, 4331, 4370, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1211, 1458, 2409, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  373,  617,  693, 1167, 1211, 2275], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  693, 1211, 2275, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1211, 1921, 2275, 2340, 2409, 2418,\n",
       "        4458], dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1211, 1508, 2409, 2418, 2428, 4458],      dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2591, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 150,  495, 1211, 2275, 2340, 2585, 2591, 2888, 4456, 4458], dtype=int32),\n",
       " Array([  86,  280,  617,  693, 1211, 1508, 1921, 2275, 2340, 2409, 2418,\n",
       "        2499, 2535, 2828, 3223, 3380, 4458], dtype=int32),\n",
       " Array([ 280,  617,  630,  693,  696, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1182, 1211, 2275], dtype=int32),\n",
       " Array([  86,  280,  417,  614,  617,  693, 1211, 1458, 1508, 2409, 4458],      dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1211, 1508, 2275, 2409, 2418, 4458],      dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693,  703, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  134,  280,  373,  693, 1211, 2409, 2418, 2534, 2535, 4458],      dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211], dtype=int32),\n",
       " Array([  86,  127,  134,  147,  149,  150,  244,  277,  280,  302,  323,\n",
       "         325,  332,  495,  519,  535,  614,  617,  630,  693,  703,  773,\n",
       "        1182, 1208, 1211, 1277, 1508, 1521, 1579, 1750, 1785, 1921, 1949,\n",
       "        1952, 2011, 2043, 2275, 2280, 2309, 2340, 2376, 2409, 2418, 2432,\n",
       "        2520, 2534, 2535, 2585, 2591, 2593, 2656, 2760, 2777, 2888, 2997,\n",
       "        3001, 3264, 3283, 3296, 3317, 3380, 4256, 4331, 4370, 4407, 4456,\n",
       "        4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 150, 1211, 2340, 2534, 2591, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  417,  614,  617,  693, 1078, 1208, 1211, 1458, 2409,\n",
       "        4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  693,  696,  703,  773, 1211, 4456, 4458], dtype=int32),\n",
       " Array([ 134,  150,  693, 1211, 1508, 2275, 2534, 2535, 4456], dtype=int32),\n",
       " Array([  86,  280,  417,  617,  693, 1078, 1211, 1508, 2409, 2418, 2535,\n",
       "        3223, 3380, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 150, 1211, 2043, 2534, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  149,  150,  244,  277,  325,  332,  495,  614,\n",
       "         617,  630,  693,  703,  773, 1078, 1182, 1208, 1211, 1277, 1521,\n",
       "        1579, 1750, 1785, 1949, 2043, 2275, 2280, 2309, 2340, 2376, 2409,\n",
       "        2520, 2534, 2585, 2591, 2656, 2760, 2888, 2997, 3001, 3264, 3283,\n",
       "        3296, 4256, 4331, 4370, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1078, 1211, 1458, 1870, 1921, 2275,\n",
       "        4458], dtype=int32),\n",
       " Array([  86,  277,  280,  693, 1211, 2275, 2340, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 2534], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  693,  696, 1208, 1211], dtype=int32),\n",
       " Array([ 277,  617,  630, 1211, 2534, 2591, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2275, 4458], dtype=int32),\n",
       " Array([  86,  280,  417,  617,  693, 1078, 1211, 1458, 1508, 1870, 1921,\n",
       "        2275, 2418, 2777, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693,  696,  703, 1211, 4456, 4458], dtype=int32),\n",
       " Array([ 277,  417,  617,  693, 1167, 1211], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4256, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1078, 1211, 2275, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  630, 1182, 1208, 1211, 1521, 2534, 2591, 4458],      dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  630,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  614,  617,  703, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2275, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 2409, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2591, 4458], dtype=int32),\n",
       " Array([1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2591, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  630,  693, 1208, 1211, 4256, 4456, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2534, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693,  703, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211, 2535, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  417,  617,  693, 1211], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  417,  614,  617,  693, 1078, 1211, 1458, 2409, 4458],      dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693,  703,  773, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  601,  617,  693,  696,  703, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  417,  617,  693, 1167, 1211], dtype=int32),\n",
       " Array([  86,  127,  134,  150,  244,  277,  302,  325,  332,  495,  535,\n",
       "         614,  617,  630,  693,  773, 1182, 1208, 1211, 1277, 1508, 1521,\n",
       "        1579, 1750, 1785, 1921, 1949, 2043, 2275, 2280, 2309, 2340, 2409,\n",
       "        2418, 2432, 2520, 2534, 2535, 2585, 2591, 2593, 2656, 2760, 2888,\n",
       "        3001, 3178, 3264, 3283, 3296, 3317, 4256, 4370, 4407, 4456, 4458],      dtype=int32),\n",
       " Array([  86,  134,  280,  614,  693, 1078, 1211, 1508, 1921, 2534, 2535,\n",
       "        3297, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693,  703,  773, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  693, 1211, 2275, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  630,  693, 1211, 2309, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617, 1167, 1211, 2534, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  693, 1211, 2409, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  630,  693, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  149,  150,  244,  277,  302,  325,  332,  373,\n",
       "         495,  519,  535,  614,  617,  630,  693,  703,  773, 1078, 1182,\n",
       "        1208, 1211, 1277, 1283, 1508, 1521, 1579, 1750, 1785, 1921, 1952,\n",
       "        2011, 2043, 2252, 2275, 2280, 2309, 2340, 2376, 2409, 2418, 2432,\n",
       "        2520, 2534, 2535, 2536, 2585, 2591, 2593, 2596, 2656, 2760, 2888,\n",
       "        2936, 2997, 3001, 3178, 3223, 3264, 3283, 3296, 3317, 3380, 3421,\n",
       "        4256, 4331, 4370, 4407, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2534, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693,  703,  773, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1078, 1211, 1508, 1921, 2409, 2418,\n",
       "        2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2275, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693,  703, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  693, 1167, 1211, 2534], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693,  696, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2409, 2534, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  630,  693,  696, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  417,  617,  693, 1211, 2534], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693,  696,  703, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1078, 1211, 2340, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  614,  693, 1211, 2409, 2428, 2535, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2275, 2340], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1211, 1508, 1921, 2275, 2409, 2418,\n",
       "        3223, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 2275], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1078, 1211], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2340, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2591, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  630,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  417,  617,  693, 1078, 1167, 1211, 1521], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 302, 1182, 1211, 2275, 2534, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  134,  280,  417,  614,  693, 1078, 1211, 1508, 1579, 2340,\n",
       "        2409, 2520, 2534, 2535, 3380, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2534, 2591, 4458], dtype=int32),\n",
       " Array([ 277,  617,  630,  693,  773, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  630, 1211, 2534, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693,  703, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  630,  693,  696, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  149,  150,  244,  277,  302,  325,  332,  495,\n",
       "         519,  535,  614,  617,  630,  693,  703, 1078, 1182, 1208, 1211,\n",
       "        1277, 1283, 1508, 1521, 1579, 1750, 1785, 1921, 1949, 1952, 2011,\n",
       "        2043, 2275, 2280, 2309, 2340, 2376, 2409, 2418, 2432, 2520, 2534,\n",
       "        2535, 2585, 2591, 2593, 2596, 2656, 2760, 2888, 3001, 3005, 3178,\n",
       "        3264, 3283, 3296, 3317, 3380, 4256, 4331, 4370, 4456, 4458],      dtype=int32),\n",
       " Array([ 277,  617,  693,  773, 1211, 2409, 4456, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([1211, 2275, 2534, 2888, 3264, 4456, 4458], dtype=int32),\n",
       " Array([  86,  280,  495,  614,  617,  693, 1211, 1921, 2409, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 134,  693, 1211, 2534, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  630,  693, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  630,  693,  696, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  332,  617,  630,  693,  703, 1211, 2275, 2340, 2534, 4456,\n",
       "        4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1078, 1211], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  332,  617,  693, 1211], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1078, 1211], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2275, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  630,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([ 127,  277,  617,  773, 1078, 1211, 2409, 4458], dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1211, 1921, 2275, 2409, 2418, 2534,\n",
       "        2777, 2828, 3223, 3380, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  630,  693, 1211], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2591, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  693,  696, 1211], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  147,  149,  150,  244,  277,  280,  302,  323,\n",
       "         325,  332,  373,  417,  495,  519,  535,  614,  617,  630,  693,\n",
       "         696,  703,  705,  773, 1078, 1167, 1182, 1208, 1211, 1277, 1283,\n",
       "        1294, 1458, 1508, 1521, 1579, 1636, 1700, 1750, 1785, 1921, 1937,\n",
       "        1949, 1952, 2011, 2043, 2252, 2275, 2280, 2309, 2340, 2376, 2409,\n",
       "        2418, 2428, 2432, 2499, 2520, 2534, 2535, 2536, 2543, 2585, 2591,\n",
       "        2593, 2596, 2656, 2670, 2760, 2777, 2888, 2925, 2936, 2997, 3001,\n",
       "        3148, 3178, 3223, 3264, 3283, 3296, 3297, 3317, 3380, 3421, 4248,\n",
       "        4256, 4331, 4370, 4407, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2591, 4458], dtype=int32),\n",
       " Array([ 280,  617,  630,  693,  696, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617, 1167, 1211, 1521, 2275, 2534, 2591, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  693,  696, 1211], dtype=int32),\n",
       " Array([ 277,  617,  630,  693, 1211, 4456, 4458], dtype=int32),\n",
       " Array([ 277,  417,  617,  693, 1167, 1208, 1211], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  150,  693, 1211, 1579, 2043, 2275, 2535, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  280,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 150,  495, 1211, 2534, 2585, 2591, 4456, 4458], dtype=int32),\n",
       " Array([ 280,  617,  630,  693,  696, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  703,  773, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  693,  696, 1211], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  149,  150,  244,  277,  302,  325,  332,  417,\n",
       "         495,  519,  535,  614,  617,  630,  693,  703,  773, 1078, 1182,\n",
       "        1208, 1211, 1277, 1283, 1508, 1521, 1579, 1750, 1785, 1921, 1949,\n",
       "        1952, 2011, 2043, 2275, 2280, 2309, 2340, 2376, 2409, 2418, 2432,\n",
       "        2520, 2534, 2535, 2585, 2591, 2593, 2656, 2760, 2888, 2997, 3001,\n",
       "        3178, 3264, 3283, 3296, 4256, 4331, 4370, 4407, 4456, 4458],      dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  630,  693, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2591, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4456, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  149,  150,  244,  277,  302,  325,  332,  495,\n",
       "         535,  614,  617,  630,  693,  703,  773, 1078, 1182, 1208, 1211,\n",
       "        1277, 1508, 1521, 1579, 1750, 1785, 1921, 2043, 2275, 2280, 2309,\n",
       "        2340, 2376, 2409, 2418, 2520, 2534, 2535, 2585, 2591, 2656, 2760,\n",
       "        2888, 2997, 3001, 3005, 3178, 3264, 3283, 3296, 3317, 3380, 3421,\n",
       "        4256, 4331, 4370, 4407, 4456, 4458], dtype=int32),\n",
       " Array([  86,  280,  617,  693, 1211, 2409, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  417,  614,  617,  693, 1211, 1921, 2409, 2418, 2777,\n",
       "        4458], dtype=int32),\n",
       " Array([ 277,  617,  630,  693, 1211, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  417,  617,  693, 1211, 2275], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  147,  149,  150,  244,  277,  280,  325,  332,\n",
       "         495,  519,  535,  614,  617,  630,  693,  703,  773, 1078, 1182,\n",
       "        1208, 1211, 1277, 1508, 1521, 1579, 1750, 1785, 1921, 1952, 2043,\n",
       "        2275, 2280, 2309, 2340, 2376, 2409, 2418, 2520, 2534, 2535, 2585,\n",
       "        2591, 2593, 2656, 2760, 2888, 2997, 3001, 3178, 3264, 3283, 3296,\n",
       "        3317, 4256, 4331, 4370, 4407, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  495,  617,  693, 1211, 1750, 2275, 2309, 2520, 2534,\n",
       "        2656, 3317, 4331, 4458], dtype=int32),\n",
       " Array([  86,  280,  614,  617,  693, 1211, 1921, 2275, 2409, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2275, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 495, 1211, 2534, 2591, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2591, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693,  703, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  280,  417,  614,  617,  693, 1208, 1211, 1458, 1921, 2409,\n",
       "        2418, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  280,  617,  630,  693,  696, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211], dtype=int32),\n",
       " Array([  86,  280,  617,  693, 1211, 1921, 2409, 2418, 2534, 4458], dtype=int32),\n",
       " Array([  86,  127,  134,  149,  150,  244,  277,  280,  302,  325,  332,\n",
       "         495,  519,  535,  614,  617,  630,  693, 1078, 1182, 1208, 1211,\n",
       "        1277, 1508, 1521, 1579, 1750, 1785, 1921, 1949, 2043, 2275, 2280,\n",
       "        2309, 2340, 2376, 2409, 2418, 2432, 2520, 2534, 2535, 2536, 2585,\n",
       "        2591, 2593, 2596, 2656, 2760, 2888, 3001, 3005, 3178, 3264, 3283,\n",
       "        3296, 3317, 4331, 4370, 4407, 4456, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 280,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([ 277,  617,  693, 1167, 1211, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 2534, 4458], dtype=int32),\n",
       " Array([  86,  277,  617,  693, 1211, 4458], dtype=int32),\n",
       " Array([ 134,  150,  693, 1211, 1508, 2534, 2535, 4456], dtype=int32)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[jnp.where(min_circuit[n] & ~mn_mask)[0] for n in range(min_circuit.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([  31,   86,  277,  617, 1167], dtype=int32),\n",
       " Array([1, 1, 3, 4, 3], dtype=int32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.unique(jnp.concatenate([jnp.where(min_circuit[n] & ~mn_mask)[0] for n in range(min_circuit.shape[0])],axis=0),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.076171875"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jnp.where(osc_score_all<0.5)[0])/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x701df9da36d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOS9JREFUeJzt3X18k/W9//F3krZJb4PlpmkFoTgUS+cNIAwYN8cJMhnqNnWb4tGzzamwTXQbwnEb4I70gEfOzobi9LepG7I55zyTiQhnkxsVB1LYBnV6JgVhtKdCIS29pcn1+6MmtvQuSZMryZXX8/Ho45Fe+Sb55Jsr1/XJ9+6yGYZhCAAAwCT2eAcAAABSC8kHAAAwFckHAAAwFckHAAAwFckHAAAwFckHAAAwFckHAAAwFckHAAAwVVq8Azib3+/XsWPHlJubK5vNFu9wAABACAzDUH19vYqKimS39962kXDJx7FjxzRs2LB4hwEAACJw5MgRDR06tNcyCZd85ObmSmoPPi8vL87RAIiGhoYGFRUVSWr/gZGdnR3niABEW11dnYYNGxY8j/cm4ZKPQFdLXl4eyQdgEQ6HI3g7Ly+P5AOwsFCGTDDgFAAAmCrhWj4AWE9aWppuvfXW4G0AqY2jAICYczqdeuqpp+IdBoAEQbcLAAAwFS0fAGLOMAw1NjZKkrKysljDB0hxtHwAiLnGxkbl5OQoJycnmIQASF0kHwAAwFQkHwAAwFSM+QDQLz6/oV2Vtaqpb9aQXJcmFOfLYWdMB4CekXwAiNim/VVavqFCVd7m4LZCt0tL55ZodmlhHCMDkMjodgEQkU37q3TXuvJOiYckVXubdde6cm3aXxWnyAAkOpIPAGHz+Q0t31Aho5v7AtuWb6iQz99dCQCpjm4XAGHbVVnbpcWjI0NSlbdZuyprNen8gXI4HLr++usldb7IHIDURPIBIGw19T0nHt2Vc7lceu6552IZEoAkQrcLgLANyXVFtRyA1ELyASBsE4rzVeh2qacJtTa1z3qZUJxvZlgAkgTJB4CwOew2LZ1bIkldEpDA/0vnlgTX+2hoaJDNZpPNZlNDQ4N5gQJISCQfACIyu7RQa+eNlcfduWvF43Zp7byxrPMBoEcMOAUQsdmlhZpZ4mGFUwBhIfkA0C8Ou02Tzh8Y7zAAJBG6XQAAgKlIPgAAgKlIPgAAgKkY8wEg5hwOh66++urgbQCpjeQDQMy5XC699NJL8Q4DQIKg2wUAAJiK5AMAAJiK5ANAzDU0NCg7O1vZ2dksrw6AMR8AzNHY2BjvEAAkCFo+AACAqUg+AACAqUg+AACAqUg+AACAqUg+AACAqZjtAiDm7Ha7pk+fHrwNILWRfACIuczMTG3dujXeYQBIEPwEAQAApiL5AAAApiL5ABBzDQ0NGjx4sAYPHszy6gAY8wHAHMePH493CAASBC0fAADAVCQfAADAVCQfAADAVCQfAADAVCQfAADAVMx2ARBzdrtd48ePD94GkNpIPgDEXGZmpnbv3h3vMAAkCH6CAAAAU5F8AAAAU5F8AIi5xsZGjRgxQiNGjFBjY2O8wwEQZ4z5ABBzhmHo8OHDwdsAUhstHwAAwFQkHwAAwFQkHwAAwFQkHwAAwFQkHwAAwFTMdgEQczabTSUlJcHbAFIbyQeAmMvKytKBAwfiHQaABEG3CwAAMBXJBwAAMBXJB4CYa2xs1JgxYzRmzBiWVwcQXvLR1tam7373uyouLlZmZqZGjhypBx54QH6/P1jGMAwtW7ZMRUVFyszM1IwZM+jrBVKcYRiqqKhQRUUFy6sDCC/5WLlypR577DGtWbNGb7/9tlatWqWHHnpIP/7xj4NlVq1apdWrV2vNmjXavXu3PB6PZs6cqfr6+qgHDwAAkk9YycfOnTt17bXXas6cORoxYoSuv/56zZo1S2+99Zak9l83P/zhD3X//ffrc5/7nEpLS/X000+rsbFR69evj8kbAAAAySWs5OOTn/yk/vCHP+jdd9+VJP35z3/Wa6+9pquvvlqSVFlZqerqas2aNSv4GKfTqenTp+uNN97o9jlbWlpUV1fX6Q8AAFhXWOt83HffffJ6vRo9erQcDod8Pp8efPBBfelLX5IkVVdXS5IKCgo6Pa6goCB4Oe2zlZWVafny5ZHEDgAAklBYLR/PPvus1q1bp/Xr16u8vFxPP/20/uM//kNPP/10p3Jnr2BoGEaPqxouWbJEXq83+HfkyJEw3wIAAEgmYbV8fOc739HixYv1xS9+UZL08Y9/XIcPH1ZZWZluvfVWeTweSe0tIIWFhcHH1dTUdGkNCXA6nXI6nZHGDyAJ2Gw2DR8+PHgbQGoLq+WjsbFRdnvnhzgcjuBU2+LiYnk8Hm3ZsiV4f2trq7Zt26bJkydHIVwAySgrK0uHDh3SoUOHlJWVFe9wAMRZWC0fc+fO1YMPPqjzzjtPY8aM0d69e7V69Wp9+ctfltT+i2bhwoVasWKFRo0apVGjRmnFihXKysrSTTfdFJM3AAAAkktYycePf/xjfe9739P8+fNVU1OjoqIi3XHHHfr+978fLLNo0SI1NTVp/vz5OnnypCZOnKjNmzcrNzc36sEDAIDkYzMSbLnBuro6ud1ueb1e5eXlxTscAFHQ1NSkadOmSZK2b9+uzMzMOEcEINrCOX+H1fIBAJHw+/3BxQg7Xo4BQGriwnIAAMBUJB8AAMBUJB8AAMBUJB8AAMBUJB8AAMBUzHYBYIpBgwbFOwQACYLkA0DMZWdn64MPPoh3GAASBN0uAADAVCQfAADAVCQfAGKuqalJM2bM0IwZM9TU1BTvcADEGWM+AMSc3+/Xtm3bgrcBpDZaPgAAgKlIPgAAgKlIPgAAgKlIPgAAgKlIPgAAgKmY7QLAFFlZWfEOAUCCSJnkw+c3tKuyVjX1zRqS69KE4nw57LZ4hwUkpXC/T9nZ2WpoaDAxQgCJLCWSj037q7R8Q4WqvM3BbYVul5bOLdHs0sI4RgYkH75PAPrL8mM+Nu2v0l3ryjsdKCWp2tusu9aVa9P+qjhFBiQfvk8AosHSyYfPb2j5hgoZ3dwX2LZ8Q4V8/u5KAOioP9+n5uZmzZkzR3PmzFFzc3OX+wGkFksnH7sqa7v8QuvIkFTlbdauylrzggKSVH++Tz6fTxs3btTGjRvl8/liGCWAZGDp5KOmPrRfWKGWA1IZ3ycA0WLp5GNIriuq5YBUxvcJQLRYOvmYUJyvQrdLPU0AtKl9lP6E4nwzwwKSEt8nANFi6eTDYbdp6dwSSepywAz8v3RuCet9ACHg+wQgWiydfEjS7NJCrZ03Vh5356Zgj9ultfPGsi4BEAa+TwCiwWYYRkLNM62rq5Pb7ZbX61VeXl7UnpcVToHoCff71NDQoJycHEnS6dOnlZ2dbVaoAEwSzvk7JVY4ldqbjCedPzDeYQCWEO73KTs7Wwn2OwdAHFm+2wUAACQWkg8AAGAqkg8AMdfc3KwbbrhBN9xwA8urA0idAacA4ocBp4D1hXP+puUDAACYiuQDAACYKmWm2gIwR3drgABARyQfAKJm0/4qLd9QoSrvR4NKC90u3fepEfELCkDCIfkAEBWb9lfprnXlOnsEe7W3WXf/al88QgKQoBjzAaDffH5DyzdUdEk8JHW7DUBqI/kA0G+7Kms7dbV0ke7UsHt+oz/85bCysrLMCwxAQqLbBUC/1dT3vnCYzWaTLcOlep9DNhsXdARSHS0fAPptSK4rquUAWBvJB4B+m1Ccr0K3Sz22abSdUcOWH+mxB76llpYWM0MDkIBSJvlobfPrpzsO6vu/26+f7jio1jZ/vEMCLMNht2np3BJJ6pKA2CQZfp+Ol2/Wz3/+tNra2kyPD0BiSYlru5RtrNATOyrl7/BO7Tbp9qnFWnJ1SVReA0Dv63x8duLHJHFtF8Cqwjl/W37AadnGCv1ke2WX7X5Dwe0kIEB0zC4t1MwST5cVTpubGuMdGoAEYunko7XNryd2dE08OnpiR6W+NWu0MtJSpgcKiCmH3aZJ5w+MdxgAEpilz7i/2HmoU1dLd/xGezkAAGAOSycfh2tDa+oNtRwAAOg/Sycfw/NDW0kx1HIAAKD/LJ183DJphOx9LKZot7WXAxA7WVlZqqmpUU1NDcurA7B28pGRZtftU4t7LXP71GIGmwIxZrPZNHjwYA0ePJjl1QFYe7aL9NE0Wtb5AAAgMaTEImNS+7TbX+w8pMO1jRqen6VbJo2gxQMwSUtLi+69915J0urVq+V0OuMcEYBoC+f8nTLJh9l8fqPLQkuOvgagABbV0NCgnJwcSaxwCpjNrPMRK5zGWU9LTC+dW6LZpYVxjAwAkEoS9XxEv0OUbdpfpbvWlXf6oCWp2tusu9aVa9P+qjhFBgBIJYl8PkqZ5MPnN7TzvRP63b5/aOd7J+Tra+nTCF9j+YYKdffMgW3LN1TE5LUBAAhI9PNRSnS7mNXstKuytkuG2ZEhqcrbrF2VtVz7AgAQM4l+PrJ8y4eZzU419T1/0JGUAwAgEol+PrJ08mF2s9OQXFdUywEAEIlEPx9ZOvkIp9kpGiYU56vQ7VJPE5hsau/umVCcH5XXA5JFZmamKisrVVlZqczMzHiHA1heop+Pwk4+/vGPf2jevHkaOHCgsrKydOmll2rPnj3B+w3D0LJly1RUVKTMzEzNmDFDBw4ciGrQoTK72clht2np3PYVU8/+wAP/L51bwnofSDl2u10jRozQiBEjZLdb+jcPkBAS/XwU1lHg5MmTmjJlitLT0/Xyyy+roqJCDz/8sAYMGBAss2rVKq1evVpr1qzR7t275fF4NHPmTNXX10c79j7Fo9lpdmmh1s4bK4+783N63C6tnTeWdT4AAKZI5PNRWCucLl68WK+//rp27NjR7f2GYaioqEgLFy7UfffdJ6l9WeWCggKtXLlSd9xxR5+vEc0VTn1+Q59c+UdVe5u7HfdhU/uH8Np9V0Q9+2OFU+Ajra2tuv/++yVJDz74oDIyMuIcEZA6EnGF07CSj5KSEl111VU6evSotm3bpnPPPVfz58/X7bffLkk6ePCgzj//fJWXl+uyyy4LPu7aa6/VgAED9PTTT3d5zpaWFrW0tHQKftiwYVFbXj0w20VSpwQkUO3xzv6AVMDy6oD1hZN8hNXtcvDgQa1du1ajRo3SK6+8ojvvvFPf/OY39fOf/1ySVF1dLUkqKCjo9LiCgoLgfWcrKyuT2+0O/g0bNiyckPqUyM1OAACkorAWGfP7/Ro/frxWrFghSbrssst04MABrV27Vv/8z/8cLGezdW7OMQyjy7aAJUuWBK92KX3U8hFNs0sLNbPEQzcIAAAJIKzko7CwUCUlJZ22XXTRRXr++eclSR6PR1J7C0hh4UctCjU1NV1aQwKcTqcpl9d22G2sKgoAQAIIq9tlypQpeueddzpte/fddzV8+HBJUnFxsTwej7Zs2RK8v7W1Vdu2bdPkyZOjEC4AAEh2YbV83HPPPZo8ebJWrFihG2+8Ubt27dLjjz+uxx9/XFJ7d8vChQu1YsUKjRo1SqNGjdKKFSuUlZWlm266KSZvAAAAJJewko/LL79cL7zwgpYsWaIHHnhAxcXF+uEPf6ibb745WGbRokVqamrS/PnzdfLkSU2cOFGbN29Wbm5u1IMHAADJJ6yptmaI5jofABKD3+/X22+/Lal9nBirnALWE875O6yWDwCIhN1u15gxY+IdBoAEwc8PAABgKlo+AMRca2trcH2gf/3Xf2V5dSDFMeYDQMyxvDpgfTFbXh0AAKC/SD4AAICpGPMRZWZduhgAgGRF8hFFm/ZXafmGClV5m4PbCt0uLZ1bwtVzAQD4EN0uUbJpf5XuWlfeKfGQpGpvs+5aV65N+6viFBkAAImF5CMKfH5DyzdUqLtpQ4FtyzdUyOdPqIlFAADEBd0uUbCrsrZLi0dHhqQqb7N2VdZq0vkDzQsMSBAul0u7du0K3gaQ2kg+oqCmvufEI5JygNU4HA5dfvnl8Q4DQIKg2yUKhuSG9ksu1HIAAFgZyUcUTCjOV6HbpZ4m1NrUPutlQnG+mWEBCaO1tVUPPfSQHnroIbW2tsY7HABxRvIRBQ67TUvnlkhSlwQk8P/SuSWs94GUdebMGS1atEiLFi3SmTNn4h0OgDgj+YiS2aWFWjtvrDzuzl0rHrdLa+eNZZ0PAAA+xIDTKJpdWqiZJR5WOAUAoBckH1HmsNuYTgsAQC/odgEAAKYi+QAAAKYi+QAAAKZizAeAmHO5XHr11VeDtwGkNpIPADHncDg0Y8aMeIcBIEHQ7QIAAExFyweAmDtz5owef/xxSdLXvvY1paenxzkiAPFkMwzDiHcQHdXV1cntdsvr9SovLy9qz+vzGyz+BcRJQ0ODcnJyJEmnT59WdnZ2nCMCEG3hnL9TouVj0/4qLd9QoSrvR5e0L3S7tHRuCcueAwBgMsuP+di0v0p3rSvvlHhIUrW3WXetK9em/VVxigwAgNRk6eTD5ze0fEOFuutXCmxbvqFCPn9C9TwBAGBplk4+dlXWdmnx6MiQVOVt1q7KWvOCAgAgxVk6+aip7znxiKQcAADoP0snH0NyQ1tJMdRyAACg/yw922VCcb4K3S5Ve5u7Hfdhk+Rxt0+7BRA7TqdTv//974O3AaQ2S7d8OOw2LZ1bIqk90ego8P/SuSWs9wHEWFpamubMmaM5c+YoLc3Sv3kAhMDSyYckzS4t1Np5Y+Vxd+5a8bhdWjtvLOt8AABgspT4CTK7tFAzSzyscArEyZkzZ/TMM89Ikm6++WaWVwdSXMosrw4gflheHbC+cM7flu92AQAAiYXkAwAAmIrkAwAAmIrkAwAAmIrkAwAAmIrkAwAAmCol1vkAEF9Op1O//vWvg7cBpDaSDwAxl5aWphtuuCHeYQBIEHS7AAAAU9HyASDm2tra9MILL0iSPvvZz3JxOSDFpcwRwOc3uLYLECctLS268cYbJbUvr07yAaS2lDgCbNpfpeUbKlTlbQ5uK3S7tHRuCVe1BQDAZJYf87Fpf5XuWlfeKfGQpGpvs+5aV65N+6viFBkAAKnJ0smHz29o+YYKdXfZ3sC25Rsq5PMn1IV9AQCwNEsnH7sqa7u0eHRkSKryNmtXZa15QQEAkOIsnXzU1PeceERSDgAA9J+lk48hua6olgMAAP1n6dkuE4rzVeh2qdrb3O24D5skj7t92i2A2MnIyNCTTz4ZvA0gtVk6+XDYbVo6t0R3rSuXTeqUgARW+Fg6t4T1PoAYS09P12233RbvMAAkCEt3u0jS7NJCrZ03Vh53564Vj9ultfPGss4HAAAms3TLR8Ds0kLNLPGwwikQJ21tbXrllVckSVdddRUrnAIpLmWOAA67TZPOHxjvMICU1NLSos985jOSWF4dQAp0uwAAgMRC8gEAAExF8gEAAExF8gEAAEzVr+SjrKxMNptNCxcuDG4zDEPLli1TUVGRMjMzNWPGDB04cKC/cQIAAIuIOPnYvXu3Hn/8cV188cWdtq9atUqrV6/WmjVrtHv3bnk8Hs2cOVP19fX9DhYAACS/iJKP06dP6+abb9YTTzyhc845J7jdMAz98Ic/1P3336/Pfe5zKi0t1dNPP63GxkatX78+akEDSC4ZGRlas2aN1qxZw/LqACJLPhYsWKA5c+boyiuv7LS9srJS1dXVmjVrVnCb0+nU9OnT9cYbb3T7XC0tLaqrq+v0B8Ba0tPTtWDBAi1YsEDp6enxDgdAnIW90s+vfvUrlZeXa/fu3V3uq66uliQVFBR02l5QUKDDhw93+3xlZWVavnx5uGEAAIAkFVbLx5EjR3T33Xdr3bp1crl6vgy9zdZ52XLDMLpsC1iyZIm8Xm/w78iRI+GEBCAJ+Hw+bd26VVu3bpXP54t3OADiLKyWjz179qimpkbjxo0LbvP5fNq+fbvWrFmjd955R1J7C0hh4UcXbKupqenSGhLgdDrldDojiR1AkmhubtY//dM/SWofM5adnR3niADEU1gtH5/61Kf017/+Vfv27Qv+jR8/XjfffLP27dunkSNHyuPxaMuWLcHHtLa2atu2bZo8eXLUgwcAAMknrJaP3NxclZaWdtqWnZ2tgQMHBrcvXLhQK1as0KhRozRq1CitWLFCWVlZuummm6IXNQAASFpRv7TkokWL1NTUpPnz5+vkyZOaOHGiNm/erNzc3Gi/FAAASEI2wzCMeAfRUV1dndxut7xer/Ly8uIdDoAoaGhoUE5OjiTGfABWFc75m2u7AAAAU5F8AAAAU0V9zAcAnC09PV2rVq0K3gaQ2hjzAQAA+o0xHwAAIGHR7QIg5nw+n8rLyyVJY8eOlcPhiHNEAOKJ5ANAzDU3N2vChAmSmGoLgG4XAABgMpIPAABgKpIPAABgKpIPAABgKpIPAABgKpIPAABgKqbaAoi59PR0LV26NHgbQGpjeXUAANBvLK8OAAASFt0uAGLO7/fr7bffliRddNFFstv53QOkMpIPADHX1NSk0tJSSSyvDoBuFwAAYDKSDwAAYCqSDwAAYCqSDwAAYCqSDwAAYCqSDwAAYCqm2gKIufT0dH37298O3gaQ2lheHQAA9BvLqwMAgIRFtwuAmPP7/Xr//fclSeeddx7LqwMpjuQDQMw1NTWpuLhYEsurA6DbBQAAmIzkAwAAmIrkAwAAmIrkAwAAmIrkAwAAmIrkAwAAmIqptgBiLi0tTfPnzw/eBpDaOAoAiDmn06lHHnkk3mEASBB0uwAAAFPR8gEg5gzD0PHjxyVJgwYNks1mi3NEAOKJ5ANAzDU2NmrIkCGSWF4dAN0uAADAZCQfAADAVCQfAADAVCQfAADAVCQfAADAVCQfAADAVEy1BRBzaWlpuvXWW4O3AaQ2jgIAYs7pdOqpp56KdxgAEgTdLgAAwFS0fACIOcMw1NjYKEnKyspieXUgxdHyASDmGhsblZOTo5ycnGASAiB1kXwAAABTkXwAAABTkXwAAABTkXwAAABTkXwAAABTkXwAAABTsc4HgJhzOBy6/vrrg7cBpDaSDwAx53K59Nxzz8U7DAAJgm4XAABgKpIPAABgKpIPADHX0NAgm80mm82mhoaGeIcDIM5IPgAAgKnCSj7Kysp0+eWXKzc3V0OGDNF1112nd955p1MZwzC0bNkyFRUVKTMzUzNmzNCBAweiGjQAAEheYSUf27Zt04IFC/Tmm29qy5Ytamtr06xZszo1o65atUqrV6/WmjVrtHv3bnk8Hs2cOVP19fVRDx4AACQfm2EYRqQP/uCDDzRkyBBt27ZN06ZNk2EYKioq0sKFC3XfffdJklpaWlRQUKCVK1fqjjvu6PM56+rq5Ha75fV6lZeXF2loABJIQ0ODcnJyJEmnT59WdnZ2nCMCEG3hnL/7NebD6/VKkvLz8yVJlZWVqq6u1qxZs4JlnE6npk+frjfeeKPb52hpaVFdXV2nPwAAYF0RJx+GYejee+/VJz/5SZWWlkqSqqurJUkFBQWdyhYUFATvO1tZWZncbnfwb9iwYZGGBAAAkkDEK5x+/etf11/+8he99tprXe6z2Wyd/jcMo8u2gCVLlujee+8N/l9XV0cCAliMw+HQ1VdfHbwNILVFlHx84xvf0Isvvqjt27dr6NChwe0ej0dSewtIYWFhcHtNTU2X1pAAp9Mpp9MZSRhh8fkN7aqsVU19s4bkujShOF8Oe/cJEYDocrlceumll+IdBoAEEVbyYRiGvvGNb+iFF17Q1q1bVVxc3On+4uJieTwebdmyRZdddpkkqbW1Vdu2bdPKlSujF3WYNu2v0vINFaryNge3FbpdWjq3RLNLC3t5JAAAiLawxnwsWLBA69at0/r165Wbm6vq6mpVV1erqalJUnt3y8KFC7VixQq98MIL2r9/v2677TZlZWXppptuiskb6Mum/VW6a115p8RDkqq9zbprXbk27a+KS1wAAKSqsFo+1q5dK0maMWNGp+1PPvmkbrvtNknSokWL1NTUpPnz5+vkyZOaOHGiNm/erNzc3KgEHA6f39DyDRXqbi6xIckmafmGCs0s8dAFA8RQQ0ODhgwZIqm9G5aptkBq69c6H7EQzXU+dr53Ql964s0+y/3y9k9o0vkD+/VaAHrGOh9A+JJtrGI45++IZ7skg5r65r4LhVEOAAAzWH2soqUvLDck1xXVcgAAxFoqjFW0dPIxoThfhW6Xemqksqk9k5xQnG9mWAAAdKuvsYpS+1hFn7/7ERM+v6Gd753Q7/b9QzvfO9FjuXizdLeLw27T0rklumtduWxSpw8zkJAsnVuS0H1oAIDUsauytkuLR0eGpCpvs3ZV1nYZq5hMXTWWbvmQpNmlhVo7b6w87s5dKx63S2vnjU24DwQAkLoiHauYbF01lm75CJhdWqiZJZ6kGjUMWIndbtf06dODtwF0L5Kxism4rERKJB9SexcM02mB+MjMzNTWrVvjHQZSTGCqanVds2pPtyg/O0Med2ZC//gMjFWs9jZ3m0zY1N5y33GsYqhdNf+55V1N+dighHj/KZN8AABSR3fjHwISdRyEFNlYxVC7ata8+netefXvCfH+af8EAFhKT+MfAqoSdBxEQLhjFcNdLiIRxoHQ8gEg5hoaGjRixAhJ0qFDh1jhFDHT2/iHjgwl3jiIjsIZq9hXV83ZEmEcCC0fAExx/PhxHT9+PN5hwOL6Gv/QUWDKaqIKjFW89tJzNen8gT0mCYGuGkk9rmt1to5TduOB5AMAYBnhXi7DKpfX6Kmrpi/xev90uwAALCPc8Q9WurxGx66a1//+gda8+l6fj4nX+6flAwBgGX1dVqMjK15eI9BVc8/MCxP68iIkH+giWa4NACDxxPv40XH8Q29ssvblNRx2m74356JeB6DG8/3T7YJOkunaAAASS6IcPwLjH5JxnY9o2bS/Sj946e0e73dnpZsYTVc2wzAS6mdtXV2d3G63vF6v8vLy4h1OSgnMjT97hwjkxVwLB5FqamrStGnTJEnbt29XZmZmnCNCtCXi8SMZVziNhp4+i45i8bmEc/4m+YCk9i/pJ1f+sccpaoElfV+77wpLf2kRW4GTAddYSk49fX4cPxJHX59FR9H+XMI5f9PtAkn9u4wzEIpEaZJHZHr7/NyZGRw/EkQ465zE83NhwCkkRX4ZZyAUyXa5b3TW1+e3paI6pOfh+BF7/xPiZ9FRPD4Xkg9IiuwyzkAofH5D33++XEfWfllH135Z/jMfHegCfb7LN1QwqypB9XW5dkn63b5jIT0Xx4/Y8vkN/XbvP8J+XDw+l5TpdqGvuXeRXMYZCMWuylpVe5vlq6tp33DWDhZo+n3z4AlN+dggU2LieBC6ULpkTzS0Kj87XScbzljy+NHbWJdE2o92VdbqZOOZkMvH83NJieSDvua+RXIZZyAUoTbpLnimXP/++Y/H/DvJ8SA8oX5+n730XP3s9UOWO370tL9cc0mhXvxzVULtR5F0n8Trc7F8twt9zaEL9zLOQChCbdI91XQm5t9JjgfhC/Xzu7LEY7njR0/7S5W3WT/ZXplw+1G43Sdfm1Yct8/F0i0fffVVxvuSwokonMs4A6GYUJwvj9upIyGWj9V3kuNBZMLpknXYbZY5fvS2v/Qk3vvRhOJ8efJcqq4LrQXkd/uOadHsi2j5iLZwpo/iI6FexhmJLd7LXAc47Db966cvCqlsLL+THA/CE9h/fv+XY/ri5edJ6nq59u66VKxy/AhnympHZu1H3X2/HXabll3T99LyAdV1LXrzvRMxjLJnlm75YPooUlWijWuYOcYTVvlYfCc5HoSuu/1nwIfLcZ/qMKDRY+GxMv3dD2K5H/X2/Zak7AyHGlp9IT3XgvXmjLU6m6WTD6aPIhX1tLRyoD86Hv3vNptNJSUlamz1yRfCD+FYfCc5HoSmp/3H29g+k+WeK0dpxKDspO5SCUV/94NY7Ue9fb/vXFce9vMFxlqZfVywdLfLuOHnqK/vhd3WXg6xkyjN//2VDO8jlDUZ4rGmRlZWlg4cOKC/v/O2zh00oMdysbzMd1+XWo/3JcYTQSjjYn61+4g+c3FRUnephKKv/aUnsdyPQvl+R8rs44KlWz72HD6pvurSb7SXY8nf2Ei05v9IJcv7SPRl8h12m665pFA/2V7ZY5lYTf1jOnnfEn3/MVNv+0tPYr0fRToOpS/x+Fwt3fJBH298WWVaYzK9j0Tf5zftr9LjvSQesZ76x3Ty3iX6/mO2nvaXQrdLd0wrVqHJ+1Gs693Mz9XSLR+DcpxRLYfQWWVaY7K9j0Qd19DY2KjLL79clccbNGjew7Knd319m6QX/1wV86l/TCfvWaLuP/HU2/6yaPZFpu5Hsa53Mz9XSycfIXeCJV7XvWlitTywVZpvk+19JOoy+YZhqKKi4sN/eigj8+oyMB20O61tfv1i5yEdrm3U8Pws3TJphDLSYt9IHK+lugOvW+1t0vHTLXJnpsvb1P0S3eHsP2a8n2i8RijPcfb+Ehj/Ve1tUm1Dq/JD+AEbbqzdlR83/BzlZ2eotqE1rPfYl3gcFyydfBxvaIlqOauJ5TgGqzTfJtv7sMK4hnjWZdnGCj2xo7LTWLEHN76t26cWa8nVoa+fEK54jSnq7nV7Es7+Y8b7icZrRPIcvdVZT48N93VCneocDfE6Llh6zAdNiD2L9TgGq9R9Mr6PZB/XEK+6LNtYoZ9sr+wySN1vSD/ZXqmyjRUxed14jSnq6XV7Eur+Y8b7icZrRPIcfdVZVTePDfd1eip/qvFM1BMPKX7HBUu3fASm2vY24yUVp9qaMY4hUZv/w5Ws7yPRxjWEOoUvXlNdW9v8emJHzwNhJemJHZX61qzRUe2CideYonCWDh+Qma5Hbh6rT4zse2qtGe8nGq8RyXOEU2eBxwZuh/o6kSzp3pO+ZuiE87nGgqWTD6bads+McQzxaP6PRR9zMndjBPqpA/Xy+78ci1sS8tah0JaaHjUkJ7hMdCh8fkNvHjyhne+dkGRo0shB+kQ36090t29ICm5761BtSMeKBc/s0dUXF8mT13099rUPnn2/32+E9F38zy3vasrHBgXjDrxnn9+Qt6lFNXUtajrj1yVDB7R/Zw3pT4dOyDCkvMx01TW1LxB2TlaGBuU6VXu6JeQWj1NNZ7Rpf5VeOVDd4xiYwPt6/e/HQ3o/y17cr+99Zowcdlv7eJO6ZtWeblF+doY87kxdOmyA1r15WLsP1Sorw6HPXzZUk0cNCpYP9TXGDs/v9rMK5xg4oTj/w/f2QUh1Fnjst3+9TyVF7pBe56nXK3XblGK9efBE1KbS9pXAnGo6I7vNFrdjl80wjIQabllXVye32y2v16u8vLx+Pdfv9v1Dd/9qX5/l/uuLl+raS8/t12slEzPrxay+7Fi/TrKs83G2RIn72Z3/qy9OvkCSNOye38ie0XPXit2mkMZYbNpfpcW//WuXpugBWen69899tFx0rPrPz67Hvuq62zgy03Wqh8Gd3RmQla7WNr8aQ1w6OxbO/nzCGTfSkc0mZaY7Qn4vWRkOrb7xErW0+UM6fnV09mf1wIYD+tnrh/p83FemjNDG/dUxWVvjbAOy0tXY6lNrmz/mrxVwXn6mti+6ImrPF87529LJx873TuhLT7zZZ7lf3v6JlGr5MLteYj3qvaflhgOvEK3+zHjNRoiUWfUSilf3H9HMKeMlSUVffbTbqbZnu2NazwnIpv1VfS4l/di8sZLUbR1Ei03t9djT6wTq+mvTivX49kpLTay7Y1qxLjvvnJjWb3fuufIC/ef/vBv24zp+VpEsQ25VFw/N04tfnxqV5yL5+NDp5jaVLnulz3L7l12lHFfi9kAFp8Kd1TQZ6cnP5zf0yZV/7HMcw2v3XZHQJ1fpo/fS0y+TZHov0dRXvUiSJ8+p1xd/Kqx6iTQB62uf647dJv3tB58ONvEHXrvqVJOWbjig+ua2Xh9fkJshm80e8uXFIxHYvwzDUHVdz7Pm+hp7lqxyMhw6bXIrTJpNcqbZ1HAm/Ap1u9LU0uZTc5sFP4x+iNY5MJzzd+KecaNg5aa3Qy73g+s+HuNoIhPJtK6+JPM4hrMl2zocZgllGebquhat+ePfdfeVo0J6zv504USyVLXfkH6x85C+MnVkRE37/1cf3bUQuhPYv/pixcRDkumJhyS1GVJbBImHJHn7SFhT1c3/b6d+F6XWj1BZeqrtoRONUS1ntkimdYUq2adjBiTbOhxmCfX9/uf/vBuzaYln62mf683h2sawp4QCCM+fj9aZfpkIS7d8FOSlR7WcmUKdcmUo8qlriTYdMxLJuA6HGcJ5v7GYlni2pqYmTZs2TZL0P3/cqkkP7QhpoOGwc7KiNvUQQM/ue26fqZeJsHTLx3s1obVohFrOTOFcvTDQrRCJwHTMay89t8dLZCfypeS5THr3JhTnKz87I6Syfe0/4XRt9cTv9+utt97SW2+9pT2HToSUeNgkjfbkRtziUZCbIU9e+JdED0dg//LkOXt9HVvy5PNIUd4Wf8TnkUhYuuWjtwFgkZQzU7jdBLHqVkiUqZo9sdL4lWhy2G267tKikKYTSr3vP9Hu2vrgdGjftytGD1ZtY+TjNpZfWypJYY0zicTSuSU9vk5gr7viwsH6w98+iFEEQHSY2T1t6ZaPohD7lkMtZ6Zwuwli0a2QLJeSt8r4lWgLrLAYit72n2h3bQ0O8SrSX516vg4dbwipbEcDstL12IefeyTjTEJV2GH/6msf/OrU86P++kC0cVXbKPnZbRN0yQObQyqXaPpa1rujWHQrJNul5K0wfiXaJhTny5Pn7LNlr6/9J9pLzI8fEdrzjRt+ju55dm9IzylJ2RkOPTZvnCZ/bFCnzz2wb7x58IQWPFMe1qJeUnv9/Mf1l6imvjl4BdPuVs3sbR/0+Q0Vul1hdSHZJBXkOfXwjZfq+OkWDcpx6lu/3tfr55ntdOjRm8bKLlu3K5wOyEzXI1vf6/GqtdEUy9YmRJ/baeeqttHizkrX8IGZOnyiqccywwdmyp2VeANOO3Yn9Mam2HQrJOMU1t4uk56KHHabll0zps8Flfraf6LdtRXq8+05fDLkLlGbpIdvvERTLxjc42tO+dgg/fvnPx78ToVyYgx8v6aMGhRSHD3tgx3fc6ivK0nLrhmjKR/76LWXXTOm2/gD5R++4RJNv3CIJGnqhd3XxXkDs8Kqg0h95mKPfv+XahKQJLHyhku5qm00bfvOFRo+MLPb+4YPzNS270RvadloCzTlFvbQZFwYw24FprBaw+zSQj02b2xwOfGOzunQPRHK80SzayuU5wt13xqQmR5yDOF0w0T7+9XX97mjnuo1Gp9Df7uisjIcIZW7ssQT8vtFfIV6HIgmS69w2pG38Yy+/NQuHfM2q8jt0s9um5CQLR7difYKp6FgaXpr8fkNvfneCe08eFxS+6/zSK5mGekKpw0NDRoxYoQk6dChQ8rOzu7z+ULdB5/56sROrQPhvo/8zAz97f/q9X5toyRDlw4doKJzsmL2/Qq89rGTjdp39JQkm87Lz9LoglzVNrWGVK/RWOq/43MMynFKRvuPieOnW3Xqw4G+eZlp8ja2qcrbpKIBmZp8/iDJJt38//7U5/MHjg3B45e3SR/Uteiv/zilvUdPKc1m08eG5Oiq0kIVDciUDKna26S9R06p2tukKm+znOkODTsnSxcW5OhvVXX6W0298lzpmnWRR7dMHqG3DtXq+fKjOnqyUc40u/KzMmSTdLyxVa1tfp07IEvXjxuqiSMHas/hkzp2qkl736/VkZON2nP4lPyGoXPdLi2aNVp1rT6Vv9++gu7B4w3yG1J90xllpjvkcbs0dsQ5cqU5NG7YOfrDOzU6XNuo4fmZ+tSFBdp9+KT+fPSkms745EpzKD87XScbz8iVliabXRqUk6Fqb6PerT4tb4tPbmeaLijIkSPNoaaWNkmGms/4VH6krs96/digLDnTHWr1+ZWd4ZDfMFTtbVbjGZ8yHHa1nPGFtfrrM1+ZGHLLXl9YXr0brW1+/WLnoQ93mO6vzIiPWGkJdiQn9sHExOcSG9Gs19Y2vy787sshjReM5ucUzvk7Jc6+ZRsrNPp7L+sHL72tn+88rB+89LZGf+9llW2siHdoCSvQRy2py/oFqTyFFeZhH0xMfC6xEc16zUiz62vTivssF8/PyfLJR9nGCv1ke2WXayv4Dekn2ytJQHrBFFbEG/tgYuJziY1o1uuSq0t0x7Tibhe/y3Y64jLOoyNLd7u0tvk1+nsv93pRp7OvnImuku1S8kg8TU1N+vSnPy1Jevnll5WZ2f0g8J6wDyYmPpfYiGa9trb59fQbldp96KSyMxz63NihXaajRwtjPj700x0H9YOX+r6y7ffmXKSvTB3Zr9cC0LOGhgbl5ORIkk6fPh0ccArAOhjz8aHDtaFdsyXUcgAAoP8snXwMz8+KajkAANB/lk4+bpk0Qn11a9lt7eUAAIA5LJ18ZKTZdfvU3qcb3T61mMGmAACYyNLXdpHapxtJ0hM7Ok+3tdvaE4/A/QAAwByWTz6k9gTkW7NGs8IpEEdZWYytAtAuJZIPqb0Lhum0QHxkZ2eroaEh3mEASBAx++n/6KOPqri4WC6XS+PGjdOOHTti9VIAACCJxCT5ePbZZ7Vw4ULdf//92rt3r6ZOnapPf/rTev/992PxcgAAIInEZIXTiRMnauzYsVq7dm1w20UXXaTrrrtOZWVlvT42Vle1BRA/zc3N+vznPy9Jev755+Vyufp4BIBkE875O+pjPlpbW7Vnzx4tXry40/ZZs2bpjTfeiPbLAUgCPp9PGzduDN4GkNqinnwcP35cPp9PBQUFnbYXFBSourq6S/mWlha1tLQE/6+rq4t2SAAAIIHEbMCpzdZ5aVHDMLpsk6SysjK53e7g37Bhw2IVEgAASABRTz4GDRokh8PRpZWjpqamS2uIJC1ZskRerzf4d+TIkWiHBAAAEkjUk4+MjAyNGzdOW7Zs6bR9y5Ytmjx5cpfyTqdTeXl5nf4AAIB1xWSRsXvvvVe33HKLxo8fr0mTJunxxx/X+++/rzvvvDMWLwcAAJJITJKPL3zhCzpx4oQeeOABVVVVqbS0VBs3btTw4cP7fGxg5i8DTwHr6Li6aV1dHTNeAAsKnLdDWcEjJut89MfRo0cZdAoAQJI6cuSIhg4d2muZhEs+/H6/jh07ptzc3G5nx/RHXV2dhg0bpiNHjjC2JIaoZ3NQz7FHHZuDejZHrOvZMAzV19erqKhIdnvvQ0oT7sJydru9z4ypvxjYag7q2RzUc+xRx+agns0Ry3p2u90hleOa8gAAwFQkHwAAwFQplXw4nU4tXbpUTqcz3qFYGvVsDuo59qhjc1DP5kikek64AacAAMDaUqrlAwAAxB/JBwAAMBXJBwAAMBXJBwAAMJXlko9HH31UxcXFcrlcGjdunHbs2NFr+W3btmncuHFyuVwaOXKkHnvsMZMiTW7h1PNvf/tbzZw5U4MHD1ZeXp4mTZqkV155xcRok1O4+3LA66+/rrS0NF166aWxDdAiwq3nlpYW3X///Ro+fLicTqfOP/98/exnPzMp2uQVbj0/88wzuuSSS5SVlaXCwkL9y7/8i06cOGFStMln+/btmjt3roqKimSz2fTf//3ffT4mruc/w0J+9atfGenp6cYTTzxhVFRUGHfffbeRnZ1tHD58uNvyBw8eNLKysoy7777bqKioMJ544gkjPT3d+M1vfmNy5Mkl3Hq+++67jZUrVxq7du0y3n33XWPJkiVGenq6UV5ebnLkySPcOg44deqUMXLkSGPWrFnGJZdcYk6wSSySer7mmmuMiRMnGlu2bDEqKyuNP/3pT8brr79uYtTJJ9x63rFjh2G3243/+q//Mg4ePGjs2LHDGDNmjHHdddeZHHny2Lhxo3H//fcbzz//vCHJeOGFF3otH+/zn6WSjwkTJhh33nlnp22jR482Fi9e3G35RYsWGaNHj+607Y477jA+8YlPxCxGKwi3nrtTUlJiLF++PNqhWUakdfyFL3zB+O53v2ssXbqU5CME4dbzyy+/bLjdbuPEiRNmhGcZ4dbzQw89ZIwcObLTth/96EfG0KFDYxajlYSSfMT7/GeZbpfW1lbt2bNHs2bN6rR91qxZeuONN7p9zM6dO7uUv+qqq/TWW2/pzJkzMYs1mUVSz2fz+/2qr69Xfn5+LEJMepHW8ZNPPqn33ntPS5cujXWIlhBJPb/44osaP368Vq1apXPPPVcXXHCBvv3tb6upqcmMkJNSJPU8efJkHT16VBs3bpRhGPq///s//eY3v9GcOXPMCDklxPv8l3AXlovU8ePH5fP5VFBQ0Gl7QUGBqquru31MdXV1t+Xb2tp0/PhxFRYWxizeZBVJPZ/t4YcfVkNDg2688cZYhJj0Iqnj//3f/9XixYu1Y8cOpaVZ5msdU5HU88GDB/Xaa6/J5XLphRde0PHjxzV//nzV1tYy7qMHkdTz5MmT9cwzz+gLX/iCmpub1dbWpmuuuUY//vGPzQg5JcT7/GeZlo8Am83W6X/DMLps66t8d9vRWbj1HPDLX/5Sy5Yt07PPPqshQ4bEKjxLCLWOfT6fbrrpJi1fvlwXXHCBWeFZRjj7st/vl81m0zPPPKMJEybo6quv1urVq/XUU0/R+tGHcOq5oqJC3/zmN/X9739fe/bs0aZNm1RZWak777zTjFBTRjzPf5b5iTRo0CA5HI4umXRNTU2X7C7A4/F0Wz4tLU0DBw6MWazJLJJ6Dnj22Wf1la98Rc8995yuvPLKWIaZ1MKt4/r6er311lvau3evvv71r0tqP0kahqG0tDRt3rxZV1xxhSmxJ5NI9uXCwkKde+65nS4bftFFF8kwDB09elSjRo2KaczJKJJ6Lisr05QpU/Sd73xHknTxxRcrOztbU6dO1b/927/RKh0F8T7/WablIyMjQ+PGjdOWLVs6bd+yZYsmT57c7WMmTZrUpfzmzZs1fvx4paenxyzWZBZJPUvtLR633Xab1q9fT79tH8Kt47y8PP31r3/Vvn37gn933nmnLrzwQu3bt08TJ040K/SkEsm+PGXKFB07dkynT58Obnv33Xdlt9s1dOjQmMabrCKp58bGRtntnU9PDodD0ke/ztE/cT//mTKs1SSB6Vw//elPjYqKCmPhwoVGdna2cejQIcMwDGPx4sXGLbfcEiwfmGp0zz33GBUVFcZPf/pTptqGINx6Xr9+vZGWlmY88sgjRlVVVfDv1KlT8XoLCS/cOj4bs11CE24919fXG0OHDjWuv/5648CBA8a2bduMUaNGGV/96lfj9RaSQrj1/OSTTxppaWnGo48+arz33nvGa6+9ZowfP96YMGFCvN5Cwquvrzf27t1r7N2715BkrF692ti7d29wOnOinf8slXwYhmE88sgjxvDhw42MjAxj7NixxrZt24L33Xrrrcb06dM7ld+6datx2WWXGRkZGcaIESOMtWvXmhxxcgqnnqdPn25I6vJ36623mh94Egl3X+6I5CN04dbz22+/bVx55ZVGZmamMXToUOPee+81GhsbTY46+YRbzz/60Y+MkpISIzMz0ygsLDRuvvlm4+jRoyZHnTxeffXVXo+ziXb+sxkGbVgAAMA8lhnzAQAAkgPJBwAAMBXJBwAAMBXJBwAAMBXJBwAAMBXJBwAAMBXJBwAAMBXJBwAAMBXJBwAAMBXJBwAAMBXJBwAAMBXJBwAAMNX/B4NXRlzIp28LAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(osc_score_all, n_neurons_mini )\n",
    "plt.axvline(x=0.5,c='k',ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024, 4604, 1001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x700e45586ad0>,\n",
       " <matplotlib.lines.Line2D at 0x700e64e01890>,\n",
       " <matplotlib.lines.Line2D at 0x700e64e03790>,\n",
       " <matplotlib.lines.Line2D at 0x700e64ff3b50>,\n",
       " <matplotlib.lines.Line2D at 0x700e64e03f90>,\n",
       " <matplotlib.lines.Line2D at 0x700e64e10390>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 9\n",
    "plt.plot(results[0,n,min_circuit[n]].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49949652\n",
      "0.499279\n",
      "0.16256762\n",
      "0.23966448\n",
      "0.49967083\n",
      "0.0\n",
      "0.49933738\n",
      "0.21912007\n",
      "0.43483755\n",
      "0.49824634\n",
      "0.49943382\n",
      "0.208418\n",
      "0.49843386\n",
      "0.49899223\n",
      "0.0\n",
      "0.49852532\n",
      "0.48537502\n",
      "0.4008642\n",
      "0.49889615\n",
      "0.4985739\n",
      "0.49905136\n",
      "0.4520758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3512079/2413706698.py:10: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axs = plt.subplots(1,3, figsize=(18, 6))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39297423\n",
      "0.49921238\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.10841509\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3931809\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4753139\n",
      "0.31009588\n",
      "0.0\n",
      "0.45856804\n",
      "0.4985162\n",
      "0.49649143\n",
      "0.49801844\n",
      "0.45881352\n",
      "0.4981954\n",
      "0.4981259\n",
      "0.49949148\n",
      "0.49832037\n",
      "0.0\n",
      "0.3834647\n",
      "0.0\n",
      "0.41936263\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3028941\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12709789\n",
      "0.121000275\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04016412\n",
      "0.0\n",
      "0.0\n",
      "0.22171937\n",
      "0.2765023\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0300802\n",
      "0.16260664\n",
      "0.0\n",
      "0.30829886\n",
      "0.0\n",
      "0.0\n",
      "0.056725375\n",
      "0.11421431\n",
      "0.24252735\n",
      "0.0\n",
      "0.0\n",
      "0.4726712\n",
      "0.0\n",
      "0.0\n",
      "0.306064\n",
      "0.16582863\n",
      "0.0\n",
      "0.05823619\n",
      "0.33847177\n",
      "0.0\n",
      "0.06730034\n",
      "0.029685313\n",
      "0.20184675\n",
      "0.0\n",
      "0.0\n",
      "0.16382498\n",
      "0.075210854\n",
      "0.061827753\n",
      "0.056185097\n",
      "0.0\n",
      "0.0\n",
      "0.23180923\n",
      "0.0\n",
      "0.16160214\n",
      "0.0\n",
      "0.0\n",
      "0.057285942\n",
      "0.18083012\n",
      "0.05400975\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.06538169\n",
      "0.0\n",
      "0.05839609\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.41337052\n",
      "0.45746967\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.30966038\n",
      "0.0\n",
      "0.0\n",
      "0.43907145\n",
      "0.0\n",
      "0.49782616\n",
      "0.4992728\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.49871832\n",
      "0.0\n",
      "0.49817997\n",
      "0.4978408\n",
      "0.49915475\n",
      "0.4950146\n",
      "0.49928063\n",
      "0.4987231\n",
      "0.29332855\n",
      "0.4981515\n",
      "0.49939552\n",
      "0.49937668\n",
      "0.0\n",
      "0.49913603\n",
      "0.0\n",
      "0.49906772\n",
      "0.29995817\n",
      "0.4998565\n",
      "0.49874097\n",
      "0.4996765\n",
      "0.0\n",
      "0.35655096\n",
      "0.0\n",
      "0.4995645\n",
      "0.49916756\n",
      "0.0\n",
      "0.4410139\n",
      "0.4993802\n",
      "0.0\n",
      "0.49949944\n",
      "0.4977489\n",
      "0.0\n",
      "0.49899346\n",
      "0.49822748\n",
      "0.0\n",
      "0.0\n",
      "0.4996085\n",
      "0.4998069\n",
      "0.0\n",
      "0.0\n",
      "0.49938118\n",
      "0.4990574\n",
      "0.4997663\n",
      "0.0\n",
      "0.0\n",
      "0.16393974\n",
      "0.4993647\n",
      "0.49975738\n",
      "0.0\n",
      "0.0\n",
      "0.49978805\n",
      "0.0\n",
      "0.48588502\n",
      "0.49849665\n",
      "0.49863502\n",
      "0.4995907\n",
      "0.499107\n",
      "0.4992439\n",
      "0.49899685\n",
      "0.0\n",
      "0.49704027\n",
      "0.49877807\n",
      "0.0\n",
      "0.49819162\n",
      "0.23193423\n",
      "0.4025112\n",
      "0.48909548\n",
      "0.49844518\n",
      "0.4934931\n",
      "0.49874833\n",
      "0.49880227\n",
      "0.3048637\n",
      "0.49972707\n",
      "0.49925616\n",
      "0.1161173\n",
      "0.17843954\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m nonmns_idxs = w_table.loc[(w_table[\u001b[33m\"\u001b[39m\u001b[33mbodyId\u001b[39m\u001b[33m\"\u001b[39m]==\u001b[32m10093\u001b[39m) | (w_table[\u001b[33m\"\u001b[39m\u001b[33mbodyId\u001b[39m\u001b[33m\"\u001b[39m]==\u001b[32m10707\u001b[39m) | (w_table[\u001b[33m\"\u001b[39m\u001b[33mbodyId\u001b[39m\u001b[33m\"\u001b[39m]==\u001b[32m11751\u001b[39m) | (w_table[\u001b[33m\"\u001b[39m\u001b[33mbodyId\u001b[39m\u001b[33m\"\u001b[39m]==\u001b[32m13905\u001b[39m)].index\n\u001b[32m      8\u001b[39m mn_idxs = jnp.asarray(w_table.loc[w_table[\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m]==\u001b[33m\"\u001b[39m\u001b[33mmotor neuron\u001b[39m\u001b[33m\"\u001b[39m].index.values)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m fig, axs = plt.subplots(\u001b[32m1\u001b[39m,\u001b[32m3\u001b[39m, figsize=(\u001b[32m18\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nonmns_idxs:\n\u001b[32m     12\u001b[39m     axs[\u001b[32m0\u001b[39m].plot(R[i])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/pyplot.py:1776\u001b[39m, in \u001b[36msubplots\u001b[39m\u001b[34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[39m\n\u001b[32m   1631\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1632\u001b[39m \u001b[33;03mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[32m   1633\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1773\u001b[39m \n\u001b[32m   1774\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1775\u001b[39m fig = figure(**fig_kw)\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[32m   1777\u001b[39m                    squeeze=squeeze, subplot_kw=subplot_kw,\n\u001b[32m   1778\u001b[39m                    gridspec_kw=gridspec_kw, height_ratios=height_ratios,\n\u001b[32m   1779\u001b[39m                    width_ratios=width_ratios)\n\u001b[32m   1780\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/figure.py:919\u001b[39m, in \u001b[36mFigureBase.subplots\u001b[39m\u001b[34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[39m\n\u001b[32m    916\u001b[39m     gridspec_kw[\u001b[33m'\u001b[39m\u001b[33mwidth_ratios\u001b[39m\u001b[33m'\u001b[39m] = width_ratios\n\u001b[32m    918\u001b[39m gs = \u001b[38;5;28mself\u001b[39m.add_gridspec(nrows, ncols, figure=\u001b[38;5;28mself\u001b[39m, **gridspec_kw)\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m axs = gs.subplots(sharex=sharex, sharey=sharey, squeeze=squeeze,\n\u001b[32m    920\u001b[39m                   subplot_kw=subplot_kw)\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m axs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/gridspec.py:283\u001b[39m, in \u001b[36mGridSpecBase.subplots\u001b[39m\u001b[34m(self, sharex, sharey, squeeze, subplot_kw)\u001b[39m\n\u001b[32m    281\u001b[39m         subplot_kw[\u001b[33m\"\u001b[39m\u001b[33msharex\u001b[39m\u001b[33m\"\u001b[39m] = shared_with[sharex]\n\u001b[32m    282\u001b[39m         subplot_kw[\u001b[33m\"\u001b[39m\u001b[33msharey\u001b[39m\u001b[33m\"\u001b[39m] = shared_with[sharey]\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m         axarr[row, col] = figure.add_subplot(\n\u001b[32m    284\u001b[39m             \u001b[38;5;28mself\u001b[39m[row, col], **subplot_kw)\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# turn off redundant tick labeling\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sharex \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcol\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/figure.py:768\u001b[39m, in \u001b[36mFigureBase.add_subplot\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    766\u001b[39m         args = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m(args[\u001b[32m0\u001b[39m])))\n\u001b[32m    767\u001b[39m     projection_class, pkw = \u001b[38;5;28mself\u001b[39m._process_projection_requirements(**kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     ax = projection_class(\u001b[38;5;28mself\u001b[39m, *args, **pkw)\n\u001b[32m    769\u001b[39m     key = (projection_class, pkw)\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._add_axes_internal(ax, key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/axes/_base.py:696\u001b[39m, in \u001b[36m_AxesBase.__init__\u001b[39m\u001b[34m(self, fig, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, forward_navigation_events, *args, **kwargs)\u001b[39m\n\u001b[32m    693\u001b[39m \u001b[38;5;28mself\u001b[39m.set_axisbelow(mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33maxes.axisbelow\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    695\u001b[39m \u001b[38;5;28mself\u001b[39m._rasterization_zorder = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m.clear()\n\u001b[32m    698\u001b[39m \u001b[38;5;66;03m# funcs used to format x and y - fall back on major formatters\u001b[39;00m\n\u001b[32m    699\u001b[39m \u001b[38;5;28mself\u001b[39m.fmt_xdata = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/axes/_base.py:1416\u001b[39m, in \u001b[36m_AxesBase.clear\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1414\u001b[39m     \u001b[38;5;28mself\u001b[39m.cla()\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m     \u001b[38;5;28mself\u001b[39m.__clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/axes/_base.py:1332\u001b[39m, in \u001b[36m_AxesBase.__clear\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1329\u001b[39m \u001b[38;5;28mself\u001b[39m.legend_ = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1330\u001b[39m \u001b[38;5;28mself\u001b[39m.containers = []\n\u001b[32m-> \u001b[39m\u001b[32m1332\u001b[39m \u001b[38;5;28mself\u001b[39m.grid(\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Disable grid on init to use rcParameter\u001b[39;00m\n\u001b[32m   1333\u001b[39m \u001b[38;5;28mself\u001b[39m.grid(\u001b[38;5;28mself\u001b[39m._gridOn, which=mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33maxes.grid.which\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   1334\u001b[39m           axis=mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33maxes.grid.axis\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m   1335\u001b[39m props = font_manager.FontProperties(\n\u001b[32m   1336\u001b[39m     size=mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33maxes.titlesize\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   1337\u001b[39m     weight=mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33maxes.titleweight\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/axes/_base.py:3312\u001b[39m, in \u001b[36m_AxesBase.grid\u001b[39m\u001b[34m(self, visible, which, axis, **kwargs)\u001b[39m\n\u001b[32m   3310\u001b[39m _api.check_in_list([\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m], axis=axis)\n\u001b[32m   3311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m-> \u001b[39m\u001b[32m3312\u001b[39m     \u001b[38;5;28mself\u001b[39m.xaxis.grid(visible, which=which, **kwargs)\n\u001b[32m   3313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m   3314\u001b[39m     \u001b[38;5;28mself\u001b[39m.yaxis.grid(visible, which=which, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/axis.py:1746\u001b[39m, in \u001b[36mAxis.grid\u001b[39m\u001b[34m(self, visible, which, **kwargs)\u001b[39m\n\u001b[32m   1743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m which \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mmajor\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m   1744\u001b[39m     gridkw[\u001b[33m'\u001b[39m\u001b[33mgridOn\u001b[39m\u001b[33m'\u001b[39m] = (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._major_tick_kw[\u001b[33m'\u001b[39m\u001b[33mgridOn\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m   1745\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m visible \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m visible)\n\u001b[32m-> \u001b[39m\u001b[32m1746\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_tick_params(which=\u001b[33m'\u001b[39m\u001b[33mmajor\u001b[39m\u001b[33m'\u001b[39m, **gridkw)\n\u001b[32m   1747\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/axis.py:986\u001b[39m, in \u001b[36mAxis.set_tick_params\u001b[39m\u001b[34m(self, which, reset, **kwargs)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m which \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mmajor\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    985\u001b[39m     \u001b[38;5;28mself\u001b[39m._major_tick_kw.update(kwtrans)\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.majorTicks:\n\u001b[32m    987\u001b[39m         tick._apply_params(**kwtrans)\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m which \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mminor\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/axis.py:547\u001b[39m, in \u001b[36m_LazyTickList.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._major:\n\u001b[32m    546\u001b[39m     instance.majorTicks = []\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     tick = instance._get_tick(major=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    548\u001b[39m     instance.majorTicks = [tick]\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m instance.majorTicks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/axis.py:1603\u001b[39m, in \u001b[36mAxis._get_tick\u001b[39m\u001b[34m(self, major)\u001b[39m\n\u001b[32m   1599\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   1600\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe Axis subclass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must define \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1601\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_tick_class or reimplement _get_tick()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1602\u001b[39m tick_kw = \u001b[38;5;28mself\u001b[39m._major_tick_kw \u001b[38;5;28;01mif\u001b[39;00m major \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._minor_tick_kw\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tick_class(\u001b[38;5;28mself\u001b[39m.axes, \u001b[32m0\u001b[39m, major=major, **tick_kw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/axis.py:379\u001b[39m, in \u001b[36mXTick.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;66;03m# the y loc is 3 points below the min of y axis\u001b[39;00m\n\u001b[32m    378\u001b[39m trans, va, ha = \u001b[38;5;28mself\u001b[39m._get_text1_transform()\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m \u001b[38;5;28mself\u001b[39m.label1.set(\n\u001b[32m    380\u001b[39m     x=\u001b[32m0\u001b[39m, y=\u001b[32m0\u001b[39m,\n\u001b[32m    381\u001b[39m     verticalalignment=va, horizontalalignment=ha, transform=trans,\n\u001b[32m    382\u001b[39m )\n\u001b[32m    383\u001b[39m trans, va, ha = \u001b[38;5;28mself\u001b[39m._get_text2_transform()\n\u001b[32m    384\u001b[39m \u001b[38;5;28mself\u001b[39m.label2.set(\n\u001b[32m    385\u001b[39m     x=\u001b[32m0\u001b[39m, y=\u001b[32m1\u001b[39m,\n\u001b[32m    386\u001b[39m     verticalalignment=va, horizontalalignment=ha, transform=trans,\n\u001b[32m    387\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/artist.py:146\u001b[39m, in \u001b[36mArtist.__init_subclass__.<locals>.<lambda>\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m.set, \u001b[33m'\u001b[39m\u001b[33m_autogenerated_signature\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[32m    142\u001b[39m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28mcls\u001b[39m.set = \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, **kwargs: Artist.set(\u001b[38;5;28mself\u001b[39m, **kwargs)\n\u001b[32m    147\u001b[39m \u001b[38;5;28mcls\u001b[39m.set.\u001b[34m__name__\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28mcls\u001b[39m.set.\u001b[34m__qualname__\u001b[39m = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.set\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/artist.py:1241\u001b[39m, in \u001b[36mArtist.set\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m   1238\u001b[39m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[32m   1239\u001b[39m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._internal_update(cbook.normalize_kwargs(kwargs, \u001b[38;5;28mself\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/vnc-closedloop/lib/python3.11/site-packages/matplotlib/cbook.py:1793\u001b[39m, in \u001b[36mnormalize_kwargs\u001b[39m\u001b[34m(kw, alias_mapping)\u001b[39m\n\u001b[32m   1790\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot both \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcanonical_to_seen[canonical]\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1791\u001b[39m                         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m, which are aliases of one another\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1792\u001b[39m     canonical_to_seen[canonical] = k\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m     ret[canonical] = v\n\u001b[32m   1795\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "check_ind = jnp.where(osc_score_all<0.5)[0]\n",
    "# for n in range(len(check_ind)):\n",
    "for n in range(10):\n",
    "    R = results[0][check_ind[n]]\n",
    "    print(osc_score_all[check_ind[n]])\n",
    "    w_table = pd.read_csv(cfg.experiment.dfPath,index_col=0)\n",
    "    # 10093 = bdn2, 10707 = exc 1, 11751 = exc 2, 13905 = inh 1\n",
    "    nonmns_idxs = w_table.loc[(w_table[\"bodyId\"]==10093) | (w_table[\"bodyId\"]==10707) | (w_table[\"bodyId\"]==11751) | (w_table[\"bodyId\"]==13905)].index\n",
    "    mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "\n",
    "    fig, axs = plt.subplots(1,3, figsize=(18, 6))\n",
    "    for i in nonmns_idxs:\n",
    "        axs[0].plot(R[i])\n",
    "    axs[0].set_title(\"Non-Motor Neurons\")\n",
    "    for i in mn_idxs:\n",
    "        axs[1].plot(R[i])\n",
    "    axs[1].set_title(\"Motor Neurons\")\n",
    "\n",
    "\n",
    "# scores001 = []\n",
    "# for i in range(results.shape[1]):\n",
    "#     R = results[0][i]\n",
    "#     max_frs = jnp.max(R, axis=-1)\n",
    "#     active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "#     activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "#     score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "#     scores001.append(score)\n",
    "# scores001 = jnp.concatenate(scores001, axis=-1)\n",
    "# axs[2].hist(scores001, bins=50, density=True)\n",
    "# plt.savefig(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=Testing/sim.noise=True/figures/Example_R.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.sim_utils import compute_oscillation_score, neuron_oscillation_score\n",
    "clip_start = 250# int(sim_params.pulse_start / sim_params.dt) + 200\n",
    "def compute_osc_score_all(R, mn_mask, clip_start=250):\n",
    "    # Get active MN activity using JAX-compatible approach\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mask = ((max_frs > 0) & mn_mask)\n",
    "\n",
    "    # Compute oscillation score\n",
    "    oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "    return oscillation_score\n",
    "\n",
    "\n",
    "# osc_score_all = osc_vmap(results[0], mn_mask, clip_start)\n",
    "osc_score_all = []\n",
    "for replicate in tqdm(range(results.shape[1])):\n",
    "    osc_score = compute_osc_score_all(results[0,replicate], mn_mask, clip_start=clip_start)\n",
    "    osc_score_all.append(osc_score)\n",
    "osc_score_all = jnp.array(osc_score_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape, active_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "\n",
    "scores001 = []\n",
    "for i in range(results001.shape[1]):\n",
    "    R = results001[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores001.append(score)\n",
    "scores01 = []\n",
    "for i in range(results01.shape[1]):\n",
    "    R = results01[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores01.append(score)\n",
    "scores1 = []\n",
    "for i in range(results1.shape[1]):\n",
    "    R = results1[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores1.append(score)\n",
    "scores10 = []\n",
    "for i in range(results10.shape[1]):\n",
    "    R = results10[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores10.append(score)\n",
    "    \n",
    "    \n",
    "    \n",
    "# score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "# print(f\"Score: {jnp.nanmean(score)}, Frequency: {jnp.nanmean(frequency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "axs[0].hist(jnp.concatenate(scores001, axis=-1), bins=25)\n",
    "axs[0].set_xlabel(\"Oscillation Score\")\n",
    "axs[0].set_title(\"Noise=0.01\")\n",
    "axs[1].hist(jnp.concatenate(scores01, axis=-1), bins=25)\n",
    "axs[1].set_xlabel(\"Oscillation Score\")\n",
    "axs[1].set_title(\"Noise=0.1\")\n",
    "axs[2].hist(jnp.concatenate(scores1, axis=-1), bins=25)\n",
    "axs[2].set_xlabel(\"Oscillation Score\")\n",
    "axs[2].set_title(\"Noise=1\")\n",
    "axs[3].hist(jnp.concatenate(scores10, axis=-1), bins=25)\n",
    "axs[3].set_xlabel(\"Oscillation Score\")\n",
    "axs[3].set_title(\"Noise=10\")\n",
    "plt.savefig(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=noisy_inputs/figures/oscillation_scores.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, config = load_vnc_net(cfg)\n",
    "simulator = OptimizedSimulator(params, config)\n",
    "# W, W_table = load_connectivity(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_queue = simulator._create_work_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.shuffle_utils import shuffle_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newkey, key = jax.random.split(work_queue[0]['seed'])\n",
    "idxs = params.inh_dn_idxs\n",
    "W = params.W\n",
    "W_shuff = shuffle_W(W, key, idxs, independent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.all(np.sum(results,axis=-1)==0,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[0][0]\n",
    "\n",
    "\n",
    "wTable = pd.read_csv(\"../data/manc t1 connectome data/wTable_20231020_DNtoMN_unsorted_withModules.csv\",index_col=0)\n",
    "nonMns = wTable.loc[(wTable[\"bodyId\"]==10093) | (wTable[\"bodyId\"]==10707) | (wTable[\"bodyId\"]==13905) | (wTable[\"bodyId\"]==11751)]\n",
    "mnIdxs = wTable.loc[wTable[\"class\"]==\"motor neuron\"].index\n",
    "\n",
    "\n",
    "for i in nonMns.index:\n",
    "# for i in mnIdxs:\n",
    "    plt.plot(R[i])\n",
    "    #plt.plot(Rtsp[i])\n",
    "\n",
    "print(np.mean(R))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing osc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_Rs.npz\").todense().astype(np.float32)\n",
    "\n",
    "wTable = pd.read_csv(\"../data/manc t1 connectome data/wTable_20231020_DNtoMN_unsorted_withModules.csv\",index_col=0)\n",
    "non_mns = (wTable.loc[(wTable[\"bodyId\"]==10093) | (wTable[\"bodyId\"]==10707) | (wTable[\"bodyId\"]==13905) | (wTable[\"bodyId\"]==11751)]).values\n",
    "mn_idxs = wTable.loc[wTable[\"class\"]==\"motor neuron\"].index.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "def neuron_oscillation_score_helper_old(activity,prominence):\n",
    "    activity = activity-np.min(activity)\n",
    "    activity = 2 * activity/np.max(activity) - 1\n",
    "\n",
    "    autocorr = np.correlate(activity,activity,mode=\"full\") / np.inner(activity,activity)\n",
    "    lags = signal.correlation_lags(len(activity),len(activity))\n",
    "    autocorr = autocorr[lags>0]\n",
    "    lags = lags[lags>0]\n",
    "\n",
    "    peaks, peakProperties = signal.find_peaks(autocorr,height=(None,None),prominence=prominence)\n",
    "    if len(peaks) > 0:\n",
    "        score = np.min([np.max(peakProperties[\"peak_heights\"]),np.max(peakProperties[\"prominences\"])])\n",
    "        frequency = 1 / peaks[np.argmax(peakProperties[\"prominences\"])]\n",
    "    else:\n",
    "        score = 0\n",
    "        frequency = 0\n",
    "\n",
    "    return score, frequency\n",
    "\n",
    "def neuron_oscillation_score_old(activity, returnFrequency=False,prominence=0.05):\n",
    "    rawScore, frequency = neuron_oscillation_score_helper_old(activity,prominence)\n",
    "    # normalize to sine wave of the same frequency and duration\n",
    "    if rawScore == 0:\n",
    "        score = 0\n",
    "    else:\n",
    "        refSinScore, _ = neuron_oscillation_score_helper_old(np.sin(2*np.pi*frequency*np.arange(len(activity))),prominence)\n",
    "        refCosScore, _ = neuron_oscillation_score_helper_old(np.cos(2*np.pi*frequency*np.arange(len(activity))),prominence)\n",
    "        refScore = np.max((refSinScore,refCosScore))\n",
    "        score = rawScore / refScore\n",
    "\n",
    "    if returnFrequency:\n",
    "        return score, frequency\n",
    "    else:\n",
    "        return score\n",
    "\n",
    "def sim_oscillation_score_old(R,activeMnIdxs,start=None,end=None,returnFrequency=False):\n",
    "    \"\"\"calculate oscillation score for a simulation\"\"\"\n",
    "    if start is None:\n",
    "        start = 0\n",
    "    if end is None:\n",
    "        end = -1\n",
    "\n",
    "    if returnFrequency:\n",
    "        neuronOscillationScores = []\n",
    "        frequencies = []\n",
    "\n",
    "        for j in activeMnIdxs:\n",
    "            score, freq = neuron_oscillation_score_old(R[j][start:end],returnFrequency=True)\n",
    "            neuronOscillationScores.append(score)\n",
    "            frequencies.append(freq)\n",
    "        return np.mean(neuronOscillationScores), np.nanmean(frequencies)\n",
    "        \n",
    "    else:\n",
    "        neuronOscillationScores = [neuron_oscillation_score_old(R[j][start:end]) for j in activeMnIdxs] # scores for each neuron\n",
    "        return np.mean(neuronOscillationScores) # average for the simulation\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[0][0]\n",
    "np_R = np.asarray(R)\n",
    "maxFrs = np.max(np_R,axis=-1)\n",
    "activeMnIdxs = mn_idxs[maxFrs[mn_idxs]>0]\n",
    "plt.plot(np_R[activeMnIdxs].T)\n",
    "plt.show()\n",
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 200\n",
    "print(f\"Start index: {start}\")\n",
    "score, freq = sim_oscillation_score_old(R,activeMnIdxs,start=start,end=None,returnFrequency=True)\n",
    "print(f\"Score: {score}, Frequency: {freq}\")\n",
    "\n",
    "##### New Method #####\n",
    "# R = results[0][0]\n",
    "\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "\n",
    "score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "\n",
    "print(f\"Score: {jnp.nanmean(score)}, Frequency: {jnp.nanmean(frequency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "R = results\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[2]), mn_idxs)\n",
    "active_mask = ((max_frs > 0) & mn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.signal import correlate\n",
    "from src.utils.sim_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = results[0][1][451, start:]  # Adjusted to match the original code's start index\n",
    "\n",
    "activity = activity - jnp.min(activity, axis=-1, keepdims=True)\n",
    "activity = 2 * activity / jnp.max(activity, axis=-1, keepdims=True) - 1\n",
    "\n",
    "autocorr = autocorrelation_1d(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr_scipy = correlate(activity, activity, mode='full', method='fft')\n",
    "autocorr_scipy = autocorr_scipy/jnp.max(autocorr_scipy)\n",
    "autocorr_old = np.correlate(activity,activity,mode=\"full\") / np.inner(activity,activity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(autocorr, label='JAX Autocorrelation')\n",
    "plt.plot(autocorr_scipy, label='SciPy Autocorrelation')\n",
    "plt.plot(autocorr_old, label='Old NumPy Autocorrelation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.where(active_mask[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "R = results[0][0]\n",
    "\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "\n",
    "score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "\n",
    "print(f\"Score: {jnp.nanmean(score)}, Frequency: {jnp.nanmean(frequency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.sim_utils import neuron_oscillation_score\n",
    "\n",
    "experiment='prune_test'\n",
    "sim = 'prune_network'\n",
    "with initialize(version_base=None, config_path=\"../configs\"):\n",
    "    cfg=compose(config_name='config.yaml', overrides= [f\"experiment={experiment}\", f\"sim={sim}\", \"paths=glados\", \"version=debug\", f'run_id=Testing'],return_hydra_config=True,)\n",
    "    HydraConfig.instance().set_config(cfg)\n",
    "\n",
    "for k in cfg.paths.keys():\n",
    "    if (k != 'user'):\n",
    "        cfg.paths[k] = Path(cfg.paths[k])\n",
    "        cfg.paths[k].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def print_inds(arr, name=''):\n",
    "    print(f\"Indices for {name}: {jnp.where(arr)[0].shape}\")\n",
    "    return jnp.where(arr)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full pipeline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_table = load_wTable(cfg.experiment.dfPath)\n",
    "\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "\n",
    "# Prepare parameters\n",
    "neuron_params = prepare_neuron_params(cfg, W_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "sim_config = parse_simulation_config(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sims = sim_params.n_stim_configs * sim_params.n_param_sets\n",
    "n_devices = jax.device_count()\n",
    "\n",
    "# Calculate batch size\n",
    "batch_size = sim_config.batch_size\n",
    "if batch_size is None:\n",
    "    batch_size = calculate_optimal_batch_size(\n",
    "        sim_params.n_neurons, len(sim_params.t_axis), n_devices\n",
    "    )\n",
    "\n",
    "# Adjust batch size for multiple devices\n",
    "if n_devices > 1:\n",
    "    batch_size = (batch_size // n_devices) * n_devices\n",
    "    if batch_size == 0:\n",
    "        batch_size = n_devices\n",
    "\n",
    "# Get batch processing function\n",
    "batch_func = get_batch_function(sim_config)\n",
    "\n",
    "# Create parallel version for multiple devices\n",
    "if n_devices > 1:\n",
    "    batch_func = pmap(batch_func, axis_name=\"device\", in_axes=(None, None, 0))\n",
    "\n",
    "print(f\"Running {total_sims} {sim_config.sim_type} simulations with batch size {batch_size} on {n_devices} device(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pre-compute static values that won't change during the loop\n",
    "oscillation_threshold_val = float(sim_config.oscillation_threshold)\n",
    "clip_start_val = int(sim_params.pulse_start / sim_params.dt) + 200\n",
    "\n",
    "# Create a version of update_single_sim_state with static args baked in\n",
    "def update_state_with_static_args(state, R, mn_mask):\n",
    "    jax.debug.print(\"W_mask shape: {W_mask.shape}\", W_mask=state.W_mask)\n",
    "    return update_single_sim_state(state, R, mn_mask, oscillation_threshold_val, clip_start_val)\n",
    "\n",
    "# Apply JIT to the wrapper function (not the original)\n",
    "jitted_update = jax.jit(update_state_with_static_args)\n",
    "\n",
    "# Now vmap this wrapper with only the traced arguments\n",
    "batch_update = jax.vmap(\n",
    "    jitted_update, \n",
    "    in_axes=(0, 0, 0)  # state, R, mn_mask - all batched\n",
    ")\n",
    "\n",
    "# Create parallel versions for multiple devices\n",
    "if n_devices > 1:\n",
    "    batch_update = pmap(batch_update, axis_name=\"device\", in_axes=(0, 0, 0))\n",
    "\n",
    "# Rest of the function...\n",
    "all_results = []\n",
    "n_batches = (total_sims + batch_size - 1) // batch_size\n",
    "\n",
    "for i in range(n_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, total_sims)\n",
    "    actual_batch_size = end_idx - start_idx\n",
    "    \n",
    "    batch_indices = jnp.arange(start_idx, end_idx)\n",
    "    \n",
    "    # Pad batch_indices if necessary for pmap\n",
    "    if n_devices > 1 and len(batch_indices) < batch_size:\n",
    "        pad_size = batch_size - len(batch_indices)\n",
    "        batch_indices = jnp.concatenate([\n",
    "            batch_indices, \n",
    "            jnp.repeat(batch_indices[-1], pad_size)\n",
    "        ])\n",
    "    \n",
    "    mn_idxs = neuron_params.mn_idxs\n",
    "    \n",
    "    # Initialize state for this batch\n",
    "    current_batch_size = len(batch_indices)\n",
    "    state = initialize_pruning_state(neuron_params, sim_params, current_batch_size)\n",
    "\n",
    "    # Reshape state for pmap if using multiple devices\n",
    "    if n_devices > 1:\n",
    "        state = reshape_state_for_pmap(state, n_devices)\n",
    "        batch_indices = batch_indices.reshape(n_devices, -1)\n",
    "\n",
    "    # Main pruning loop\n",
    "    iteration = 0\n",
    "    \n",
    "    # Clear GPU memory before processing\n",
    "    jax.clear_caches()\n",
    "    \n",
    "    # while True:\n",
    "    # Check convergence condition\n",
    "    all_converged = jnp.all(state.min_circuit)\n",
    "    \n",
    "    if all_converged or (iteration >= sim_config.max_pruning_iterations):\n",
    "        break\n",
    "        \n",
    "    start_time = time.time()\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    \n",
    "    # Update neuron parameters W_mask based on the current state\n",
    "    if n_devices > 1:\n",
    "        flat_W_mask = reshape_state_from_pmap(state).W_mask\n",
    "        neuron_params = neuron_params._replace(W_mask=flat_W_mask)\n",
    "    else:\n",
    "        neuron_params = neuron_params._replace(W_mask=state.W_mask)\n",
    "\n",
    "    # Run simulation\n",
    "    batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "    \n",
    "    # Create mn_mask and broadcast to batch dimensions\n",
    "    mn_mask = jnp.isin(jnp.arange(sim_params.n_neurons), mn_idxs)\n",
    "    \n",
    "    if n_devices > 1:\n",
    "        # For pmap, broadcast to (n_devices, batch_per_device, n_neurons)\n",
    "        batch_per_device = batch_indices.shape[1]\n",
    "        mn_mask_batch = jnp.broadcast_to(mn_mask, (n_devices, batch_per_device, len(mn_mask)))\n",
    "    else:\n",
    "        # For single device, broadcast to (batch_size, n_neurons)\n",
    "        mn_mask_batch = jnp.broadcast_to(mn_mask, (batch_results.shape[0], len(mn_mask)))\n",
    "        \n",
    "    # Update state - now only passing traced arguments\n",
    "    print(\"Updating state with batch results\")\n",
    "    print(f\"W_mask shape: {state.W_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_pytree(neuron_params)\n",
    "# sim_config\n",
    "# print_pytree(batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.W_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscillation_threshold = 0.2\n",
    "# Load data (this part stays on CPU)\n",
    "w_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "## Initialize parameters\n",
    "neuron_params = prepare_neuron_params(cfg, w_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "all_neurons = w_table.index.to_numpy()\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "clip_start = int(cfg.sim.pulseStart / cfg.sim.dt) + 100\n",
    "\n",
    "total_sims = sim_params.n_stim_configs * sim_params.n_param_sets\n",
    "batch_size = getattr(cfg.experiment, \"batch_size\", None)\n",
    "if batch_size is None:\n",
    "    batch_size = calculate_optimal_batch_size(\n",
    "        sim_params.n_neurons, len(sim_params.t_axis)\n",
    "    )\n",
    "    \n",
    "batch_func = process_batch_prune\n",
    "# Create parallel version for multiple devices\n",
    "if jax.device_count() > 1:\n",
    "    batch_func = pmap(batch_func, axis_name=\"device\", in_axes=(None, None, 0))\n",
    "    batch_size = (batch_size // jax.device_count()) * jax.device_count()\n",
    "\n",
    "print(f\"Running {total_sims} simulations with batch size {batch_size}\")\n",
    "\n",
    "# Process in batches\n",
    "all_results = []\n",
    "n_batches = (total_sims + batch_size - 1) // batch_size\n",
    "\n",
    "# for i in range(n_batches):\n",
    "i = 0 \n",
    "start_idx = i * batch_size\n",
    "end_idx = min((i + 1) * batch_size, total_sims)\n",
    "\n",
    "batch_indices = jnp.arange(start_idx, end_idx)\n",
    "\n",
    "# Pad if necessary for pmap\n",
    "if jax.device_count() > 1 and len(batch_indices) < batch_size:\n",
    "    pad_size = batch_size - len(batch_indices)\n",
    "    batch_indices = jnp.concatenate([\n",
    "        batch_indices, \n",
    "        jnp.repeat(batch_indices[-1], pad_size)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mn_idxs = neuron_params.mn_idxs\n",
    "all_neurons = jnp.arange(neuron_params.W.shape[-1])\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "\n",
    "clip_start = int(sim_params.pulse_start / sim_params.dt) + 100\n",
    "# Initialize state\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "W_mask = jnp.full((n_sims, neuron_params.W.shape[0], neuron_params.W.shape[1]), 1, dtype=jnp.float32)\n",
    "interneuron_mask = jnp.full((n_sims, W_mask.shape[-1]),fill_value=False, dtype=jnp.bool_)\n",
    "interneuron_mask = interneuron_mask.at[:,in_idxs].set(True)\n",
    "level = jnp.zeros((n_sims,1), dtype=jnp.int32)\n",
    "total_removed_neurons = jnp.full((n_sims, W_mask.shape[-1]), False, dtype=jnp.bool)\n",
    "removed_stim_neurons = jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "neurons_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "prev_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "last_removed =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool) # Use False for None\n",
    "min_circuit = jnp.full((n_sims,1), False)\n",
    "\n",
    "# Initialize probabilities\n",
    "exclude_mask = (~interneuron_mask)\n",
    "p_arrays = jax.vmap(removal_probability)(jnp.ones(len(interneuron_mask)), exclude_mask)\n",
    "\n",
    "# initialize pruning state\n",
    "state = Pruning_state(\n",
    "    W_mask=W_mask,\n",
    "    interneuron_mask=interneuron_mask,\n",
    "    level=level,\n",
    "    total_removed_neurons=total_removed_neurons,\n",
    "    removed_stim_neurons=removed_stim_neurons,\n",
    "    neurons_put_back=neurons_put_back,\n",
    "    prev_put_back=prev_put_back,\n",
    "    last_removed=last_removed,\n",
    "    remove_p=p_arrays,\n",
    "    min_circuit=min_circuit,\n",
    "    keys=neuron_params.seeds\n",
    ")\n",
    "\n",
    "iter_start = 0  # Starting iteration\n",
    "# Main pruning loop\n",
    "iteration = iter_start\n",
    "max_iterations = 1  # Safety limit\n",
    "while not jnp.all(min_circuit) and (iteration < max_iterations):\n",
    "    start_time = time.time()\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    # Update neuron parameters W_mask based on the current state\n",
    "    neuron_params = neuron_params._replace(W_mask=state.W_mask)\n",
    "    # Run simulation (this would call your simulation function)\n",
    "    # Reshape for devices if using pmap\n",
    "    if jax.device_count() > 1:\n",
    "        batch_indices = batch_indices.reshape(jax.device_count(), -1)\n",
    "        batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "        batch_results = batch_results.reshape(-1, *batch_results.shape[2:])\n",
    "        batch_results = batch_results[:end_idx - start_idx]  # Remove padding\n",
    "    else:\n",
    "        batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "    \n",
    "    n = 0 \n",
    "    state = jax.vmap(update_single_sim_state, in_axes=(0, 0, None, None, None))(state, batch_results, mn_idxs, oscillation_threshold, clip_start)\n",
    "    iteration += 1\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  Total time: {elapsed:.2f} seconds\")\n",
    "\n",
    "# batch_results = jax.device_put(batch_results, jax.devices(\"cpu\")[0])\n",
    "# all_results.append(batch_results)\n",
    "# print(f\"Batch {i + 1}/{n_batches} completed\")\n",
    "\n",
    "# del batch_results  # Free memory\n",
    "# gc.collect()  # Force garbage collection\n",
    "\n",
    "# Combine results\n",
    "# results = jnp.concatenate(all_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mn_idxs = neuron_params.mn_idxs\n",
    "all_neurons = jnp.arange(neuron_params.W.shape[-1])\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "\n",
    "clip_start = int(sim_params.pulse_start / sim_params.dt) + 100\n",
    "# Initialize state\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "W_mask = jnp.full((n_sims, neuron_params.W.shape[0], neuron_params.W.shape[1]), 1, dtype=jnp.float32)\n",
    "interneuron_mask = jnp.full((n_sims, W_mask.shape[-1]),fill_value=False, dtype=jnp.bool_)\n",
    "interneuron_mask = interneuron_mask.at[:,in_idxs].set(True)\n",
    "level = jnp.zeros((n_sims,1), dtype=jnp.int32)\n",
    "total_removed_neurons = jnp.full((n_sims, W_mask.shape[-1]), False, dtype=jnp.bool)\n",
    "removed_stim_neurons = jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "neurons_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "prev_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "last_removed =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool) # Use False for None\n",
    "min_circuit = jnp.full((n_sims,1), False)\n",
    "\n",
    "# Initialize probabilities\n",
    "exclude_mask = (~interneuron_mask)\n",
    "p_arrays = jax.vmap(removal_probability)(jnp.ones(len(interneuron_mask)), exclude_mask)\n",
    "\n",
    "# initialize pruning state\n",
    "state = Pruning_state(\n",
    "    W_mask=W_mask[0],\n",
    "    interneuron_mask=interneuron_mask[0],\n",
    "    level=level[0],\n",
    "    total_removed_neurons=total_removed_neurons[0],\n",
    "    removed_stim_neurons=removed_stim_neurons[0],\n",
    "    neurons_put_back=neurons_put_back[0],\n",
    "    prev_put_back=prev_put_back[0],\n",
    "    last_removed=last_removed[0],\n",
    "    remove_p=p_arrays[0],\n",
    "    min_circuit=min_circuit[0],\n",
    "    keys=neuron_params.seeds[0],\n",
    ")\n",
    "R = batch_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unpack state\n",
    "(W_mask, interneuron_mask, level, total_removed_neurons, removed_stim_neurons,\n",
    "    neurons_put_back, last_removed, remove_p, min_circuit, key) = state\n",
    "\n",
    "# Get active MN activity using JAX-compatible approach\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "active_mask = ((max_frs>0) & mn_mask)\n",
    "\n",
    "# Compute oscillation score\n",
    "oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "\n",
    "# Check if oscillation is below threshold or NaN\n",
    "reset_condition = (oscillation_score < oscillation_threshold) | jnp.isnan(oscillation_score)\n",
    "\n",
    "# Identify currently silent interneurons (these will be permanently removed)\n",
    "silent_interneurons = interneuron_mask & (max_frs <= 0)\n",
    "\n",
    "key_next, subkey_continue, subkey_reset = random.split(key, 3)\n",
    "\n",
    "# === CONTINUE BRANCH: Normal pruning (oscillation is good) ===\n",
    "# Permanently remove silent interneurons\n",
    "total_removed_continue = total_removed_neurons | silent_interneurons\n",
    "\n",
    "# Update probabilities - exclude non-interneurons and removed neurons\n",
    "exclude_mask_continue = (~interneuron_mask) | total_removed_continue\n",
    "p_continue = removal_probability(max_frs, exclude_mask_continue)\n",
    "\n",
    "# Sample new neuron to remove (only from available interneurons)\n",
    "neuron_idx_continue = jax_choice(subkey_continue, jnp.arange(len(max_frs)), p_continue)\n",
    "\n",
    "# Update removed neurons\n",
    "removed_stim_continue = removed_stim_neurons.at[neuron_idx_continue].set(True)\n",
    "total_removed_continue = total_removed_continue.at[neuron_idx_continue].set(True)\n",
    "\n",
    "# Track what was removed this iteration (both silent and stimulated)\n",
    "newly_silent_continue = silent_interneurons & (~total_removed_neurons)  # Only newly silent\n",
    "last_removed_continue = jnp.full(last_removed.shape, False, dtype=jnp.bool_)\n",
    "last_removed_continue = last_removed_continue.at[neuron_idx_continue].set(True)  # Stimulated removal\n",
    "last_removed_continue = last_removed_continue | newly_silent_continue  # Add newly silent\n",
    "\n",
    "# Update other state\n",
    "level_continue = level + 1\n",
    "neurons_put_back_continue = neurons_put_back  # Unchanged\n",
    "min_circuit_continue = False  # Not converged yet\n",
    "\n",
    "# === RESET BRANCH: Restore last removed and try again ===\n",
    "# Restore ALL neurons from last_removed (both stimulated and those that went silent)\n",
    "# This includes neurons that went silent due to the last stimulated removal\n",
    "\n",
    "# Restore stimulated neurons from last removal\n",
    "removed_stim_reset = removed_stim_neurons & (~last_removed)\n",
    "\n",
    "# For total_removed: keep permanent removals from before last iteration, \n",
    "# add current silent neurons, but restore all last_removed neurons\n",
    "permanent_before_last = total_removed_neurons & (~last_removed)\n",
    "# Current silent neurons are those silent now (may include some that weren't silent before)\n",
    "# But we need to be careful not to restore neurons that are currently silent due to OTHER reasons\n",
    "# Only add neurons to total_removed if they are silent AND were not in last_removed\n",
    "currently_silent_not_restored = silent_interneurons & (~last_removed)\n",
    "total_removed_reset = permanent_before_last | currently_silent_not_restored\n",
    "\n",
    "# Track neurons being put back - ALL neurons from last_removed\n",
    "# This includes both the stimulated neuron and any neurons that went silent due to that removal\n",
    "restored_neurons = last_removed  # All neurons from last_removed are being restored\n",
    "neurons_put_back_reset = neurons_put_back | restored_neurons\n",
    "\n",
    "# Now select a different neuron to remove (avoid the restored ones)\n",
    "exclude_mask_reset = (~interneuron_mask) | total_removed_reset | restored_neurons\n",
    "p_reset = removal_probability(max_frs, exclude_mask_reset)\n",
    "\n",
    "# Check how many neurons are available\n",
    "available_neurons_reset = jnp.sum(interneuron_mask & (~exclude_mask_reset))\n",
    "\n",
    "# Select neuron to remove\n",
    "neuron_idx_reset = jax_choice(subkey_reset, jnp.arange(len(max_frs)), p_reset)\n",
    "\n",
    "# Only update if we have available neurons (otherwise keep current state)\n",
    "should_remove_new = available_neurons_reset > 0\n",
    "removed_stim_reset = jax.lax.select(\n",
    "    should_remove_new,\n",
    "    removed_stim_reset.at[neuron_idx_reset].set(True),\n",
    "    removed_stim_reset\n",
    ")\n",
    "total_removed_reset = jax.lax.select(\n",
    "    should_remove_new,\n",
    "    total_removed_reset.at[neuron_idx_reset].set(True),\n",
    "    total_removed_reset\n",
    ")\n",
    "\n",
    "# Track what was newly removed this iteration\n",
    "last_removed_reset = jnp.full(last_removed.shape, False, dtype=jnp.bool_)\n",
    "last_removed_reset = jax.lax.select(\n",
    "    should_remove_new,\n",
    "    last_removed_reset.at[neuron_idx_reset].set(True),\n",
    "    last_removed_reset\n",
    ")\n",
    "\n",
    "# Add any newly silent neurons (those that are silent now but weren't in total_removed_neurons before)\n",
    "# These are neurons that became silent due to current network state, not due to last removal\n",
    "newly_silent_reset = silent_interneurons & (~total_removed_neurons) & (~last_removed)\n",
    "last_removed_reset = last_removed_reset | newly_silent_reset\n",
    "\n",
    "# Keep level the same (we're trying again, not progressing)\n",
    "level_reset = level\n",
    "\n",
    "# Check if we've converged - either no more neurons to remove OR we're oscillating\n",
    "# Oscillation detection: if we're restoring neurons we've put back before, we're in a loop\n",
    "oscillation_detected = jnp.any(restored_neurons & neurons_put_back)\n",
    "min_circuit_reset = (available_neurons_reset <= 2) | oscillation_detected\n",
    "\n",
    "# === SELECT BETWEEN BRANCHES ===\n",
    "# Use jax.lax.select to choose between continue and reset results\n",
    "final_total_removed = jax.lax.select(reset_condition, total_removed_reset, total_removed_continue)\n",
    "final_removed_stim = jax.lax.select(reset_condition, removed_stim_reset, removed_stim_continue)\n",
    "final_last_removed = jax.lax.select(reset_condition, last_removed_reset, last_removed_continue)\n",
    "final_neurons_put_back = jax.lax.select(reset_condition, neurons_put_back_reset, neurons_put_back_continue)\n",
    "final_level = jax.lax.select(reset_condition, level_reset, level_continue)\n",
    "final_p = jax.lax.select(reset_condition, p_reset, p_continue)\n",
    "final_min_circuit = jax.lax.select(reset_condition, min_circuit_reset, min_circuit_continue)\n",
    "\n",
    "# Calculate available neurons and check for convergence\n",
    "available_neurons = jnp.sum(interneuron_mask & (~final_total_removed))\n",
    "\n",
    "# Check for oscillation: if we're in reset mode and detected oscillation, we've converged\n",
    "oscillation_converged = reset_condition & final_min_circuit\n",
    "size_converged = available_neurons <= 2\n",
    "final_converged = oscillation_converged | size_converged\n",
    "\n",
    "# Update W_mask to reflect removed neurons\n",
    "W_mask_init = jnp.ones_like(W_mask, dtype=jnp.float32)\n",
    "removed_float = final_total_removed.astype(jnp.float32)\n",
    "kept_mask = 1.0 - removed_float\n",
    "W_mask_new = W_mask_init * kept_mask[:, None] * kept_mask[None, :]\n",
    "\n",
    "# Convert to scalar for jax.lax.select\n",
    "final_converged_scalar = jnp.squeeze(final_converged)\n",
    "\n",
    "# Debug information\n",
    "jax.debug.print(\"Oscillation score: {score}\", score=oscillation_score)\n",
    "jax.debug.print(\"Reset condition (below threshold): {condition}\", condition=reset_condition)\n",
    "jax.debug.print(\"Available neurons: {count}\", count=available_neurons)\n",
    "jax.debug.print(\"Level: {level}\", level=final_level)\n",
    "jax.debug.print(\"Oscillation detected: {detected}\", detected=reset_condition & (final_min_circuit & ~size_converged))\n",
    "jax.debug.print(\"Final converged: {converged}\", converged=final_converged)\n",
    "jax.debug.print(\"Silent neurons removed: {count}\", count=jnp.sum(silent_interneurons))\n",
    "print('\\n')\n",
    "\n",
    "# When converged, preserve current state (don't make further changes)\n",
    "state = Pruning_state(\n",
    "    W_mask=jax.lax.select(final_converged_scalar, W_mask, W_mask_new),\n",
    "    interneuron_mask=interneuron_mask,\n",
    "    level=jax.lax.select(final_converged_scalar, level, final_level),\n",
    "    total_removed_neurons=jax.lax.select(final_converged_scalar, total_removed_neurons, final_total_removed),\n",
    "    neurons_put_back=jax.lax.select(final_converged_scalar, neurons_put_back, final_neurons_put_back),\n",
    "    removed_stim_neurons=jax.lax.select(final_converged_scalar, removed_stim_neurons, final_removed_stim),\n",
    "    last_removed=jax.lax.select(final_converged_scalar, last_removed, final_last_removed),\n",
    "    remove_p=jax.lax.select(final_converged_scalar, remove_p, final_p),\n",
    "    min_circuit=final_converged_scalar,\n",
    "    keys=key_next,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_inds(~load_state.total_removed_neurons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_inds = print_inds(exclude_mask_continue)\n",
    "in_idxs.shape[0] - exclude_inds.shape[0]  # Number of interneurons left after pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_inds(~exclude_mask_continue), print_inds(~exclude_mask_reset), print_inds(~final_total_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pytree(pytree):\n",
    "    \"\"\"\n",
    "    path_filter: function that takes key_path tuple and returns True/False\n",
    "    \"\"\"\n",
    "    def process_leaf(key_path, leaf):\n",
    "       print(f\"Key Path: {key_path[0]}, Leaf: {leaf.shape} dype: {leaf.dtype}\")\n",
    "\n",
    "    return jax.tree.map_with_path(process_leaf, pytree)\n",
    "print_pytree(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from src.sim_utils import compute_oscillation_score\n",
    "from src.optimized_vnc import update_params\n",
    "\n",
    "@dataclass\n",
    "class Pruning_state:\n",
    "    W_mask: jnp.ndarray\n",
    "    interneuron_mask: jnp.ndarray\n",
    "    level: int\n",
    "    total_removed_neurons: jnp.ndarray\n",
    "    neurons_put_back_current: jnp.ndarray\n",
    "    neurons_put_back_prev: jnp.ndarray\n",
    "    removed_stim_neurons: jnp.ndarray\n",
    "    last_removed: jnp.ndarray\n",
    "    remove_p: jnp.ndarray\n",
    "    round_complete: bool\n",
    "    converged: bool\n",
    "    round_number: int\n",
    "    keys: jax.random.PRNGKey\n",
    "    steps_in_current_round: int  # Track steps within current round\n",
    "    total_iterations: int        # Track total iterations for safety\n",
    "\n",
    "def safe_choice(key, logits, exclude_mask):\n",
    "    \"\"\"Safe choice function that works with vmap\"\"\"\n",
    "    # Set excluded neurons to very negative logits\n",
    "    safe_logits = jnp.where(exclude_mask, -1e10, logits)\n",
    "    # Use gumbel trick for sampling\n",
    "    gumbel_noise = jax.random.gumbel(key, safe_logits.shape)\n",
    "    return jnp.argmax(safe_logits + gumbel_noise)\n",
    "\n",
    "def removal_probability_safe(max_frs, exclude_mask):\n",
    "    \"\"\"Safe removal probability that works with vmap\"\"\"\n",
    "    # Create base probabilities (higher firing rate = lower removal probability)\n",
    "    base_probs = 1.0 / (max_frs + 1e-6)  # Add epsilon to avoid division by zero\n",
    "    # Zero out excluded neurons\n",
    "    probs = jnp.where(exclude_mask, 0.0, base_probs)\n",
    "    # Normalize (with safety for all-zero case)\n",
    "    total_prob = jnp.sum(probs)\n",
    "    return jnp.where(total_prob > 0, probs / total_prob, probs)\n",
    "\n",
    "def pruning_step_dynamic(state, R, mn_idxs, clip_start, oscillation_threshold):\n",
    "    \"\"\"\n",
    "    Single pruning step with dynamic convergence checking.\n",
    "    Works with vmap and continues until natural convergence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Safety check - stop if max iterations reached\n",
    "    max_iterations_reached = state.total_iterations >= 200\n",
    "    already_converged = state.converged\n",
    "    \n",
    "    # If we should stop, return unchanged state\n",
    "    should_stop = already_converged | max_iterations_reached\n",
    "    \n",
    "    def stopped_computation():\n",
    "        return state._replace(\n",
    "            converged=True,  # Mark as converged if we hit max iterations\n",
    "            total_iterations=state.total_iterations + 1\n",
    "        )\n",
    "    \n",
    "    def active_computation():\n",
    "        # Get neural activity\n",
    "        max_frs = jnp.max(R, axis=-1)\n",
    "        mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "        active_mask = (max_frs > 0) & mn_mask\n",
    "\n",
    "        # Compute oscillation score\n",
    "        oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "        reset_condition = (oscillation_score < oscillation_threshold) | jnp.isnan(oscillation_score)\n",
    "\n",
    "        # Identify silent interneurons (permanent removal)\n",
    "        silent_interneurons = state.interneuron_mask & (max_frs <= 0)\n",
    "        \n",
    "        # Generate key for this iteration\n",
    "        key = jax.random.fold_in(state.keys, state.total_iterations)\n",
    "        key_continue, key_reset = jax.random.split(key)\n",
    "        \n",
    "        # Check if we need to start a new round\n",
    "        def check_new_round():\n",
    "            \"\"\"Check if current round is complete and handle round transition\"\"\"\n",
    "            \n",
    "            # Current round is complete if no interneurons available for removal\n",
    "            exclude_mask = (~state.interneuron_mask) | state.total_removed_neurons | state.neurons_put_back_current\n",
    "            available_neurons = jnp.sum(state.interneuron_mask & (~exclude_mask))\n",
    "            current_round_done = available_neurons <= 0\n",
    "            \n",
    "            def start_new_round():\n",
    "                # Compare current and previous put-back lists for convergence\n",
    "                lists_identical = jnp.allclose(state.neurons_put_back_current, \n",
    "                                             state.neurons_put_back_prev, atol=1e-6)\n",
    "                \n",
    "                # If lists are identical, we've converged\n",
    "                new_converged = lists_identical\n",
    "                \n",
    "                # Start new round\n",
    "                return state._replace(\n",
    "                    neurons_put_back_prev=state.neurons_put_back_current,\n",
    "                    neurons_put_back_current=jnp.zeros_like(state.neurons_put_back_current),\n",
    "                    removed_stim_neurons=jnp.zeros_like(state.removed_stim_neurons),\n",
    "                    last_removed=jnp.zeros_like(state.last_removed),\n",
    "                    level=0,\n",
    "                    round_complete=False,\n",
    "                    converged=new_converged,\n",
    "                    round_number=state.round_number + 1,\n",
    "                    steps_in_current_round=0\n",
    "                )\n",
    "            \n",
    "            def continue_current_round():\n",
    "                return state\n",
    "            \n",
    "            # Start new round if current one is complete\n",
    "            return jax.lax.cond(current_round_done, start_new_round, continue_current_round)\n",
    "        \n",
    "        # Check for round transition first\n",
    "        state_after_round_check = check_new_round()\n",
    "        \n",
    "        # If we just converged in round transition, return that state\n",
    "        def handle_convergence():\n",
    "            return state_after_round_check._replace(\n",
    "                total_iterations=state.total_iterations + 1\n",
    "            )\n",
    "        \n",
    "        def normal_pruning_step():\n",
    "            \"\"\"Normal within-round pruning step\"\"\"\n",
    "            \n",
    "            # === CONTINUE BRANCH: Normal removal ===\n",
    "            total_removed_continue = state_after_round_check.total_removed_neurons | silent_interneurons\n",
    "            exclude_mask_continue = (~state_after_round_check.interneuron_mask) | total_removed_continue | state_after_round_check.neurons_put_back_current\n",
    "            \n",
    "            # Check if any neurons available for removal in continue branch\n",
    "            available_neurons_continue = jnp.sum(state_after_round_check.interneuron_mask & (~exclude_mask_continue))\n",
    "            \n",
    "            # Sample neuron to remove\n",
    "            p_continue = removal_probability_safe(max_frs, exclude_mask_continue)\n",
    "            neuron_idx_continue = safe_choice(key_continue, p_continue, exclude_mask_continue)\n",
    "            \n",
    "            # Update for continue branch (only if neurons available)\n",
    "            can_remove_continue = available_neurons_continue > 0\n",
    "            \n",
    "            removed_stim_continue = jnp.where(\n",
    "                can_remove_continue,\n",
    "                state_after_round_check.removed_stim_neurons.at[neuron_idx_continue].set(True),\n",
    "                state_after_round_check.removed_stim_neurons\n",
    "            )\n",
    "            total_removed_continue = jnp.where(\n",
    "                can_remove_continue,\n",
    "                total_removed_continue.at[neuron_idx_continue].set(True),\n",
    "                total_removed_continue\n",
    "            )\n",
    "            \n",
    "            # Track last removed\n",
    "            last_removed_continue = jnp.zeros_like(state_after_round_check.last_removed)\n",
    "            last_removed_continue = jnp.where(\n",
    "                can_remove_continue,\n",
    "                last_removed_continue.at[neuron_idx_continue].set(True),\n",
    "                last_removed_continue\n",
    "            )\n",
    "            # Add newly silent neurons\n",
    "            newly_silent = silent_interneurons & (~state_after_round_check.total_removed_neurons)\n",
    "            last_removed_continue = last_removed_continue | newly_silent\n",
    "            \n",
    "            # === RESET BRANCH: Restore and try different neuron ===\n",
    "            # Restore last removed neurons to put_back list\n",
    "            neurons_put_back_reset = state_after_round_check.neurons_put_back_current | state_after_round_check.last_removed\n",
    "            removed_stim_reset = state_after_round_check.removed_stim_neurons & (~state_after_round_check.last_removed)\n",
    "            total_removed_reset = (state_after_round_check.total_removed_neurons & (~state_after_round_check.last_removed)) | silent_interneurons\n",
    "            \n",
    "            exclude_mask_reset = (~state_after_round_check.interneuron_mask) | total_removed_reset | neurons_put_back_reset\n",
    "            available_neurons_reset = jnp.sum(state_after_round_check.interneuron_mask & (~exclude_mask_reset))\n",
    "            \n",
    "            # Sample different neuron\n",
    "            p_reset = removal_probability_safe(max_frs, exclude_mask_reset)\n",
    "            neuron_idx_reset = safe_choice(key_reset, p_reset, exclude_mask_reset)\n",
    "            \n",
    "            can_remove_reset = available_neurons_reset > 0\n",
    "            \n",
    "            removed_stim_reset = jnp.where(\n",
    "                can_remove_reset,\n",
    "                removed_stim_reset.at[neuron_idx_reset].set(True),\n",
    "                removed_stim_reset\n",
    "            )\n",
    "            total_removed_reset = jnp.where(\n",
    "                can_remove_reset,\n",
    "                total_removed_reset.at[neuron_idx_reset].set(True),\n",
    "                total_removed_reset\n",
    "            )\n",
    "            \n",
    "            last_removed_reset = jnp.zeros_like(state_after_round_check.last_removed)\n",
    "            last_removed_reset = jnp.where(\n",
    "                can_remove_reset,\n",
    "                last_removed_reset.at[neuron_idx_reset].set(True),\n",
    "                last_removed_reset\n",
    "            )\n",
    "            # Add newly silent neurons (excluding those already in last_removed)\n",
    "            newly_silent_reset = silent_interneurons & (~state_after_round_check.total_removed_neurons) & (~state_after_round_check.last_removed)\n",
    "            last_removed_reset = last_removed_reset | newly_silent_reset\n",
    "            \n",
    "            # Choose between branches based on reset condition\n",
    "            final_total_removed = jnp.where(reset_condition, total_removed_reset, total_removed_continue)\n",
    "            final_removed_stim = jnp.where(reset_condition, removed_stim_reset, removed_stim_continue)\n",
    "            final_last_removed = jnp.where(reset_condition, last_removed_reset, last_removed_continue)\n",
    "            final_neurons_put_back = jnp.where(reset_condition, neurons_put_back_reset, state_after_round_check.neurons_put_back_current)\n",
    "            final_remove_p = jnp.where(reset_condition, p_reset, p_continue)\n",
    "            \n",
    "            # Update W_mask based on removed neurons\n",
    "            removed_float = final_total_removed.astype(jnp.float32)\n",
    "            kept_mask = 1.0 - removed_float\n",
    "            W_mask_new = kept_mask[:, None] * kept_mask[None, :]\n",
    "            \n",
    "            return state_after_round_check._replace(\n",
    "                W_mask=W_mask_new,\n",
    "                level=state_after_round_check.level + 1,\n",
    "                total_removed_neurons=final_total_removed,\n",
    "                neurons_put_back_current=final_neurons_put_back,\n",
    "                removed_stim_neurons=final_removed_stim,\n",
    "                last_removed=final_last_removed,\n",
    "                remove_p=final_remove_p,\n",
    "                steps_in_current_round=state_after_round_check.steps_in_current_round + 1,\n",
    "                total_iterations=state.total_iterations + 1\n",
    "            )\n",
    "        \n",
    "        # Choose between convergence handling and normal step\n",
    "        return jax.lax.cond(\n",
    "            state_after_round_check.converged, \n",
    "            handle_convergence, \n",
    "            normal_pruning_step\n",
    "        )\n",
    "    \n",
    "    # Main conditional: stop or continue\n",
    "    return jax.lax.cond(should_stop, stopped_computation, active_computation)\n",
    "\n",
    "# Vmap-compatible version\n",
    "@partial(jax.vmap, in_axes=(0, 0, None, None, None))\n",
    "def pruning_step_batched(state_batch, R_batch, mn_idxs, clip_start, oscillation_threshold):\n",
    "    \"\"\"Vectorized pruning step that works across a batch\"\"\"\n",
    "    return pruning_step_dynamic(state_batch, R_batch, mn_idxs, clip_start, oscillation_threshold)\n",
    "\n",
    "def run_pruning_algorithm_batched(neuron_params, sim_params, initial_states, Rs, mn_idxs, clip_start, oscillation_threshold):\n",
    "    \"\"\"\n",
    "    Run pruning algorithm on batch until convergence or max iterations (200).\n",
    "    \n",
    "    Args:\n",
    "        initial_states: Batched Pruning_state \n",
    "        Rs: Batch of neural activity [batch_size, neurons, time]\n",
    "        mn_idxs: Motor neuron indices\n",
    "        clip_start: Start index for oscillation analysis\n",
    "        oscillation_threshold: Threshold for oscillation score\n",
    "    \n",
    "    Returns:\n",
    "        final_states: Final states for each batch element\n",
    "        iterations_used: Number of iterations each element used\n",
    "    \"\"\"\n",
    "    \n",
    "    def should_continue(state_batch):\n",
    "        \"\"\"Check if any element in batch needs to continue\"\"\"\n",
    "        return jnp.any(~state_batch.converged)\n",
    "    \n",
    "    def iteration_step(state_batch):\n",
    "        \"\"\"Single iteration across the batch\"\"\"\n",
    "        neuron_params = neuron_params._replace(W_mask=state.W_mask)\n",
    "        batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "        return pruning_step_batched(state_batch, Rs, mn_idxs, clip_start, oscillation_threshold)\n",
    "    \n",
    "    # Run until all converged or max iterations reached\n",
    "    current_states = initial_states\n",
    "    max_iterations = 200\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Take one step for all batch elements\n",
    "        current_states = iteration_step(current_states)\n",
    "        \n",
    "        # Check if all converged - optional early stopping for efficiency\n",
    "        if not should_continue(current_states):\n",
    "            break\n",
    "    \n",
    "    return current_states\n",
    "\n",
    "def create_batched_initial_state(batch_size, n_neurons, key=None):\n",
    "    \"\"\"Helper to create batched initial states\"\"\"\n",
    "    if key is None:\n",
    "        key = jax.random.PRNGKey(42)\n",
    "    \n",
    "    keys = jax.random.split(key, batch_size)\n",
    "    \n",
    "    return Pruning_state(\n",
    "        W_mask=jnp.ones((batch_size, n_neurons, n_neurons)),\n",
    "        interneuron_mask=jnp.ones((batch_size, n_neurons), dtype=bool),\n",
    "        level=jnp.zeros(batch_size, dtype=int),\n",
    "        total_removed_neurons=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        neurons_put_back_current=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        neurons_put_back_prev=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        removed_stim_neurons=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        last_removed=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        remove_p=jnp.ones((batch_size, n_neurons)) / n_neurons,\n",
    "        round_complete=jnp.zeros(batch_size, dtype=bool),\n",
    "        converged=jnp.zeros(batch_size, dtype=bool),\n",
    "        round_number=jnp.zeros(batch_size, dtype=int),\n",
    "        keys=keys,\n",
    "        steps_in_current_round=jnp.zeros(batch_size, dtype=int),\n",
    "        total_iterations=jnp.zeros(batch_size, dtype=int)\n",
    "    )\n",
    "\n",
    "# Usage example:\n",
    "\n",
    "# Create batch\n",
    "batch_size = 16\n",
    "n_neurons = 100\n",
    "initial_states = create_batched_initial_state(batch_size, n_neurons)\n",
    "\n",
    "# Your neural activity data\n",
    "Rs = jnp.ones((batch_size, n_neurons, 1000))  # [batch, neurons, time]\n",
    "mn_idxs = jnp.array([0, 1, 2])  # Motor neuron indices\n",
    "\n",
    "# Run algorithm\n",
    "final_states = run_pruning_algorithm_batched(\n",
    "    neuron_params, sim_params,\n",
    "    initial_states, Rs, mn_idxs, \n",
    "    clip_start=100, oscillation_threshold=0.5\n",
    ")\n",
    "\n",
    "# Check results\n",
    "print(f\"Converged: {jnp.sum(final_states.converged)} / {batch_size}\")\n",
    "print(f\"Iterations used: {final_states.total_iterations}\")\n",
    "print(f\"Hit max iterations: {jnp.sum(final_states.total_iterations >= 200)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparse.load_npz('/data/users/eabe/Pugliese_2025/Prune_Test/debug/run_id=Testing/sim=prune_network/ckpt/Prune_Test_Rs.npz').todense().astype(jnp.float32).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparse.load_npz(cfg.paths.ckpt_dir  / f\"{cfg.experiment.name}_Rs.npz\").todense().astype(np.float32).squeeze()\n",
    "mini_circuit = sparse.load_npz(cfg.paths.ckpt_dir  / f\"{cfg.experiment.name}_mini_circuits.npz\").todense().astype(np.bool).squeeze()\n",
    "# W_mask = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_W_mask.npz\").todense().astype(np.float32)\n",
    "# total_removed_neurons = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_total_removed.npz\").todense().astype(np.bool_)\n",
    "# loaded_state = load_state(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_state.pkl\")\n",
    "# loaded_state = load_state('/data/users/eabe/Pugliese_2025/Prune_Test/debug/run_id=Testing/sim=prune_network/ckpt/Prune_Test_state.pkl')\n",
    "w_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "## Initialize parameters\n",
    "neuron_params = prepare_neuron_params(cfg, w_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "all_neurons = w_table.index.to_numpy()\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "nonmn_idxs = w_table.loc[(w_table[\"bodyId\"]==10093) | (w_table[\"bodyId\"]==10707) | (w_table[\"bodyId\"]==13905) | (w_table[\"bodyId\"]==11751)].index.values\n",
    "interneuron_mask = jnp.full((neuron_params.W_mask.shape[0], neuron_params.W_mask.shape[-1]), fill_value=False, dtype=jnp.bool_)\n",
    "interneuron_mask = interneuron_mask.at[:, in_idxs].set(True)\n",
    "# neuron_params = neuron_params._replace(W_mask=loaded_state.W_mask)\n",
    "# mini_circuit = ((~loaded_state.total_removed_neurons) | loaded_state.last_removed | loaded_state.prev_put_back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_params.W_mask.shape, mini_circuit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results\n",
    "# mini_circuit = ((~loaded_state.total_removed_neurons) | loaded_state.last_removed | loaded_state.prev_put_back)\n",
    "W_mask_init = jnp.ones_like(neuron_params.W_mask, dtype=jnp.bool)\n",
    "W_mask_new = W_mask_init * mini_circuit[:, :, None] * mini_circuit[:, None, :] \n",
    "neuron_params = neuron_params._replace(W_mask=(W_mask_new))\n",
    "# results = process_batch_prune(neuron_params, sim_params, jnp.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.squeeze()\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = batch_results[0]\n",
    "n_replicate = 510\n",
    "R = results[n_replicate]\n",
    "interneuron_left = jnp.where(mini_circuit[n_replicate]&(interneuron_mask[n_replicate]))[0]\n",
    "print(f\"interneurons left: {interneuron_left}\")\n",
    "print(f\"prev_min_circuit neurons: {nonmn_idxs}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "ax = axs[0]\n",
    "ax.plot(R[nonmn_idxs].T)\n",
    "ax.set_title(\"mini_circuit neurons\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(R[mn_idxs].T)\n",
    "ax.set_title(\"motor neurons\")\n",
    "\n",
    "ax = axs[2]\n",
    "active_neurons = jnp.where((jnp.sum(results[0],axis=-1) > 0))[0]\n",
    "ax.plot(R[active_neurons].T)\n",
    "ax.set_title(\"active neurons\")\n",
    "\n",
    "# Get active MN activity using JAX-compatible approach\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "active_mask = ((max_frs>0) & mn_mask)\n",
    "clip_start = 220\n",
    "# Compute oscillation score\n",
    "oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "# print('oscillation_score:', oscillation_score)\n",
    "oscillation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_interneurons = []\n",
    "active_motor_neurons = []\n",
    "for n in range(results.shape[0]):\n",
    "    R = results[n]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_interneurons.append(jnp.where((max_frs > 0) & interneuron_mask[n])[0])\n",
    "    active_motor_neurons.append(jnp.where((max_frs > 0) & ~interneuron_mask[n])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_interneurons\n",
    "active_motor_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.sim_utils import neuron_oscillation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oscillation_score, _ = compute_oscillation_score(results.reshape(-1, results.shape[-1])[..., clip_start:], active_mask, prominence=0.05)\n",
    "activity = results[..., clip_start:]\n",
    "prominence = 0.05\n",
    "all_scores = []\n",
    "for nsim in range(activity.shape[0]):\n",
    "    R = activity[nsim]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "    active_mask = ((max_frs>0) & mn_mask)\n",
    "    sim_scores, freqs = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(R, prominence)\n",
    "    all_scores.append(sim_scores[active_mask])\n",
    "all_scores = jnp.concatenate(all_scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_scores, bins=50, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stim Adjustment Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_with_stim_adjustment(self,maxIters=10,clampedNeurons=[],clampedRates=None,nActiveUpper=500,nActiveLower=5,nHighFrUpper=100):\n",
    "    nextHighest = None\n",
    "    nextLowest = None\n",
    "\n",
    "    for i in range(maxIters):\n",
    "        self.run(clampedNeurons=clampedNeurons,clampedRates=clampedRates)\n",
    "        R = self.R\n",
    "\n",
    "        nActive = sum(np.sum(R,1)>0)\n",
    "        nHighFr = sum(np.max(R,1)>100)\n",
    "\n",
    "        currInputs = self.inputs.copy()\n",
    "\n",
    "        print(f\"Run {i}\")\n",
    "        print(f\"max stimI = {np.max(currInputs)}\")\n",
    "        print(f\"nActive: {nActive}\")\n",
    "        print(f\"nHighFr: {nHighFr}\")\n",
    "\n",
    "        if (nActive > nActiveUpper) or (nHighFr > nHighFrUpper): # too strong\n",
    "            if nextLowest is None:\n",
    "                newInputs = currInputs/2\n",
    "            else:\n",
    "                newInputs = (currInputs+nextLowest)/2\n",
    "            nextHighest = currInputs\n",
    "        elif (nActive < nActiveLower): # too weak\n",
    "            if nextHighest is None:\n",
    "                newInputs = currInputs*2\n",
    "            else:\n",
    "                newInputs = (currInputs+nextHighest)/2\n",
    "            nextLowest = currInputs\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        self.set_input(newInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note: The run_with_stim_adjustment function cannot be easily JIT-compiled\n",
    "# because it involves loops with data-dependent control flow and side effects.\n",
    "# Here's a restructured version that separates the JIT-able parts:\n",
    "\n",
    "@jit\n",
    "def compute_activity_metrics(R):\n",
    "    \"\"\"JIT-compatible function to compute activity metrics.\"\"\"\n",
    "    n_active = jnp.sum(jnp.sum(R, axis=1) > 0)\n",
    "    n_high_fr = jnp.sum(jnp.max(R, axis=1) > 100)\n",
    "    return n_active, n_high_fr\n",
    "\n",
    "@jit\n",
    "def update_inputs_binary_search(curr_inputs, next_lowest, next_highest, \n",
    "                               n_active, n_high_fr, n_active_upper, \n",
    "                               n_active_lower, n_high_fr_upper):\n",
    "    \"\"\"JIT-compatible input update logic.\"\"\"\n",
    "    \n",
    "    # Determine if stimulation is too strong\n",
    "    too_strong = (n_active > n_active_upper) | (n_high_fr > n_high_fr_upper)\n",
    "    too_weak = n_active < n_active_lower\n",
    "    \n",
    "    # Update inputs based on binary search logic\n",
    "    def update_for_too_strong():\n",
    "        new_inputs = jnp.where(\n",
    "            next_lowest is None,\n",
    "            curr_inputs / 2,\n",
    "            (curr_inputs + next_lowest) / 2\n",
    "        )\n",
    "        new_next_highest = curr_inputs\n",
    "        return new_inputs, next_lowest, new_next_highest\n",
    "    \n",
    "    def update_for_too_weak():\n",
    "        new_inputs = jnp.where(\n",
    "            next_highest is None,\n",
    "            curr_inputs * 2,\n",
    "            (curr_inputs + next_highest) / 2\n",
    "        )\n",
    "        new_next_lowest = curr_inputs\n",
    "        return new_inputs, new_next_lowest, next_highest\n",
    "    \n",
    "    def no_update():\n",
    "        return curr_inputs, next_lowest, next_highest\n",
    "    \n",
    "    # Apply updates conditionally\n",
    "    new_inputs, new_next_lowest, new_next_highest = jax.lax.cond(\n",
    "        too_strong,\n",
    "        update_for_too_strong,\n",
    "        lambda: jax.lax.cond(\n",
    "            too_weak,\n",
    "            update_for_too_weak,\n",
    "            no_update\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    converged = ~too_strong & ~too_weak\n",
    "    \n",
    "    return new_inputs, new_next_lowest, new_next_highest, converged\n",
    "\n",
    "# Example usage:\n",
    "def run_with_stim_adjustment_jax(simulation_runner, max_iters=10, \n",
    "                                clamped_neurons=None, clamped_rates=None,\n",
    "                                n_active_upper=500, n_active_lower=5, \n",
    "                                n_high_fr_upper=100):\n",
    "    \"\"\"\n",
    "    JAX-compatible version of run_with_stim_adjustment.\n",
    "    Note: This requires the simulation_runner to be compatible with JAX.\n",
    "    \"\"\"\n",
    "    next_highest = None\n",
    "    next_lowest = None\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        # Run simulation (this part depends on your simulation framework)\n",
    "        R = simulation_runner.run(clamped_neurons=clamped_neurons, \n",
    "                                 clamped_rates=clamped_rates)\n",
    "        \n",
    "        # Compute metrics (JIT-compiled)\n",
    "        n_active, n_high_fr = compute_activity_metrics(R)\n",
    "        curr_inputs = simulation_runner.get_inputs()\n",
    "        \n",
    "        print(f\"Run {i}\")\n",
    "        print(f\"max stimI = {jnp.max(curr_inputs)}\")\n",
    "        print(f\"nActive: {n_active}\")\n",
    "        print(f\"nHighFr: {n_high_fr}\")\n",
    "        \n",
    "        # Update inputs (JIT-compiled)\n",
    "        new_inputs, next_lowest, next_highest, converged = update_inputs_binary_search(\n",
    "            curr_inputs, next_lowest, next_highest, n_active, n_high_fr,\n",
    "            n_active_upper, n_active_lower, n_high_fr_upper\n",
    "        )\n",
    "        \n",
    "        if converged:\n",
    "            break\n",
    "            \n",
    "        simulation_runner.set_input(new_inputs)\n",
    "\n",
    "# Additional utility functions for JAX compatibility:\n",
    "\n",
    "@jit\n",
    "def safe_divide(x, y, default=0.0):\n",
    "    \"\"\"Safe division that handles division by zero.\"\"\"\n",
    "    return jnp.where(y == 0, default, x / y)\n",
    "\n",
    "@jit\n",
    "def safe_max(x, default=0.0):\n",
    "    \"\"\"Safe max that handles empty arrays.\"\"\"\n",
    "    return jnp.where(len(x) == 0, default, jnp.max(x))\n",
    "\n",
    "@jit\n",
    "def safe_min(x, default=0.0):\n",
    "    \"\"\"Safe min that handles empty arrays.\"\"\"\n",
    "    return jnp.where(len(x) == 0, default, jnp.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnc-closedloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
