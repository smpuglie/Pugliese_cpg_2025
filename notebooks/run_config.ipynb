{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from src.vnc import run_vnc_simulation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "import jax\n",
    "# jax.config.update(\"jax_enable_x64\", True)\n",
    "# Configure JAX for better performance\n",
    "jax.config.update(\"jax_enable_x64\", False)  # Use float32 for better GPU performance\n",
    "# jax.config.update(\"jax_platforms\", \"cuda\")  # Prefer GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # Use GPU 0\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\n",
    "\n",
    "# Disable XLA optimizations that might cause timing issues\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_triton_gemm_any=false'\n",
    "\n",
    "import sparse\n",
    "\n",
    "import src.io_dict_to_hdf5 as ioh5\n",
    "from src.plot_utils import *\n",
    "from src.vnc_sim import *\n",
    "from src.path_utils import *\n",
    "from omegaconf import OmegaConf\n",
    "# Ensure custom resolvers are registered\n",
    "# This is important when loading saved configs that contain custom interpolations\n",
    "from src.path_utils import register_custom_resolvers\n",
    "register_custom_resolvers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing inf/nan detection in simulation...\n",
      "Running simulation with parameters designed to cause large values...\n",
      "Simulation completed.\n",
      "Result shape: (4604, 2001)\n",
      "Expected time points: 2001\n",
      "Actual time points: 2001\n",
      "Solution times: first=0.000, last=inf, count=2001\n",
      "Expected final time: 2.0\n",
      "Has inf: True\n",
      "Has nan: False\n",
      "Max absolute value: inf\n",
      "⚠ Simulation ran to completion: 2001/2001 time points\n",
      "Final time: inf/2.0\n",
      "✗ Event failed to catch inf/nan values!\n"
     ]
    }
   ],
   "source": [
    "def test_inf_nan_detection():\n",
    "    \"\"\"Test that the event function correctly detects inf/nan values.\"\"\"\n",
    "    print(\"Testing inf/nan detection in simulation...\")\n",
    "    \n",
    "    # Load a simple configuration with fewer replicates to avoid memory issues\n",
    "    with initialize(version_base=None, config_path=\"../configs\"):\n",
    "        cfg = compose(config_name=\"config\", \n",
    "                     overrides=[\"experiment=DNb08_Stim\", \"sim=default\",\n",
    "                               \"experiment.n_replicates=1\"])  # Use only 1 replicate\n",
    "    \n",
    "    # Load basic parameters\n",
    "    W_table = load_wTable(cfg.experiment.dfPath)\n",
    "    neuron_params = prepare_neuron_params(cfg, W_table)\n",
    "    sim_params = prepare_sim_params(cfg, 1, neuron_params.W.shape[0])\n",
    "    \n",
    "    # Create parameters that will cause large values (and potentially inf/nan)\n",
    "    extreme_input = jnp.zeros(neuron_params.W.shape[0])\n",
    "    stim_indices = jnp.array(cfg.experiment.stimNeurons[0])\n",
    "    extreme_input = extreme_input.at[stim_indices].set(500.0)  # Large stimulation\n",
    "    \n",
    "    # Use more extreme parameters to trigger large values\n",
    "    extreme_tau = jnp.full((neuron_params.W.shape[0],), 0.001)  # Small tau for fast dynamics\n",
    "    extreme_a = jnp.full((neuron_params.W.shape[0],), 1000.0)   # Large activation gain\n",
    "    extreme_threshold = jnp.full((neuron_params.W.shape[0],), -100.0)  # Low threshold\n",
    "    extreme_fr_cap = jnp.full((neuron_params.W.shape[0],), 2000.0)  # High firing rate cap\n",
    "    \n",
    "    print(\"Running simulation with parameters designed to cause large values...\")\n",
    "    \n",
    "    try:\n",
    "        # Run simulation with extreme parameters\n",
    "        result, solution = run_single_simulation(\n",
    "            W=neuron_params.W,\n",
    "            tau=extreme_tau,\n",
    "            a=extreme_a,\n",
    "            threshold=extreme_threshold,\n",
    "            fr_cap=extreme_fr_cap,\n",
    "            inputs=extreme_input,\n",
    "            noise_stdv=sim_params.noise_stdv,\n",
    "            t_axis=sim_params.t_axis,\n",
    "            T=sim_params.T,\n",
    "            dt=sim_params.dt,\n",
    "            pulse_start=sim_params.pulse_start,\n",
    "            pulse_end=sim_params.pulse_end,\n",
    "            r_tol=sim_params.r_tol,\n",
    "            a_tol=sim_params.a_tol,\n",
    "            key=neuron_params.seeds[0]\n",
    "        )\n",
    "        \n",
    "        print(f\"Simulation completed.\")\n",
    "        print(f\"Result shape: {result.shape}\")\n",
    "        print(f\"Expected time points: {len(sim_params.t_axis)}\")\n",
    "        print(f\"Actual time points: {result.shape[-1]}\")\n",
    "        \n",
    "        if hasattr(solution, 'ts') and len(solution.ts) > 0:\n",
    "            print(f\"Solution times: first={solution.ts[0]:.3f}, last={solution.ts[-1]:.3f}, count={len(solution.ts)}\")\n",
    "            print(f\"Expected final time: {sim_params.T}\")\n",
    "        \n",
    "        print(f\"Has inf: {jnp.any(jnp.isinf(result))}\")\n",
    "        print(f\"Has nan: {jnp.any(jnp.isnan(result))}\")\n",
    "        print(f\"Max absolute value: {jnp.max(jnp.abs(result)):.2e}\")\n",
    "        \n",
    "        # Check if the simulation stopped early\n",
    "        expected_time_points = len(sim_params.t_axis)\n",
    "        actual_time_points = result.shape[-1]\n",
    "        \n",
    "        if actual_time_points < expected_time_points:\n",
    "            print(f\"✓ Simulation stopped early: {actual_time_points}/{expected_time_points} time points\")\n",
    "            print(\"✓ Early stopping mechanism is working!\")\n",
    "            return True\n",
    "        else:\n",
    "            actual_final_time = solution.ts[-1] if len(solution.ts) > 0 else 0.0\n",
    "            if actual_final_time < (sim_params.T - sim_params.dt):\n",
    "                print(f\"✓ Simulation stopped early in time: {actual_final_time:.3f}/{sim_params.T}\")\n",
    "                print(\"✓ Early stopping mechanism is working!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"⚠ Simulation ran to completion: {actual_time_points}/{expected_time_points} time points\")\n",
    "                print(f\"Final time: {actual_final_time:.3f}/{sim_params.T}\")\n",
    "                # Check if we successfully prevented inf/nan even with extreme parameters\n",
    "                if not (jnp.any(jnp.isinf(result)) or jnp.any(jnp.isnan(result))):\n",
    "                    print(\"✓ No inf/nan detected - parameters were handled robustly\")\n",
    "                    return True\n",
    "                else:\n",
    "                    print(\"✗ Event failed to catch inf/nan values!\")\n",
    "                    return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Simulation failed with error: {e}\")\n",
    "        # This might actually be good - if extreme parameters cause an exception,\n",
    "        # it means the solver detected the problem\n",
    "        print(\"This might indicate that numerical issues were detected by the solver\")\n",
    "        return True\n",
    "\n",
    "extreme_ok = test_inf_nan_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /data/users/eabe/Pugliese_2025/DN_Screen/debug/run_id=Testing/logs/run_config.yaml\n",
      "Loading: DN_Screen /data/users/eabe/Pugliese_2025/DN_Screen/debug/run_id=Testing/logs/run_config.yaml\n"
     ]
    }
   ],
   "source": [
    "experiment = 'DN_Screen'\n",
    "version = 'debug'\n",
    "# base_dir = Path(f'/gscratch/portia/eabe/Pugliese_2025/{experiment}/{version}')\n",
    "base_dir = Path(f'/data/users/eabe/Pugliese_2025/{experiment}/{version}')\n",
    "run_cfg_list = sorted(list(Path(base_dir).rglob('run_config.yaml')))\n",
    "for n, run_cfg in enumerate(run_cfg_list):\n",
    "    print(n, run_cfg)\n",
    "\n",
    "# ###### New runs ###### \n",
    "\n",
    "cfg_num = 0\n",
    "cfg = OmegaConf.load(run_cfg_list[cfg_num])\n",
    "# run_id = int(run_cfg_list[cfg_num].parent.parent.stem.split('=')[1])\n",
    "print('Loading:', cfg.experiment.name, run_cfg_list[cfg_num])\n",
    "\n",
    "# fig_dir = Path('/data/users/eabe/biomech_model/Flybody/RL_Flybody/debug/figures')\n",
    "##### Reset paths for local computer #####\n",
    "with initialize(version_base=None, config_path=\"../configs\"):\n",
    "    cfg_temp=compose(config_name='config.yaml',overrides= [f\"experiment={experiment}\", \"paths=glados\", f\"version={cfg.version}\", f'run_id=Testing'], return_hydra_config=True)\n",
    "    HydraConfig.instance().set_config(cfg_temp)\n",
    "\n",
    "cfg.paths = cfg_temp.paths\n",
    "\n",
    "# Try to convert paths, but handle cases where interpolations might fail\n",
    "try:\n",
    "    cfg.paths = convert_dict_to_path(cfg.paths)\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Warning: Could not resolve all path interpolations: {e}\")\n",
    "    print(\"Using temporary config paths instead...\")\n",
    "    cfg.paths = convert_dict_to_path(cfg_temp.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pytree(pytree):\n",
    "    \"\"\"\n",
    "    path_filter: function that takes key_path tuple and returns True/False\n",
    "    \"\"\"\n",
    "    def process_leaf(key_path, leaf):\n",
    "       print(f\"Key Path: {key_path[0]}, Leaf: {leaf.shape}\")\n",
    "\n",
    "    return jax.tree.map_with_path(process_leaf, pytree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network configuration...\n",
      "Key Path: .W, Leaf: (4604, 4604)\n",
      "Key Path: .tau, Leaf: (16, 4604)\n",
      "Key Path: .a, Leaf: (16, 4604)\n",
      "Key Path: .threshold, Leaf: (16, 4604)\n",
      "Key Path: .fr_cap, Leaf: (16, 4604)\n",
      "Key Path: .input_currents, Leaf: (933, 16, 4604)\n",
      "Key Path: .seeds, Leaf: (16, 2)\n",
      "Key Path: .exc_dn_idxs, Leaf: (933,)\n",
      "Key Path: .inh_dn_idxs, Leaf: (385,)\n",
      "Key Path: .exc_in_idxs, Leaf: (1484,)\n",
      "Key Path: .inh_in_idxs, Leaf: (1658,)\n",
      "Key Path: .mn_idxs, Leaf: (144,)\n",
      "Key Path: .W_mask, Leaf: (16, 4604, 4604)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuronParams(W=None, tau=None, a=None, threshold=None, fr_cap=None, input_currents=None, seeds=None, exc_dn_idxs=None, inh_dn_idxs=None, exc_in_idxs=None, inh_in_idxs=None, mn_idxs=None, W_mask=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading network configuration...\")\n",
    "W_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "# Prepare parameters\n",
    "neuron_params = prepare_neuron_params(cfg, W_table, cfg.paths.ckpt_dir / 'neuron_params.h5')\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "mn_mask = jnp.isin(jnp.arange(sim_params.n_neurons), neuron_params.mn_idxs)\n",
    "sim_config = parse_simulation_config(cfg)\n",
    "##### For pruning add stim neuron to mn_mask to remove from min circuit #####\n",
    "stim_neuron = jnp.asarray(cfg.experiment.stimNeurons[0])\n",
    "mn_mask = mn_mask.at[stim_neuron].set(True)\n",
    "simulation_type = \"baseline\"\n",
    "# results = run_simulation_batched(\n",
    "#     neuron_params, sim_params, simulation_type,\n",
    "#     batch_size=None\n",
    "# )\n",
    "print_pytree(neuron_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exc_dns = W_table.loc[\n",
    "    (W_table[\"class\"] == \"descending neuron\") & \n",
    "    (W_table[\"predictedNt\"] == \"acetylcholine\")\n",
    "]\n",
    "stim_neurons = [[neuron] for neuron in all_exc_dns.index.to_list()]\n",
    "stim_inputs = [cfg.experiment.stimI[0]] * len(stim_neurons)\n",
    "cfg.experiment.stimNeurons = stim_neurons\n",
    "cfg.experiment.stimI = stim_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = neuron_params.W\n",
    "tau = neuron_params.tau[0]\n",
    "a = neuron_params.a[0]\n",
    "threshold = neuron_params.threshold[0]\n",
    "fr_cap = neuron_params.fr_cap[0]\n",
    "inputs = jnp.zeros_like(neuron_params.input_currents[0,0])\n",
    "inputs = inputs.at[stim_neurons[65][0]].set(100000.0)  # Set the input current for the stimulus neuron\n",
    "noise_stdv = sim_params.noise_stdv\n",
    "t_axis = sim_params.t_axis\n",
    "T = sim_params.T\n",
    "dt = sim_params.dt\n",
    "pulse_start = sim_params.pulse_start\n",
    "pulse_end = sim_params.pulse_end\n",
    "r_tol = sim_params.r_tol\n",
    "a_tol = sim_params.a_tol\n",
    "seed = neuron_params.seeds[0]\n",
    "\n",
    "W_reweighted = reweight_connectivity(W, sim_params.exc_multiplier, sim_params.inh_multiplier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, solution = run_single_simulation(\n",
    "        W_reweighted, tau, a, threshold, fr_cap, inputs, sim_params.noise_stdv,\n",
    "        sim_params.t_axis, sim_params.T, sim_params.dt,\n",
    "        sim_params.pulse_start, sim_params.pulse_end,\n",
    "        sim_params.r_tol, sim_params.a_tol, seed,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diffrax._solution.RESULTS<The maximum number of solver steps was reached. Try increasing `max_steps`.>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_steps': Array(100000, dtype=int32, weak_type=True),\n",
       " 'num_accepted_steps': Array(12, dtype=int32, weak_type=True),\n",
       " 'num_rejected_steps': Array(99988, dtype=int32, weak_type=True),\n",
       " 'num_steps': Array(100000, dtype=int32, weak_type=True)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(False, dtype=bool),\n",
       " Array(True, dtype=bool),\n",
       " Array([inf, inf, inf, ..., inf, inf, inf], dtype=float32),\n",
       " Array(4604, dtype=int32),\n",
       " Array(4604, dtype=int32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rates = jnp.max(result, axis=-1)\n",
    "n_active = jnp.sum(jnp.sum(result, axis=-1) > 0)\n",
    "n_high_fr = jnp.sum(max_rates > sim_config.high_fr_threshold)\n",
    "jnp.any(jnp.isnan(result)), jnp.any(jnp.isinf(result)), max_rates, n_active, n_high_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(inf, dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.max(result,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([31], dtype=int32),)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.where(neuron_params.input_currents[0,0]>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.sim_utils import compute_oscillation_score, neuron_oscillation_score\n",
    "\n",
    "results = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_Rs.npz\").todense().astype(np.float32)\n",
    "# min_circuit = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_mini_circuits.npz\").todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[jnp.where(min_circuit[n] & ~mn_mask) for n in range(min_circuit.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[jnp.where((jnp.sum(results[0][n],axis=-1)>0) & ~mn_mask)[0] for n in range(results.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_circuits_all = jnp.stack([((jnp.sum(results[:,n],axis=-1)>0) & ~mn_mask) for n in range(results.shape[1])],axis=1)\n",
    "min_circuits_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.where(~(min_circuit[0] == min_circuits_all[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_mask_init = jnp.ones_like(neuron_params.W_mask, dtype=jnp.bool)\n",
    "\n",
    "W_mask_new = (W_mask_init * min_circuits_all[:, :, None] * min_circuits_all[:, None, :]).astype(jnp.bool_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 322\n",
    "plt.plot(results[0,n,min_circuits_all[n]].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[0][0]\n",
    "\n",
    "\n",
    "w_table = pd.read_csv(cfg.experiment.dfPath,index_col=0)\n",
    "# 10093 = bdn2, 10707 = exc 1, 11751 = exc 2, 13905 = inh 1\n",
    "nonmns_idxs = w_table.loc[(w_table[\"bodyId\"]==10093) | (w_table[\"bodyId\"]==10707) | (w_table[\"bodyId\"]==11751) | (w_table[\"bodyId\"]==13905)].index\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(18, 6))\n",
    "for i in nonmns_idxs:\n",
    "    axs[0].plot(R[i])\n",
    "axs[0].set_title(\"Non-Motor Neurons\")\n",
    "for i in mn_idxs:\n",
    "    axs[1].plot(R[i])\n",
    "axs[1].set_title(\"Motor Neurons\")\n",
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "\n",
    "# scores001 = []\n",
    "# for i in range(results.shape[1]):\n",
    "#     R = results[0][i]\n",
    "#     max_frs = jnp.max(R, axis=-1)\n",
    "#     active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "#     activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "#     score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "#     scores001.append(score)\n",
    "# scores001 = jnp.concatenate(scores001, axis=-1)\n",
    "# axs[2].hist(scores001, bins=50, density=True)\n",
    "# plt.savefig(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=Testing/sim.noise=True/figures/Example_R.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sim_utils import compute_oscillation_score, neuron_oscillation_score\n",
    "clip_start = 250\n",
    "oscillation_threshold = 0.2\n",
    "# Load data (this part stays on CPU)\n",
    "w_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "## Initialize parameters\n",
    "neuron_params = prepare_neuron_params(cfg, w_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "all_neurons = w_table.index.to_numpy()\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "# max_frs = jnp.max(results[0], axis=-1)\n",
    "# mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "# active_mask = ((max_frs>0) & mn_mask)\n",
    "prominence = 0.05\n",
    "# Compute oscillation score\n",
    "# oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape, active_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "\n",
    "scores001 = []\n",
    "for i in range(results001.shape[1]):\n",
    "    R = results001[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores001.append(score)\n",
    "scores01 = []\n",
    "for i in range(results01.shape[1]):\n",
    "    R = results01[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores01.append(score)\n",
    "scores1 = []\n",
    "for i in range(results1.shape[1]):\n",
    "    R = results1[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores1.append(score)\n",
    "scores10 = []\n",
    "for i in range(results10.shape[1]):\n",
    "    R = results10[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores10.append(score)\n",
    "    \n",
    "    \n",
    "    \n",
    "# score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "# print(f\"Score: {jnp.nanmean(score)}, Frequency: {jnp.nanmean(frequency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "axs[0].hist(jnp.concatenate(scores001, axis=-1), bins=25)\n",
    "axs[0].set_xlabel(\"Oscillation Score\")\n",
    "axs[0].set_title(\"Noise=0.01\")\n",
    "axs[1].hist(jnp.concatenate(scores01, axis=-1), bins=25)\n",
    "axs[1].set_xlabel(\"Oscillation Score\")\n",
    "axs[1].set_title(\"Noise=0.1\")\n",
    "axs[2].hist(jnp.concatenate(scores1, axis=-1), bins=25)\n",
    "axs[2].set_xlabel(\"Oscillation Score\")\n",
    "axs[2].set_title(\"Noise=1\")\n",
    "axs[3].hist(jnp.concatenate(scores10, axis=-1), bins=25)\n",
    "axs[3].set_xlabel(\"Oscillation Score\")\n",
    "axs[3].set_title(\"Noise=10\")\n",
    "plt.savefig(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=noisy_inputs/figures/oscillation_scores.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, config = load_vnc_net(cfg)\n",
    "simulator = OptimizedSimulator(params, config)\n",
    "# W, W_table = load_connectivity(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_queue = simulator._create_work_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.shuffle_utils import shuffle_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newkey, key = jax.random.split(work_queue[0]['seed'])\n",
    "idxs = params.inh_dn_idxs\n",
    "W = params.W\n",
    "W_shuff = shuffle_W(W, key, idxs, independent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.all(np.sum(results,axis=-1)==0,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[0][0]\n",
    "\n",
    "\n",
    "wTable = pd.read_csv(\"../data/manc t1 connectome data/wTable_20231020_DNtoMN_unsorted_withModules.csv\",index_col=0)\n",
    "nonMns = wTable.loc[(wTable[\"bodyId\"]==10093) | (wTable[\"bodyId\"]==10707) | (wTable[\"bodyId\"]==13905) | (wTable[\"bodyId\"]==11751)]\n",
    "mnIdxs = wTable.loc[wTable[\"class\"]==\"motor neuron\"].index\n",
    "\n",
    "\n",
    "for i in nonMns.index:\n",
    "# for i in mnIdxs:\n",
    "    plt.plot(R[i])\n",
    "    #plt.plot(Rtsp[i])\n",
    "\n",
    "print(np.mean(R))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing osc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_Rs.npz\").todense().astype(np.float32)\n",
    "\n",
    "wTable = pd.read_csv(\"../data/manc t1 connectome data/wTable_20231020_DNtoMN_unsorted_withModules.csv\",index_col=0)\n",
    "non_mns = (wTable.loc[(wTable[\"bodyId\"]==10093) | (wTable[\"bodyId\"]==10707) | (wTable[\"bodyId\"]==13905) | (wTable[\"bodyId\"]==11751)]).values\n",
    "mn_idxs = wTable.loc[wTable[\"class\"]==\"motor neuron\"].index.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "def neuron_oscillation_score_helper_old(activity,prominence):\n",
    "    activity = activity-np.min(activity)\n",
    "    activity = 2 * activity/np.max(activity) - 1\n",
    "\n",
    "    autocorr = np.correlate(activity,activity,mode=\"full\") / np.inner(activity,activity)\n",
    "    lags = signal.correlation_lags(len(activity),len(activity))\n",
    "    autocorr = autocorr[lags>0]\n",
    "    lags = lags[lags>0]\n",
    "\n",
    "    peaks, peakProperties = signal.find_peaks(autocorr,height=(None,None),prominence=prominence)\n",
    "    if len(peaks) > 0:\n",
    "        score = np.min([np.max(peakProperties[\"peak_heights\"]),np.max(peakProperties[\"prominences\"])])\n",
    "        frequency = 1 / peaks[np.argmax(peakProperties[\"prominences\"])]\n",
    "    else:\n",
    "        score = 0\n",
    "        frequency = 0\n",
    "\n",
    "    return score, frequency\n",
    "\n",
    "def neuron_oscillation_score_old(activity, returnFrequency=False,prominence=0.05):\n",
    "    rawScore, frequency = neuron_oscillation_score_helper_old(activity,prominence)\n",
    "    # normalize to sine wave of the same frequency and duration\n",
    "    if rawScore == 0:\n",
    "        score = 0\n",
    "    else:\n",
    "        refSinScore, _ = neuron_oscillation_score_helper_old(np.sin(2*np.pi*frequency*np.arange(len(activity))),prominence)\n",
    "        refCosScore, _ = neuron_oscillation_score_helper_old(np.cos(2*np.pi*frequency*np.arange(len(activity))),prominence)\n",
    "        refScore = np.max((refSinScore,refCosScore))\n",
    "        score = rawScore / refScore\n",
    "\n",
    "    if returnFrequency:\n",
    "        return score, frequency\n",
    "    else:\n",
    "        return score\n",
    "\n",
    "def sim_oscillation_score_old(R,activeMnIdxs,start=None,end=None,returnFrequency=False):\n",
    "    \"\"\"calculate oscillation score for a simulation\"\"\"\n",
    "    if start is None:\n",
    "        start = 0\n",
    "    if end is None:\n",
    "        end = -1\n",
    "\n",
    "    if returnFrequency:\n",
    "        neuronOscillationScores = []\n",
    "        frequencies = []\n",
    "\n",
    "        for j in activeMnIdxs:\n",
    "            score, freq = neuron_oscillation_score_old(R[j][start:end],returnFrequency=True)\n",
    "            neuronOscillationScores.append(score)\n",
    "            frequencies.append(freq)\n",
    "        return np.mean(neuronOscillationScores), np.nanmean(frequencies)\n",
    "        \n",
    "    else:\n",
    "        neuronOscillationScores = [neuron_oscillation_score_old(R[j][start:end]) for j in activeMnIdxs] # scores for each neuron\n",
    "        return np.mean(neuronOscillationScores) # average for the simulation\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[0][0]\n",
    "np_R = np.asarray(R)\n",
    "maxFrs = np.max(np_R,axis=-1)\n",
    "activeMnIdxs = mn_idxs[maxFrs[mn_idxs]>0]\n",
    "plt.plot(np_R[activeMnIdxs].T)\n",
    "plt.show()\n",
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 200\n",
    "print(f\"Start index: {start}\")\n",
    "score, freq = sim_oscillation_score_old(R,activeMnIdxs,start=start,end=None,returnFrequency=True)\n",
    "print(f\"Score: {score}, Frequency: {freq}\")\n",
    "\n",
    "##### New Method #####\n",
    "# R = results[0][0]\n",
    "\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "\n",
    "score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "\n",
    "print(f\"Score: {jnp.nanmean(score)}, Frequency: {jnp.nanmean(frequency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "R = results\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[2]), mn_idxs)\n",
    "active_mask = ((max_frs > 0) & mn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.signal import correlate\n",
    "from src.sim_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = results[0][1][451, start:]  # Adjusted to match the original code's start index\n",
    "\n",
    "activity = activity - jnp.min(activity, axis=-1, keepdims=True)\n",
    "activity = 2 * activity / jnp.max(activity, axis=-1, keepdims=True) - 1\n",
    "\n",
    "autocorr = autocorrelation_1d(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr_scipy = correlate(activity, activity, mode='full', method='fft')\n",
    "autocorr_scipy = autocorr_scipy/jnp.max(autocorr_scipy)\n",
    "autocorr_old = np.correlate(activity,activity,mode=\"full\") / np.inner(activity,activity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(autocorr, label='JAX Autocorrelation')\n",
    "plt.plot(autocorr_scipy, label='SciPy Autocorrelation')\n",
    "plt.plot(autocorr_old, label='Old NumPy Autocorrelation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.where(active_mask[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "R = results[0][0]\n",
    "\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "\n",
    "score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "\n",
    "print(f\"Score: {jnp.nanmean(score)}, Frequency: {jnp.nanmean(frequency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sim_utils import neuron_oscillation_score\n",
    "\n",
    "experiment='prune_test'\n",
    "sim = 'prune_network'\n",
    "with initialize(version_base=None, config_path=\"../configs\"):\n",
    "    cfg=compose(config_name='config.yaml', overrides= [f\"experiment={experiment}\", f\"sim={sim}\", \"paths=glados\", \"version=debug\", f'run_id=Testing'],return_hydra_config=True,)\n",
    "    HydraConfig.instance().set_config(cfg)\n",
    "\n",
    "for k in cfg.paths.keys():\n",
    "    if (k != 'user'):\n",
    "        cfg.paths[k] = Path(cfg.paths[k])\n",
    "        cfg.paths[k].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def print_inds(arr, name=''):\n",
    "    print(f\"Indices for {name}: {jnp.where(arr)[0].shape}\")\n",
    "    return jnp.where(arr)[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full pipeline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_table = load_wTable(cfg.experiment.dfPath)\n",
    "\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "\n",
    "# Prepare parameters\n",
    "neuron_params = prepare_neuron_params(cfg, W_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "sim_config = parse_simulation_config(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sims = sim_params.n_stim_configs * sim_params.n_param_sets\n",
    "n_devices = jax.device_count()\n",
    "\n",
    "# Calculate batch size\n",
    "batch_size = sim_config.batch_size\n",
    "if batch_size is None:\n",
    "    batch_size = calculate_optimal_batch_size(\n",
    "        sim_params.n_neurons, len(sim_params.t_axis), n_devices\n",
    "    )\n",
    "\n",
    "# Adjust batch size for multiple devices\n",
    "if n_devices > 1:\n",
    "    batch_size = (batch_size // n_devices) * n_devices\n",
    "    if batch_size == 0:\n",
    "        batch_size = n_devices\n",
    "\n",
    "# Get batch processing function\n",
    "batch_func = get_batch_function(sim_config)\n",
    "\n",
    "# Create parallel version for multiple devices\n",
    "if n_devices > 1:\n",
    "    batch_func = pmap(batch_func, axis_name=\"device\", in_axes=(None, None, 0))\n",
    "\n",
    "print(f\"Running {total_sims} {sim_config.sim_type} simulations with batch size {batch_size} on {n_devices} device(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pre-compute static values that won't change during the loop\n",
    "oscillation_threshold_val = float(sim_config.oscillation_threshold)\n",
    "clip_start_val = int(sim_params.pulse_start / sim_params.dt) + 200\n",
    "\n",
    "# Create a version of update_single_sim_state with static args baked in\n",
    "def update_state_with_static_args(state, R, mn_mask):\n",
    "    jax.debug.print(\"W_mask shape: {W_mask.shape}\", W_mask=state.W_mask)\n",
    "    return update_single_sim_state(state, R, mn_mask, oscillation_threshold_val, clip_start_val)\n",
    "\n",
    "# Apply JIT to the wrapper function (not the original)\n",
    "jitted_update = jax.jit(update_state_with_static_args)\n",
    "\n",
    "# Now vmap this wrapper with only the traced arguments\n",
    "batch_update = jax.vmap(\n",
    "    jitted_update, \n",
    "    in_axes=(0, 0, 0)  # state, R, mn_mask - all batched\n",
    ")\n",
    "\n",
    "# Create parallel versions for multiple devices\n",
    "if n_devices > 1:\n",
    "    batch_update = pmap(batch_update, axis_name=\"device\", in_axes=(0, 0, 0))\n",
    "\n",
    "# Rest of the function...\n",
    "all_results = []\n",
    "n_batches = (total_sims + batch_size - 1) // batch_size\n",
    "\n",
    "for i in range(n_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, total_sims)\n",
    "    actual_batch_size = end_idx - start_idx\n",
    "    \n",
    "    batch_indices = jnp.arange(start_idx, end_idx)\n",
    "    \n",
    "    # Pad batch_indices if necessary for pmap\n",
    "    if n_devices > 1 and len(batch_indices) < batch_size:\n",
    "        pad_size = batch_size - len(batch_indices)\n",
    "        batch_indices = jnp.concatenate([\n",
    "            batch_indices, \n",
    "            jnp.repeat(batch_indices[-1], pad_size)\n",
    "        ])\n",
    "    \n",
    "    mn_idxs = neuron_params.mn_idxs\n",
    "    \n",
    "    # Initialize state for this batch\n",
    "    current_batch_size = len(batch_indices)\n",
    "    state = initialize_pruning_state(neuron_params, sim_params, current_batch_size)\n",
    "\n",
    "    # Reshape state for pmap if using multiple devices\n",
    "    if n_devices > 1:\n",
    "        state = reshape_state_for_pmap(state, n_devices)\n",
    "        batch_indices = batch_indices.reshape(n_devices, -1)\n",
    "\n",
    "    # Main pruning loop\n",
    "    iteration = 0\n",
    "    \n",
    "    # Clear GPU memory before processing\n",
    "    jax.clear_caches()\n",
    "    \n",
    "    # while True:\n",
    "    # Check convergence condition\n",
    "    all_converged = jnp.all(state.min_circuit)\n",
    "    \n",
    "    if all_converged or (iteration >= sim_config.max_pruning_iterations):\n",
    "        break\n",
    "        \n",
    "    start_time = time.time()\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    \n",
    "    # Update neuron parameters W_mask based on the current state\n",
    "    if n_devices > 1:\n",
    "        flat_W_mask = reshape_state_from_pmap(state).W_mask\n",
    "        neuron_params = neuron_params._replace(W_mask=flat_W_mask)\n",
    "    else:\n",
    "        neuron_params = neuron_params._replace(W_mask=state.W_mask)\n",
    "\n",
    "    # Run simulation\n",
    "    batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "    \n",
    "    # Create mn_mask and broadcast to batch dimensions\n",
    "    mn_mask = jnp.isin(jnp.arange(sim_params.n_neurons), mn_idxs)\n",
    "    \n",
    "    if n_devices > 1:\n",
    "        # For pmap, broadcast to (n_devices, batch_per_device, n_neurons)\n",
    "        batch_per_device = batch_indices.shape[1]\n",
    "        mn_mask_batch = jnp.broadcast_to(mn_mask, (n_devices, batch_per_device, len(mn_mask)))\n",
    "    else:\n",
    "        # For single device, broadcast to (batch_size, n_neurons)\n",
    "        mn_mask_batch = jnp.broadcast_to(mn_mask, (batch_results.shape[0], len(mn_mask)))\n",
    "        \n",
    "    # Update state - now only passing traced arguments\n",
    "    print(\"Updating state with batch results\")\n",
    "    print(f\"W_mask shape: {state.W_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_pytree(neuron_params)\n",
    "# sim_config\n",
    "# print_pytree(batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.W_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscillation_threshold = 0.2\n",
    "# Load data (this part stays on CPU)\n",
    "w_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "## Initialize parameters\n",
    "neuron_params = prepare_neuron_params(cfg, w_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "all_neurons = w_table.index.to_numpy()\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "clip_start = int(cfg.sim.pulseStart / cfg.sim.dt) + 100\n",
    "\n",
    "total_sims = sim_params.n_stim_configs * sim_params.n_param_sets\n",
    "batch_size = getattr(cfg.experiment, \"batch_size\", None)\n",
    "if batch_size is None:\n",
    "    batch_size = calculate_optimal_batch_size(\n",
    "        sim_params.n_neurons, len(sim_params.t_axis)\n",
    "    )\n",
    "    \n",
    "batch_func = process_batch_prune\n",
    "# Create parallel version for multiple devices\n",
    "if jax.device_count() > 1:\n",
    "    batch_func = pmap(batch_func, axis_name=\"device\", in_axes=(None, None, 0))\n",
    "    batch_size = (batch_size // jax.device_count()) * jax.device_count()\n",
    "\n",
    "print(f\"Running {total_sims} simulations with batch size {batch_size}\")\n",
    "\n",
    "# Process in batches\n",
    "all_results = []\n",
    "n_batches = (total_sims + batch_size - 1) // batch_size\n",
    "\n",
    "# for i in range(n_batches):\n",
    "i = 0 \n",
    "start_idx = i * batch_size\n",
    "end_idx = min((i + 1) * batch_size, total_sims)\n",
    "\n",
    "batch_indices = jnp.arange(start_idx, end_idx)\n",
    "\n",
    "# Pad if necessary for pmap\n",
    "if jax.device_count() > 1 and len(batch_indices) < batch_size:\n",
    "    pad_size = batch_size - len(batch_indices)\n",
    "    batch_indices = jnp.concatenate([\n",
    "        batch_indices, \n",
    "        jnp.repeat(batch_indices[-1], pad_size)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mn_idxs = neuron_params.mn_idxs\n",
    "all_neurons = jnp.arange(neuron_params.W.shape[-1])\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "\n",
    "clip_start = int(sim_params.pulse_start / sim_params.dt) + 100\n",
    "# Initialize state\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "W_mask = jnp.full((n_sims, neuron_params.W.shape[0], neuron_params.W.shape[1]), 1, dtype=jnp.float32)\n",
    "interneuron_mask = jnp.full((n_sims, W_mask.shape[-1]),fill_value=False, dtype=jnp.bool_)\n",
    "interneuron_mask = interneuron_mask.at[:,in_idxs].set(True)\n",
    "level = jnp.zeros((n_sims,1), dtype=jnp.int32)\n",
    "total_removed_neurons = jnp.full((n_sims, W_mask.shape[-1]), False, dtype=jnp.bool)\n",
    "removed_stim_neurons = jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "neurons_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "prev_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "last_removed =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool) # Use False for None\n",
    "min_circuit = jnp.full((n_sims,1), False)\n",
    "\n",
    "# Initialize probabilities\n",
    "exclude_mask = (~interneuron_mask)\n",
    "p_arrays = jax.vmap(removal_probability)(jnp.ones(len(interneuron_mask)), exclude_mask)\n",
    "\n",
    "# initialize pruning state\n",
    "state = Pruning_state(\n",
    "    W_mask=W_mask,\n",
    "    interneuron_mask=interneuron_mask,\n",
    "    level=level,\n",
    "    total_removed_neurons=total_removed_neurons,\n",
    "    removed_stim_neurons=removed_stim_neurons,\n",
    "    neurons_put_back=neurons_put_back,\n",
    "    prev_put_back=prev_put_back,\n",
    "    last_removed=last_removed,\n",
    "    remove_p=p_arrays,\n",
    "    min_circuit=min_circuit,\n",
    "    keys=neuron_params.seeds\n",
    ")\n",
    "\n",
    "iter_start = 0  # Starting iteration\n",
    "# Main pruning loop\n",
    "iteration = iter_start\n",
    "max_iterations = 1  # Safety limit\n",
    "while not jnp.all(min_circuit) and (iteration < max_iterations):\n",
    "    start_time = time.time()\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    # Update neuron parameters W_mask based on the current state\n",
    "    neuron_params = neuron_params._replace(W_mask=state.W_mask)\n",
    "    # Run simulation (this would call your simulation function)\n",
    "    # Reshape for devices if using pmap\n",
    "    if jax.device_count() > 1:\n",
    "        batch_indices = batch_indices.reshape(jax.device_count(), -1)\n",
    "        batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "        batch_results = batch_results.reshape(-1, *batch_results.shape[2:])\n",
    "        batch_results = batch_results[:end_idx - start_idx]  # Remove padding\n",
    "    else:\n",
    "        batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "    \n",
    "    n = 0 \n",
    "    state = jax.vmap(update_single_sim_state, in_axes=(0, 0, None, None, None))(state, batch_results, mn_idxs, oscillation_threshold, clip_start)\n",
    "    iteration += 1\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  Total time: {elapsed:.2f} seconds\")\n",
    "\n",
    "# batch_results = jax.device_put(batch_results, jax.devices(\"cpu\")[0])\n",
    "# all_results.append(batch_results)\n",
    "# print(f\"Batch {i + 1}/{n_batches} completed\")\n",
    "\n",
    "# del batch_results  # Free memory\n",
    "# gc.collect()  # Force garbage collection\n",
    "\n",
    "# Combine results\n",
    "# results = jnp.concatenate(all_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mn_idxs = neuron_params.mn_idxs\n",
    "all_neurons = jnp.arange(neuron_params.W.shape[-1])\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "\n",
    "clip_start = int(sim_params.pulse_start / sim_params.dt) + 100\n",
    "# Initialize state\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "W_mask = jnp.full((n_sims, neuron_params.W.shape[0], neuron_params.W.shape[1]), 1, dtype=jnp.float32)\n",
    "interneuron_mask = jnp.full((n_sims, W_mask.shape[-1]),fill_value=False, dtype=jnp.bool_)\n",
    "interneuron_mask = interneuron_mask.at[:,in_idxs].set(True)\n",
    "level = jnp.zeros((n_sims,1), dtype=jnp.int32)\n",
    "total_removed_neurons = jnp.full((n_sims, W_mask.shape[-1]), False, dtype=jnp.bool)\n",
    "removed_stim_neurons = jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "neurons_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "prev_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "last_removed =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool) # Use False for None\n",
    "min_circuit = jnp.full((n_sims,1), False)\n",
    "\n",
    "# Initialize probabilities\n",
    "exclude_mask = (~interneuron_mask)\n",
    "p_arrays = jax.vmap(removal_probability)(jnp.ones(len(interneuron_mask)), exclude_mask)\n",
    "\n",
    "# initialize pruning state\n",
    "state = Pruning_state(\n",
    "    W_mask=W_mask[0],\n",
    "    interneuron_mask=interneuron_mask[0],\n",
    "    level=level[0],\n",
    "    total_removed_neurons=total_removed_neurons[0],\n",
    "    removed_stim_neurons=removed_stim_neurons[0],\n",
    "    neurons_put_back=neurons_put_back[0],\n",
    "    prev_put_back=prev_put_back[0],\n",
    "    last_removed=last_removed[0],\n",
    "    remove_p=p_arrays[0],\n",
    "    min_circuit=min_circuit[0],\n",
    "    keys=neuron_params.seeds[0],\n",
    ")\n",
    "R = batch_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unpack state\n",
    "(W_mask, interneuron_mask, level, total_removed_neurons, removed_stim_neurons,\n",
    "    neurons_put_back, last_removed, remove_p, min_circuit, key) = state\n",
    "\n",
    "# Get active MN activity using JAX-compatible approach\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "active_mask = ((max_frs>0) & mn_mask)\n",
    "\n",
    "# Compute oscillation score\n",
    "oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "\n",
    "# Check if oscillation is below threshold or NaN\n",
    "reset_condition = (oscillation_score < oscillation_threshold) | jnp.isnan(oscillation_score)\n",
    "\n",
    "# Identify currently silent interneurons (these will be permanently removed)\n",
    "silent_interneurons = interneuron_mask & (max_frs <= 0)\n",
    "\n",
    "key_next, subkey_continue, subkey_reset = random.split(key, 3)\n",
    "\n",
    "# === CONTINUE BRANCH: Normal pruning (oscillation is good) ===\n",
    "# Permanently remove silent interneurons\n",
    "total_removed_continue = total_removed_neurons | silent_interneurons\n",
    "\n",
    "# Update probabilities - exclude non-interneurons and removed neurons\n",
    "exclude_mask_continue = (~interneuron_mask) | total_removed_continue\n",
    "p_continue = removal_probability(max_frs, exclude_mask_continue)\n",
    "\n",
    "# Sample new neuron to remove (only from available interneurons)\n",
    "neuron_idx_continue = jax_choice(subkey_continue, jnp.arange(len(max_frs)), p_continue)\n",
    "\n",
    "# Update removed neurons\n",
    "removed_stim_continue = removed_stim_neurons.at[neuron_idx_continue].set(True)\n",
    "total_removed_continue = total_removed_continue.at[neuron_idx_continue].set(True)\n",
    "\n",
    "# Track what was removed this iteration (both silent and stimulated)\n",
    "newly_silent_continue = silent_interneurons & (~total_removed_neurons)  # Only newly silent\n",
    "last_removed_continue = jnp.full(last_removed.shape, False, dtype=jnp.bool_)\n",
    "last_removed_continue = last_removed_continue.at[neuron_idx_continue].set(True)  # Stimulated removal\n",
    "last_removed_continue = last_removed_continue | newly_silent_continue  # Add newly silent\n",
    "\n",
    "# Update other state\n",
    "level_continue = level + 1\n",
    "neurons_put_back_continue = neurons_put_back  # Unchanged\n",
    "min_circuit_continue = False  # Not converged yet\n",
    "\n",
    "# === RESET BRANCH: Restore last removed and try again ===\n",
    "# Restore ALL neurons from last_removed (both stimulated and those that went silent)\n",
    "# This includes neurons that went silent due to the last stimulated removal\n",
    "\n",
    "# Restore stimulated neurons from last removal\n",
    "removed_stim_reset = removed_stim_neurons & (~last_removed)\n",
    "\n",
    "# For total_removed: keep permanent removals from before last iteration, \n",
    "# add current silent neurons, but restore all last_removed neurons\n",
    "permanent_before_last = total_removed_neurons & (~last_removed)\n",
    "# Current silent neurons are those silent now (may include some that weren't silent before)\n",
    "# But we need to be careful not to restore neurons that are currently silent due to OTHER reasons\n",
    "# Only add neurons to total_removed if they are silent AND were not in last_removed\n",
    "currently_silent_not_restored = silent_interneurons & (~last_removed)\n",
    "total_removed_reset = permanent_before_last | currently_silent_not_restored\n",
    "\n",
    "# Track neurons being put back - ALL neurons from last_removed\n",
    "# This includes both the stimulated neuron and any neurons that went silent due to that removal\n",
    "restored_neurons = last_removed  # All neurons from last_removed are being restored\n",
    "neurons_put_back_reset = neurons_put_back | restored_neurons\n",
    "\n",
    "# Now select a different neuron to remove (avoid the restored ones)\n",
    "exclude_mask_reset = (~interneuron_mask) | total_removed_reset | restored_neurons\n",
    "p_reset = removal_probability(max_frs, exclude_mask_reset)\n",
    "\n",
    "# Check how many neurons are available\n",
    "available_neurons_reset = jnp.sum(interneuron_mask & (~exclude_mask_reset))\n",
    "\n",
    "# Select neuron to remove\n",
    "neuron_idx_reset = jax_choice(subkey_reset, jnp.arange(len(max_frs)), p_reset)\n",
    "\n",
    "# Only update if we have available neurons (otherwise keep current state)\n",
    "should_remove_new = available_neurons_reset > 0\n",
    "removed_stim_reset = jax.lax.select(\n",
    "    should_remove_new,\n",
    "    removed_stim_reset.at[neuron_idx_reset].set(True),\n",
    "    removed_stim_reset\n",
    ")\n",
    "total_removed_reset = jax.lax.select(\n",
    "    should_remove_new,\n",
    "    total_removed_reset.at[neuron_idx_reset].set(True),\n",
    "    total_removed_reset\n",
    ")\n",
    "\n",
    "# Track what was newly removed this iteration\n",
    "last_removed_reset = jnp.full(last_removed.shape, False, dtype=jnp.bool_)\n",
    "last_removed_reset = jax.lax.select(\n",
    "    should_remove_new,\n",
    "    last_removed_reset.at[neuron_idx_reset].set(True),\n",
    "    last_removed_reset\n",
    ")\n",
    "\n",
    "# Add any newly silent neurons (those that are silent now but weren't in total_removed_neurons before)\n",
    "# These are neurons that became silent due to current network state, not due to last removal\n",
    "newly_silent_reset = silent_interneurons & (~total_removed_neurons) & (~last_removed)\n",
    "last_removed_reset = last_removed_reset | newly_silent_reset\n",
    "\n",
    "# Keep level the same (we're trying again, not progressing)\n",
    "level_reset = level\n",
    "\n",
    "# Check if we've converged - either no more neurons to remove OR we're oscillating\n",
    "# Oscillation detection: if we're restoring neurons we've put back before, we're in a loop\n",
    "oscillation_detected = jnp.any(restored_neurons & neurons_put_back)\n",
    "min_circuit_reset = (available_neurons_reset <= 2) | oscillation_detected\n",
    "\n",
    "# === SELECT BETWEEN BRANCHES ===\n",
    "# Use jax.lax.select to choose between continue and reset results\n",
    "final_total_removed = jax.lax.select(reset_condition, total_removed_reset, total_removed_continue)\n",
    "final_removed_stim = jax.lax.select(reset_condition, removed_stim_reset, removed_stim_continue)\n",
    "final_last_removed = jax.lax.select(reset_condition, last_removed_reset, last_removed_continue)\n",
    "final_neurons_put_back = jax.lax.select(reset_condition, neurons_put_back_reset, neurons_put_back_continue)\n",
    "final_level = jax.lax.select(reset_condition, level_reset, level_continue)\n",
    "final_p = jax.lax.select(reset_condition, p_reset, p_continue)\n",
    "final_min_circuit = jax.lax.select(reset_condition, min_circuit_reset, min_circuit_continue)\n",
    "\n",
    "# Calculate available neurons and check for convergence\n",
    "available_neurons = jnp.sum(interneuron_mask & (~final_total_removed))\n",
    "\n",
    "# Check for oscillation: if we're in reset mode and detected oscillation, we've converged\n",
    "oscillation_converged = reset_condition & final_min_circuit\n",
    "size_converged = available_neurons <= 2\n",
    "final_converged = oscillation_converged | size_converged\n",
    "\n",
    "# Update W_mask to reflect removed neurons\n",
    "W_mask_init = jnp.ones_like(W_mask, dtype=jnp.float32)\n",
    "removed_float = final_total_removed.astype(jnp.float32)\n",
    "kept_mask = 1.0 - removed_float\n",
    "W_mask_new = W_mask_init * kept_mask[:, None] * kept_mask[None, :]\n",
    "\n",
    "# Convert to scalar for jax.lax.select\n",
    "final_converged_scalar = jnp.squeeze(final_converged)\n",
    "\n",
    "# Debug information\n",
    "jax.debug.print(\"Oscillation score: {score}\", score=oscillation_score)\n",
    "jax.debug.print(\"Reset condition (below threshold): {condition}\", condition=reset_condition)\n",
    "jax.debug.print(\"Available neurons: {count}\", count=available_neurons)\n",
    "jax.debug.print(\"Level: {level}\", level=final_level)\n",
    "jax.debug.print(\"Oscillation detected: {detected}\", detected=reset_condition & (final_min_circuit & ~size_converged))\n",
    "jax.debug.print(\"Final converged: {converged}\", converged=final_converged)\n",
    "jax.debug.print(\"Silent neurons removed: {count}\", count=jnp.sum(silent_interneurons))\n",
    "print('\\n')\n",
    "\n",
    "# When converged, preserve current state (don't make further changes)\n",
    "state = Pruning_state(\n",
    "    W_mask=jax.lax.select(final_converged_scalar, W_mask, W_mask_new),\n",
    "    interneuron_mask=interneuron_mask,\n",
    "    level=jax.lax.select(final_converged_scalar, level, final_level),\n",
    "    total_removed_neurons=jax.lax.select(final_converged_scalar, total_removed_neurons, final_total_removed),\n",
    "    neurons_put_back=jax.lax.select(final_converged_scalar, neurons_put_back, final_neurons_put_back),\n",
    "    removed_stim_neurons=jax.lax.select(final_converged_scalar, removed_stim_neurons, final_removed_stim),\n",
    "    last_removed=jax.lax.select(final_converged_scalar, last_removed, final_last_removed),\n",
    "    remove_p=jax.lax.select(final_converged_scalar, remove_p, final_p),\n",
    "    min_circuit=final_converged_scalar,\n",
    "    keys=key_next,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_inds(~load_state.total_removed_neurons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_inds = print_inds(exclude_mask_continue)\n",
    "in_idxs.shape[0] - exclude_inds.shape[0]  # Number of interneurons left after pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_inds(~exclude_mask_continue), print_inds(~exclude_mask_reset), print_inds(~final_total_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pytree(pytree):\n",
    "    \"\"\"\n",
    "    path_filter: function that takes key_path tuple and returns True/False\n",
    "    \"\"\"\n",
    "    def process_leaf(key_path, leaf):\n",
    "       print(f\"Key Path: {key_path[0]}, Leaf: {leaf.shape} dype: {leaf.dtype}\")\n",
    "\n",
    "    return jax.tree.map_with_path(process_leaf, pytree)\n",
    "print_pytree(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from src.sim_utils import compute_oscillation_score\n",
    "from src.optimized_vnc import update_params\n",
    "\n",
    "@dataclass\n",
    "class Pruning_state:\n",
    "    W_mask: jnp.ndarray\n",
    "    interneuron_mask: jnp.ndarray\n",
    "    level: int\n",
    "    total_removed_neurons: jnp.ndarray\n",
    "    neurons_put_back_current: jnp.ndarray\n",
    "    neurons_put_back_prev: jnp.ndarray\n",
    "    removed_stim_neurons: jnp.ndarray\n",
    "    last_removed: jnp.ndarray\n",
    "    remove_p: jnp.ndarray\n",
    "    round_complete: bool\n",
    "    converged: bool\n",
    "    round_number: int\n",
    "    keys: jax.random.PRNGKey\n",
    "    steps_in_current_round: int  # Track steps within current round\n",
    "    total_iterations: int        # Track total iterations for safety\n",
    "\n",
    "def safe_choice(key, logits, exclude_mask):\n",
    "    \"\"\"Safe choice function that works with vmap\"\"\"\n",
    "    # Set excluded neurons to very negative logits\n",
    "    safe_logits = jnp.where(exclude_mask, -1e10, logits)\n",
    "    # Use gumbel trick for sampling\n",
    "    gumbel_noise = jax.random.gumbel(key, safe_logits.shape)\n",
    "    return jnp.argmax(safe_logits + gumbel_noise)\n",
    "\n",
    "def removal_probability_safe(max_frs, exclude_mask):\n",
    "    \"\"\"Safe removal probability that works with vmap\"\"\"\n",
    "    # Create base probabilities (higher firing rate = lower removal probability)\n",
    "    base_probs = 1.0 / (max_frs + 1e-6)  # Add epsilon to avoid division by zero\n",
    "    # Zero out excluded neurons\n",
    "    probs = jnp.where(exclude_mask, 0.0, base_probs)\n",
    "    # Normalize (with safety for all-zero case)\n",
    "    total_prob = jnp.sum(probs)\n",
    "    return jnp.where(total_prob > 0, probs / total_prob, probs)\n",
    "\n",
    "def pruning_step_dynamic(state, R, mn_idxs, clip_start, oscillation_threshold):\n",
    "    \"\"\"\n",
    "    Single pruning step with dynamic convergence checking.\n",
    "    Works with vmap and continues until natural convergence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Safety check - stop if max iterations reached\n",
    "    max_iterations_reached = state.total_iterations >= 200\n",
    "    already_converged = state.converged\n",
    "    \n",
    "    # If we should stop, return unchanged state\n",
    "    should_stop = already_converged | max_iterations_reached\n",
    "    \n",
    "    def stopped_computation():\n",
    "        return state._replace(\n",
    "            converged=True,  # Mark as converged if we hit max iterations\n",
    "            total_iterations=state.total_iterations + 1\n",
    "        )\n",
    "    \n",
    "    def active_computation():\n",
    "        # Get neural activity\n",
    "        max_frs = jnp.max(R, axis=-1)\n",
    "        mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "        active_mask = (max_frs > 0) & mn_mask\n",
    "\n",
    "        # Compute oscillation score\n",
    "        oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "        reset_condition = (oscillation_score < oscillation_threshold) | jnp.isnan(oscillation_score)\n",
    "\n",
    "        # Identify silent interneurons (permanent removal)\n",
    "        silent_interneurons = state.interneuron_mask & (max_frs <= 0)\n",
    "        \n",
    "        # Generate key for this iteration\n",
    "        key = jax.random.fold_in(state.keys, state.total_iterations)\n",
    "        key_continue, key_reset = jax.random.split(key)\n",
    "        \n",
    "        # Check if we need to start a new round\n",
    "        def check_new_round():\n",
    "            \"\"\"Check if current round is complete and handle round transition\"\"\"\n",
    "            \n",
    "            # Current round is complete if no interneurons available for removal\n",
    "            exclude_mask = (~state.interneuron_mask) | state.total_removed_neurons | state.neurons_put_back_current\n",
    "            available_neurons = jnp.sum(state.interneuron_mask & (~exclude_mask))\n",
    "            current_round_done = available_neurons <= 0\n",
    "            \n",
    "            def start_new_round():\n",
    "                # Compare current and previous put-back lists for convergence\n",
    "                lists_identical = jnp.allclose(state.neurons_put_back_current, \n",
    "                                             state.neurons_put_back_prev, atol=1e-6)\n",
    "                \n",
    "                # If lists are identical, we've converged\n",
    "                new_converged = lists_identical\n",
    "                \n",
    "                # Start new round\n",
    "                return state._replace(\n",
    "                    neurons_put_back_prev=state.neurons_put_back_current,\n",
    "                    neurons_put_back_current=jnp.zeros_like(state.neurons_put_back_current),\n",
    "                    removed_stim_neurons=jnp.zeros_like(state.removed_stim_neurons),\n",
    "                    last_removed=jnp.zeros_like(state.last_removed),\n",
    "                    level=0,\n",
    "                    round_complete=False,\n",
    "                    converged=new_converged,\n",
    "                    round_number=state.round_number + 1,\n",
    "                    steps_in_current_round=0\n",
    "                )\n",
    "            \n",
    "            def continue_current_round():\n",
    "                return state\n",
    "            \n",
    "            # Start new round if current one is complete\n",
    "            return jax.lax.cond(current_round_done, start_new_round, continue_current_round)\n",
    "        \n",
    "        # Check for round transition first\n",
    "        state_after_round_check = check_new_round()\n",
    "        \n",
    "        # If we just converged in round transition, return that state\n",
    "        def handle_convergence():\n",
    "            return state_after_round_check._replace(\n",
    "                total_iterations=state.total_iterations + 1\n",
    "            )\n",
    "        \n",
    "        def normal_pruning_step():\n",
    "            \"\"\"Normal within-round pruning step\"\"\"\n",
    "            \n",
    "            # === CONTINUE BRANCH: Normal removal ===\n",
    "            total_removed_continue = state_after_round_check.total_removed_neurons | silent_interneurons\n",
    "            exclude_mask_continue = (~state_after_round_check.interneuron_mask) | total_removed_continue | state_after_round_check.neurons_put_back_current\n",
    "            \n",
    "            # Check if any neurons available for removal in continue branch\n",
    "            available_neurons_continue = jnp.sum(state_after_round_check.interneuron_mask & (~exclude_mask_continue))\n",
    "            \n",
    "            # Sample neuron to remove\n",
    "            p_continue = removal_probability_safe(max_frs, exclude_mask_continue)\n",
    "            neuron_idx_continue = safe_choice(key_continue, p_continue, exclude_mask_continue)\n",
    "            \n",
    "            # Update for continue branch (only if neurons available)\n",
    "            can_remove_continue = available_neurons_continue > 0\n",
    "            \n",
    "            removed_stim_continue = jnp.where(\n",
    "                can_remove_continue,\n",
    "                state_after_round_check.removed_stim_neurons.at[neuron_idx_continue].set(True),\n",
    "                state_after_round_check.removed_stim_neurons\n",
    "            )\n",
    "            total_removed_continue = jnp.where(\n",
    "                can_remove_continue,\n",
    "                total_removed_continue.at[neuron_idx_continue].set(True),\n",
    "                total_removed_continue\n",
    "            )\n",
    "            \n",
    "            # Track last removed\n",
    "            last_removed_continue = jnp.zeros_like(state_after_round_check.last_removed)\n",
    "            last_removed_continue = jnp.where(\n",
    "                can_remove_continue,\n",
    "                last_removed_continue.at[neuron_idx_continue].set(True),\n",
    "                last_removed_continue\n",
    "            )\n",
    "            # Add newly silent neurons\n",
    "            newly_silent = silent_interneurons & (~state_after_round_check.total_removed_neurons)\n",
    "            last_removed_continue = last_removed_continue | newly_silent\n",
    "            \n",
    "            # === RESET BRANCH: Restore and try different neuron ===\n",
    "            # Restore last removed neurons to put_back list\n",
    "            neurons_put_back_reset = state_after_round_check.neurons_put_back_current | state_after_round_check.last_removed\n",
    "            removed_stim_reset = state_after_round_check.removed_stim_neurons & (~state_after_round_check.last_removed)\n",
    "            total_removed_reset = (state_after_round_check.total_removed_neurons & (~state_after_round_check.last_removed)) | silent_interneurons\n",
    "            \n",
    "            exclude_mask_reset = (~state_after_round_check.interneuron_mask) | total_removed_reset | neurons_put_back_reset\n",
    "            available_neurons_reset = jnp.sum(state_after_round_check.interneuron_mask & (~exclude_mask_reset))\n",
    "            \n",
    "            # Sample different neuron\n",
    "            p_reset = removal_probability_safe(max_frs, exclude_mask_reset)\n",
    "            neuron_idx_reset = safe_choice(key_reset, p_reset, exclude_mask_reset)\n",
    "            \n",
    "            can_remove_reset = available_neurons_reset > 0\n",
    "            \n",
    "            removed_stim_reset = jnp.where(\n",
    "                can_remove_reset,\n",
    "                removed_stim_reset.at[neuron_idx_reset].set(True),\n",
    "                removed_stim_reset\n",
    "            )\n",
    "            total_removed_reset = jnp.where(\n",
    "                can_remove_reset,\n",
    "                total_removed_reset.at[neuron_idx_reset].set(True),\n",
    "                total_removed_reset\n",
    "            )\n",
    "            \n",
    "            last_removed_reset = jnp.zeros_like(state_after_round_check.last_removed)\n",
    "            last_removed_reset = jnp.where(\n",
    "                can_remove_reset,\n",
    "                last_removed_reset.at[neuron_idx_reset].set(True),\n",
    "                last_removed_reset\n",
    "            )\n",
    "            # Add newly silent neurons (excluding those already in last_removed)\n",
    "            newly_silent_reset = silent_interneurons & (~state_after_round_check.total_removed_neurons) & (~state_after_round_check.last_removed)\n",
    "            last_removed_reset = last_removed_reset | newly_silent_reset\n",
    "            \n",
    "            # Choose between branches based on reset condition\n",
    "            final_total_removed = jnp.where(reset_condition, total_removed_reset, total_removed_continue)\n",
    "            final_removed_stim = jnp.where(reset_condition, removed_stim_reset, removed_stim_continue)\n",
    "            final_last_removed = jnp.where(reset_condition, last_removed_reset, last_removed_continue)\n",
    "            final_neurons_put_back = jnp.where(reset_condition, neurons_put_back_reset, state_after_round_check.neurons_put_back_current)\n",
    "            final_remove_p = jnp.where(reset_condition, p_reset, p_continue)\n",
    "            \n",
    "            # Update W_mask based on removed neurons\n",
    "            removed_float = final_total_removed.astype(jnp.float32)\n",
    "            kept_mask = 1.0 - removed_float\n",
    "            W_mask_new = kept_mask[:, None] * kept_mask[None, :]\n",
    "            \n",
    "            return state_after_round_check._replace(\n",
    "                W_mask=W_mask_new,\n",
    "                level=state_after_round_check.level + 1,\n",
    "                total_removed_neurons=final_total_removed,\n",
    "                neurons_put_back_current=final_neurons_put_back,\n",
    "                removed_stim_neurons=final_removed_stim,\n",
    "                last_removed=final_last_removed,\n",
    "                remove_p=final_remove_p,\n",
    "                steps_in_current_round=state_after_round_check.steps_in_current_round + 1,\n",
    "                total_iterations=state.total_iterations + 1\n",
    "            )\n",
    "        \n",
    "        # Choose between convergence handling and normal step\n",
    "        return jax.lax.cond(\n",
    "            state_after_round_check.converged, \n",
    "            handle_convergence, \n",
    "            normal_pruning_step\n",
    "        )\n",
    "    \n",
    "    # Main conditional: stop or continue\n",
    "    return jax.lax.cond(should_stop, stopped_computation, active_computation)\n",
    "\n",
    "# Vmap-compatible version\n",
    "@partial(jax.vmap, in_axes=(0, 0, None, None, None))\n",
    "def pruning_step_batched(state_batch, R_batch, mn_idxs, clip_start, oscillation_threshold):\n",
    "    \"\"\"Vectorized pruning step that works across a batch\"\"\"\n",
    "    return pruning_step_dynamic(state_batch, R_batch, mn_idxs, clip_start, oscillation_threshold)\n",
    "\n",
    "def run_pruning_algorithm_batched(neuron_params, sim_params, initial_states, Rs, mn_idxs, clip_start, oscillation_threshold):\n",
    "    \"\"\"\n",
    "    Run pruning algorithm on batch until convergence or max iterations (200).\n",
    "    \n",
    "    Args:\n",
    "        initial_states: Batched Pruning_state \n",
    "        Rs: Batch of neural activity [batch_size, neurons, time]\n",
    "        mn_idxs: Motor neuron indices\n",
    "        clip_start: Start index for oscillation analysis\n",
    "        oscillation_threshold: Threshold for oscillation score\n",
    "    \n",
    "    Returns:\n",
    "        final_states: Final states for each batch element\n",
    "        iterations_used: Number of iterations each element used\n",
    "    \"\"\"\n",
    "    \n",
    "    def should_continue(state_batch):\n",
    "        \"\"\"Check if any element in batch needs to continue\"\"\"\n",
    "        return jnp.any(~state_batch.converged)\n",
    "    \n",
    "    def iteration_step(state_batch):\n",
    "        \"\"\"Single iteration across the batch\"\"\"\n",
    "        neuron_params = neuron_params._replace(W_mask=state.W_mask)\n",
    "        batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "        return pruning_step_batched(state_batch, Rs, mn_idxs, clip_start, oscillation_threshold)\n",
    "    \n",
    "    # Run until all converged or max iterations reached\n",
    "    current_states = initial_states\n",
    "    max_iterations = 200\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Take one step for all batch elements\n",
    "        current_states = iteration_step(current_states)\n",
    "        \n",
    "        # Check if all converged - optional early stopping for efficiency\n",
    "        if not should_continue(current_states):\n",
    "            break\n",
    "    \n",
    "    return current_states\n",
    "\n",
    "def create_batched_initial_state(batch_size, n_neurons, key=None):\n",
    "    \"\"\"Helper to create batched initial states\"\"\"\n",
    "    if key is None:\n",
    "        key = jax.random.PRNGKey(42)\n",
    "    \n",
    "    keys = jax.random.split(key, batch_size)\n",
    "    \n",
    "    return Pruning_state(\n",
    "        W_mask=jnp.ones((batch_size, n_neurons, n_neurons)),\n",
    "        interneuron_mask=jnp.ones((batch_size, n_neurons), dtype=bool),\n",
    "        level=jnp.zeros(batch_size, dtype=int),\n",
    "        total_removed_neurons=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        neurons_put_back_current=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        neurons_put_back_prev=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        removed_stim_neurons=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        last_removed=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        remove_p=jnp.ones((batch_size, n_neurons)) / n_neurons,\n",
    "        round_complete=jnp.zeros(batch_size, dtype=bool),\n",
    "        converged=jnp.zeros(batch_size, dtype=bool),\n",
    "        round_number=jnp.zeros(batch_size, dtype=int),\n",
    "        keys=keys,\n",
    "        steps_in_current_round=jnp.zeros(batch_size, dtype=int),\n",
    "        total_iterations=jnp.zeros(batch_size, dtype=int)\n",
    "    )\n",
    "\n",
    "# Usage example:\n",
    "\n",
    "# Create batch\n",
    "batch_size = 16\n",
    "n_neurons = 100\n",
    "initial_states = create_batched_initial_state(batch_size, n_neurons)\n",
    "\n",
    "# Your neural activity data\n",
    "Rs = jnp.ones((batch_size, n_neurons, 1000))  # [batch, neurons, time]\n",
    "mn_idxs = jnp.array([0, 1, 2])  # Motor neuron indices\n",
    "\n",
    "# Run algorithm\n",
    "final_states = run_pruning_algorithm_batched(\n",
    "    neuron_params, sim_params,\n",
    "    initial_states, Rs, mn_idxs, \n",
    "    clip_start=100, oscillation_threshold=0.5\n",
    ")\n",
    "\n",
    "# Check results\n",
    "print(f\"Converged: {jnp.sum(final_states.converged)} / {batch_size}\")\n",
    "print(f\"Iterations used: {final_states.total_iterations}\")\n",
    "print(f\"Hit max iterations: {jnp.sum(final_states.total_iterations >= 200)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparse.load_npz('/data/users/eabe/Pugliese_2025/Prune_Test/debug/run_id=Testing/sim=prune_network/ckpt/Prune_Test_Rs.npz').todense().astype(jnp.float32).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparse.load_npz(cfg.paths.ckpt_dir  / f\"{cfg.experiment.name}_Rs.npz\").todense().astype(np.float32).squeeze()\n",
    "mini_circuit = sparse.load_npz(cfg.paths.ckpt_dir  / f\"{cfg.experiment.name}_mini_circuits.npz\").todense().astype(np.bool).squeeze()\n",
    "# W_mask = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_W_mask.npz\").todense().astype(np.float32)\n",
    "# total_removed_neurons = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_total_removed.npz\").todense().astype(np.bool_)\n",
    "# loaded_state = load_state(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_state.pkl\")\n",
    "# loaded_state = load_state('/data/users/eabe/Pugliese_2025/Prune_Test/debug/run_id=Testing/sim=prune_network/ckpt/Prune_Test_state.pkl')\n",
    "w_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "## Initialize parameters\n",
    "neuron_params = prepare_neuron_params(cfg, w_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "all_neurons = w_table.index.to_numpy()\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "nonmn_idxs = w_table.loc[(w_table[\"bodyId\"]==10093) | (w_table[\"bodyId\"]==10707) | (w_table[\"bodyId\"]==13905) | (w_table[\"bodyId\"]==11751)].index.values\n",
    "interneuron_mask = jnp.full((neuron_params.W_mask.shape[0], neuron_params.W_mask.shape[-1]), fill_value=False, dtype=jnp.bool_)\n",
    "interneuron_mask = interneuron_mask.at[:, in_idxs].set(True)\n",
    "# neuron_params = neuron_params._replace(W_mask=loaded_state.W_mask)\n",
    "# mini_circuit = ((~loaded_state.total_removed_neurons) | loaded_state.last_removed | loaded_state.prev_put_back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_params.W_mask.shape, mini_circuit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results\n",
    "# mini_circuit = ((~loaded_state.total_removed_neurons) | loaded_state.last_removed | loaded_state.prev_put_back)\n",
    "W_mask_init = jnp.ones_like(neuron_params.W_mask, dtype=jnp.bool)\n",
    "W_mask_new = W_mask_init * mini_circuit[:, :, None] * mini_circuit[:, None, :] \n",
    "neuron_params = neuron_params._replace(W_mask=(W_mask_new))\n",
    "# results = process_batch_prune(neuron_params, sim_params, jnp.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.squeeze()\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = batch_results[0]\n",
    "n_replicate = 510\n",
    "R = results[n_replicate]\n",
    "interneuron_left = jnp.where(mini_circuit[n_replicate]&(interneuron_mask[n_replicate]))[0]\n",
    "print(f\"interneurons left: {interneuron_left}\")\n",
    "print(f\"prev_min_circuit neurons: {nonmn_idxs}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "ax = axs[0]\n",
    "ax.plot(R[nonmn_idxs].T)\n",
    "ax.set_title(\"mini_circuit neurons\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(R[mn_idxs].T)\n",
    "ax.set_title(\"motor neurons\")\n",
    "\n",
    "ax = axs[2]\n",
    "active_neurons = jnp.where((jnp.sum(results[0],axis=-1) > 0))[0]\n",
    "ax.plot(R[active_neurons].T)\n",
    "ax.set_title(\"active neurons\")\n",
    "\n",
    "# Get active MN activity using JAX-compatible approach\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "active_mask = ((max_frs>0) & mn_mask)\n",
    "clip_start = 220\n",
    "# Compute oscillation score\n",
    "oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "# print('oscillation_score:', oscillation_score)\n",
    "oscillation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_interneurons = []\n",
    "active_motor_neurons = []\n",
    "for n in range(results.shape[0]):\n",
    "    R = results[n]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_interneurons.append(jnp.where((max_frs > 0) & interneuron_mask[n])[0])\n",
    "    active_motor_neurons.append(jnp.where((max_frs > 0) & ~interneuron_mask[n])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_interneurons\n",
    "active_motor_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sim_utils import neuron_oscillation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oscillation_score, _ = compute_oscillation_score(results.reshape(-1, results.shape[-1])[..., clip_start:], active_mask, prominence=0.05)\n",
    "activity = results[..., clip_start:]\n",
    "prominence = 0.05\n",
    "all_scores = []\n",
    "for nsim in range(activity.shape[0]):\n",
    "    R = activity[nsim]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "    active_mask = ((max_frs>0) & mn_mask)\n",
    "    sim_scores, freqs = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(R, prominence)\n",
    "    all_scores.append(sim_scores[active_mask])\n",
    "all_scores = jnp.concatenate(all_scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_scores, bins=50, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stim Adjustment Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_with_stim_adjustment(self,maxIters=10,clampedNeurons=[],clampedRates=None,nActiveUpper=500,nActiveLower=5,nHighFrUpper=100):\n",
    "    nextHighest = None\n",
    "    nextLowest = None\n",
    "\n",
    "    for i in range(maxIters):\n",
    "        self.run(clampedNeurons=clampedNeurons,clampedRates=clampedRates)\n",
    "        R = self.R\n",
    "\n",
    "        nActive = sum(np.sum(R,1)>0)\n",
    "        nHighFr = sum(np.max(R,1)>100)\n",
    "\n",
    "        currInputs = self.inputs.copy()\n",
    "\n",
    "        print(f\"Run {i}\")\n",
    "        print(f\"max stimI = {np.max(currInputs)}\")\n",
    "        print(f\"nActive: {nActive}\")\n",
    "        print(f\"nHighFr: {nHighFr}\")\n",
    "\n",
    "        if (nActive > nActiveUpper) or (nHighFr > nHighFrUpper): # too strong\n",
    "            if nextLowest is None:\n",
    "                newInputs = currInputs/2\n",
    "            else:\n",
    "                newInputs = (currInputs+nextLowest)/2\n",
    "            nextHighest = currInputs\n",
    "        elif (nActive < nActiveLower): # too weak\n",
    "            if nextHighest is None:\n",
    "                newInputs = currInputs*2\n",
    "            else:\n",
    "                newInputs = (currInputs+nextHighest)/2\n",
    "            nextLowest = currInputs\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        self.set_input(newInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note: The run_with_stim_adjustment function cannot be easily JIT-compiled\n",
    "# because it involves loops with data-dependent control flow and side effects.\n",
    "# Here's a restructured version that separates the JIT-able parts:\n",
    "\n",
    "@jit\n",
    "def compute_activity_metrics(R):\n",
    "    \"\"\"JIT-compatible function to compute activity metrics.\"\"\"\n",
    "    n_active = jnp.sum(jnp.sum(R, axis=1) > 0)\n",
    "    n_high_fr = jnp.sum(jnp.max(R, axis=1) > 100)\n",
    "    return n_active, n_high_fr\n",
    "\n",
    "@jit\n",
    "def update_inputs_binary_search(curr_inputs, next_lowest, next_highest, \n",
    "                               n_active, n_high_fr, n_active_upper, \n",
    "                               n_active_lower, n_high_fr_upper):\n",
    "    \"\"\"JIT-compatible input update logic.\"\"\"\n",
    "    \n",
    "    # Determine if stimulation is too strong\n",
    "    too_strong = (n_active > n_active_upper) | (n_high_fr > n_high_fr_upper)\n",
    "    too_weak = n_active < n_active_lower\n",
    "    \n",
    "    # Update inputs based on binary search logic\n",
    "    def update_for_too_strong():\n",
    "        new_inputs = jnp.where(\n",
    "            next_lowest is None,\n",
    "            curr_inputs / 2,\n",
    "            (curr_inputs + next_lowest) / 2\n",
    "        )\n",
    "        new_next_highest = curr_inputs\n",
    "        return new_inputs, next_lowest, new_next_highest\n",
    "    \n",
    "    def update_for_too_weak():\n",
    "        new_inputs = jnp.where(\n",
    "            next_highest is None,\n",
    "            curr_inputs * 2,\n",
    "            (curr_inputs + next_highest) / 2\n",
    "        )\n",
    "        new_next_lowest = curr_inputs\n",
    "        return new_inputs, new_next_lowest, next_highest\n",
    "    \n",
    "    def no_update():\n",
    "        return curr_inputs, next_lowest, next_highest\n",
    "    \n",
    "    # Apply updates conditionally\n",
    "    new_inputs, new_next_lowest, new_next_highest = jax.lax.cond(\n",
    "        too_strong,\n",
    "        update_for_too_strong,\n",
    "        lambda: jax.lax.cond(\n",
    "            too_weak,\n",
    "            update_for_too_weak,\n",
    "            no_update\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    converged = ~too_strong & ~too_weak\n",
    "    \n",
    "    return new_inputs, new_next_lowest, new_next_highest, converged\n",
    "\n",
    "# Example usage:\n",
    "def run_with_stim_adjustment_jax(simulation_runner, max_iters=10, \n",
    "                                clamped_neurons=None, clamped_rates=None,\n",
    "                                n_active_upper=500, n_active_lower=5, \n",
    "                                n_high_fr_upper=100):\n",
    "    \"\"\"\n",
    "    JAX-compatible version of run_with_stim_adjustment.\n",
    "    Note: This requires the simulation_runner to be compatible with JAX.\n",
    "    \"\"\"\n",
    "    next_highest = None\n",
    "    next_lowest = None\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        # Run simulation (this part depends on your simulation framework)\n",
    "        R = simulation_runner.run(clamped_neurons=clamped_neurons, \n",
    "                                 clamped_rates=clamped_rates)\n",
    "        \n",
    "        # Compute metrics (JIT-compiled)\n",
    "        n_active, n_high_fr = compute_activity_metrics(R)\n",
    "        curr_inputs = simulation_runner.get_inputs()\n",
    "        \n",
    "        print(f\"Run {i}\")\n",
    "        print(f\"max stimI = {jnp.max(curr_inputs)}\")\n",
    "        print(f\"nActive: {n_active}\")\n",
    "        print(f\"nHighFr: {n_high_fr}\")\n",
    "        \n",
    "        # Update inputs (JIT-compiled)\n",
    "        new_inputs, next_lowest, next_highest, converged = update_inputs_binary_search(\n",
    "            curr_inputs, next_lowest, next_highest, n_active, n_high_fr,\n",
    "            n_active_upper, n_active_lower, n_high_fr_upper\n",
    "        )\n",
    "        \n",
    "        if converged:\n",
    "            break\n",
    "            \n",
    "        simulation_runner.set_input(new_inputs)\n",
    "\n",
    "# Additional utility functions for JAX compatibility:\n",
    "\n",
    "@jit\n",
    "def safe_divide(x, y, default=0.0):\n",
    "    \"\"\"Safe division that handles division by zero.\"\"\"\n",
    "    return jnp.where(y == 0, default, x / y)\n",
    "\n",
    "@jit\n",
    "def safe_max(x, default=0.0):\n",
    "    \"\"\"Safe max that handles empty arrays.\"\"\"\n",
    "    return jnp.where(len(x) == 0, default, jnp.max(x))\n",
    "\n",
    "@jit\n",
    "def safe_min(x, default=0.0):\n",
    "    \"\"\"Safe min that handles empty arrays.\"\"\"\n",
    "    return jnp.where(len(x) == 0, default, jnp.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnc-closedloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
