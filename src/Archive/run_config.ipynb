{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from src.vnc import run_vnc_simulation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "import jax\n",
    "# jax.config.update(\"jax_enable_x64\", True)\n",
    "# Configure JAX for better performance\n",
    "jax.config.update(\"jax_enable_x64\", False)  # Use float32 for better GPU performance\n",
    "jax.config.update(\"jax_platforms\", \"cuda\")  # Prefer GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # Use GPU 0\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\n",
    "\n",
    "# Disable XLA optimizations that might cause timing issues\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_triton_gemm_any=false'\n",
    "\n",
    "import sparse\n",
    "\n",
    "from src.optimized_vnc import *\n",
    "from src.plot_utils import *\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment='Stim_Neurons'\n",
    "with initialize(version_base=None, config_path=\"../configs\"):\n",
    "    cfg=compose(config_name='config.yaml', overrides= [f\"experiment={experiment}\", \"paths=glados\", \"version=debug\", f'run_id=Testing'],return_hydra_config=True,)\n",
    "    HydraConfig.instance().set_config(cfg)\n",
    "\n",
    "for k in cfg.paths.keys():\n",
    "    if (k != 'user'):\n",
    "        cfg.paths[k] = Path(cfg.paths[k])\n",
    "        cfg.paths[k].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# base_dir ='/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=noisy_input01'\n",
    "# # base_dir ='/data/users/eabe/biomech_model/Flybody/RL_Flybody/debug/'\n",
    "# # base_dir ='/Users/eabe/Research/data/biomech_model/Flybody/RL_Flybody/debug'\n",
    "\n",
    "# run_cfg_list = sorted(list(Path(base_dir).rglob('config.yaml')))\n",
    "# for n, run_cfg in enumerate(run_cfg_list):\n",
    "#     print(n, run_cfg)\n",
    "\n",
    "# ###### New runs ###### \n",
    "# # 0,1 Multiclip 3, 4\n",
    "# # 2 Fly Run 5\n",
    "# # 6 Fly Joystick\n",
    "# cfg_num = -1 #30\n",
    "# cfg = OmegaConf.load(run_cfg_list[cfg_num])\n",
    "# # run_id = int(run_cfg_list[cfg_num].parent.parent.stem.split('=')[1])\n",
    "# print('Loading:', cfg.dataset.env_name, run_cfg_list[cfg_num])\n",
    "# fig_dir = Path('/data/users/eabe/biomech_model/Flybody/RL_Flybody/debug/figures')\n",
    "# # fig_dir = Path('/Users/eabe/Research/data/biomech_model/Flybody/RL_Flybody/debug/Figures')\n",
    "# ##### Reset paths for local computer #####\n",
    "# dataset = cfg.dataset.env_name\n",
    "# with initialize(version_base=None, config_path=\"configs\"):\n",
    "#     cfg_temp=compose(config_name='config.yaml',overrides= [f\"dataset={dataset}\", \"paths=walle\", \"version=ckpt\", f'run_id=Testing'],return_hydra_config=True,)\n",
    "#     HydraConfig.instance().set_config(cfg_temp)\n",
    "\n",
    "# cfg.paths = cfg_temp.paths\n",
    "# for k in cfg.paths.keys():\n",
    "#     if (k != 'user'):\n",
    "#         cfg.paths[k] = Path(cfg.paths[k])\n",
    "#         cfg.paths[k].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# experiment='default'\n",
    "# with initialize(version_base=None, config_path=\"../configs\"):\n",
    "#     cfg_old=compose(config_name='config.yaml', overrides= [f\"experiment={experiment}\", \"paths=glados\", \"version=debug\", f'run_id=Testing'],return_hydra_config=True,)\n",
    "#     HydraConfig.instance().set_config(cfg_old)\n",
    "\n",
    "# for k in cfg_old.paths.keys():\n",
    "#     if (k != 'user'):\n",
    "#         cfg_old.paths[k] = Path(cfg_old.paths[k])\n",
    "#         cfg_old.paths[k].mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading network configuration...\")\n",
    "W_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "# Prepare parameters\n",
    "neuron_params = prepare_neuron_params(cfg, W_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "simulation_type = \"baseline\"\n",
    "\n",
    "# results = run_simulation_batched(\n",
    "#     neuron_params, sim_params, simulation_type,\n",
    "#     batch_size=None\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.paths.save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = run_vnc_simulation_optimized(cfg)\n",
    "# save_path = cfg.paths.ckpt_dir  / \"bdn2.npz\"\n",
    "from src.sim_utils import compute_oscillation_score, neuron_oscillation_score\n",
    "\n",
    "# results001 = sparse.load_npz(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=noisy_inputs/0/ckpt/BND2_Stim_Test_Rs.npz\") .todense().astype(np.float32)\n",
    "# results01 = sparse.load_npz(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=noisy_inputs/1/ckpt/BND2_Stim_Test_Rs.npz\").todense().astype(np.float32)\n",
    "# results1 = sparse.load_npz(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=noisy_inputs/2/ckpt/BND2_Stim_Test_Rs.npz\").todense().astype(np.float32)\n",
    "# results10 = sparse.load_npz(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=noisy_inputs/3/ckpt/BND2_Stim_Test_Rs.npz\").todense().astype(np.float32)\n",
    "\n",
    "results = sparse.load_npz('/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=Testing/sim.noise=True/ckpt/BND2_Stim_Test_Rs.npz').todense().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.all(np.sum(results,axis=-1)==0,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[0][20]\n",
    "\n",
    "\n",
    "w_table = pd.read_csv(\"../data/manc t1 connectome data/wTable_20231020_DNtoMN_unsorted_withModules.csv\",index_col=0)\n",
    "nonMns_idx = w_table.loc[(w_table[\"bodyId\"]==10093) | (w_table[\"bodyId\"]==10707) | (w_table[\"bodyId\"]==13905) | (w_table[\"bodyId\"]==11751)].index\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(18, 6))\n",
    "for i in nonMns_idx:\n",
    "    axs[0].plot(R[i])\n",
    "axs[0].set_title(\"Non-Motor Neurons\")\n",
    "for i in mn_idxs:\n",
    "    axs[1].plot(R[i])\n",
    "axs[1].set_title(\"Motor Neurons\")\n",
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "\n",
    "scores001 = []\n",
    "for i in range(results.shape[1]):\n",
    "    R = results[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores001.append(score)\n",
    "scores001 = jnp.concatenate(scores001, axis=-1)\n",
    "axs[2].hist(scores001, bins=50, density=True)\n",
    "plt.savefig(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=Testing/sim.noise=True/figures/Example_R.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sim_utils import compute_oscillation_score, neuron_oscillation_score\n",
    "clip_start = 250\n",
    "oscillation_threshold = 0.2\n",
    "# Load data (this part stays on CPU)\n",
    "w_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "## Initialize parameters\n",
    "neuron_params = prepare_neuron_params(cfg, w_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "all_neurons = w_table.index.to_numpy()\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "# max_frs = jnp.max(results[0], axis=-1)\n",
    "# mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "# active_mask = ((max_frs>0) & mn_mask)\n",
    "prominence = 0.05\n",
    "# Compute oscillation score\n",
    "# oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape, active_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "\n",
    "scores001 = []\n",
    "for i in range(results001.shape[1]):\n",
    "    R = results001[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores001.append(score)\n",
    "scores01 = []\n",
    "for i in range(results01.shape[1]):\n",
    "    R = results01[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores01.append(score)\n",
    "scores1 = []\n",
    "for i in range(results1.shape[1]):\n",
    "    R = results1[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores1.append(score)\n",
    "scores10 = []\n",
    "for i in range(results10.shape[1]):\n",
    "    R = results10[0][i]\n",
    "    max_frs = jnp.max(R, axis=-1)\n",
    "    active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "    activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "    score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "    scores10.append(score)\n",
    "    \n",
    "    \n",
    "    \n",
    "# score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "# print(f\"Score: {jnp.nanmean(score)}, Frequency: {jnp.nanmean(frequency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "axs[0].hist(jnp.concatenate(scores001, axis=-1), bins=25)\n",
    "axs[0].set_xlabel(\"Oscillation Score\")\n",
    "axs[0].set_title(\"Noise=0.01\")\n",
    "axs[1].hist(jnp.concatenate(scores01, axis=-1), bins=25)\n",
    "axs[1].set_xlabel(\"Oscillation Score\")\n",
    "axs[1].set_title(\"Noise=0.1\")\n",
    "axs[2].hist(jnp.concatenate(scores1, axis=-1), bins=25)\n",
    "axs[2].set_xlabel(\"Oscillation Score\")\n",
    "axs[2].set_title(\"Noise=1\")\n",
    "axs[3].hist(jnp.concatenate(scores10, axis=-1), bins=25)\n",
    "axs[3].set_xlabel(\"Oscillation Score\")\n",
    "axs[3].set_title(\"Noise=10\")\n",
    "plt.savefig(\"/data/users/eabe/Pugliese_2025/BND2_Stim_Test/debug/run_id=noisy_inputs/figures/oscillation_scores.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, config = load_vnc_net(cfg)\n",
    "simulator = OptimizedSimulator(params, config)\n",
    "# W, W_table = load_connectivity(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_queue = simulator._create_work_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.shuffle_utils import shuffle_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newkey, key = jax.random.split(work_queue[0]['seed'])\n",
    "idxs = params.inh_dn_idxs\n",
    "W = params.W\n",
    "W_shuff = shuffle_W(W, key, idxs, independent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing batchsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200#2**6# cfg.experiment.batch_size\n",
    "# batch_idx = 0  # Example batch index\n",
    "work_queue = []\n",
    "ntotal = 0\n",
    "n_stim_configs = len(params.input_currents_list)\n",
    "n_param_sets = n_replicates = 12345 # len(params.tau)\n",
    "for stim_idx in range(n_stim_configs):\n",
    "    for param_idx in range(n_param_sets):\n",
    "        work_queue.append({\"stim_idx\":stim_idx, \"param_idx\":param_idx, \"total_count\": ntotal})\n",
    "        ntotal +=1\n",
    "all_results = []\n",
    "all_metadata = []\n",
    "n_batches = (len(work_queue) + batch_size - 1) // batch_size\n",
    "for batch_idx in range(n_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min((batch_idx + 1) * batch_size, len(work_queue))\n",
    "    actual_batch_size = end_idx - start_idx\n",
    "    batch_work = work_queue[start_idx:end_idx]\n",
    "\n",
    "    batch_params = {\n",
    "        'tau_batch': jnp.array([item['total_count'] for item in batch_work]),\n",
    "        'stim_batch': jnp.array([item['stim_idx'] for item in batch_work]),\n",
    "        'param_batch': jnp.array([item['param_idx'] for item in batch_work])\n",
    "    }\n",
    "\n",
    "    batch_metadata = [\n",
    "        {'param_idx': item['param_idx'], 'stim_idx': item['stim_idx'], 'total_count': item['total_count']} \n",
    "        for item in batch_work\n",
    "    ]\n",
    "    \n",
    "    batch_size = len(batch_params['tau_batch'])\n",
    "    n_devices = jax.device_count()\n",
    "    # Pad to make divisible by n_devices\n",
    "    pad_size = n_devices - (batch_size % n_devices) if batch_size % n_devices != 0 else 0\n",
    "    print(pad_size, batch_size, n_devices)\n",
    "    device_data = {}\n",
    "    for key, data in batch_params.items():\n",
    "    #     if pad_size > 0:\n",
    "    #         # Pad with the last element\n",
    "    #         if data.ndim == 1:\n",
    "    #             padding = jnp.repeat(data[-1:], pad_size, axis=0)\n",
    "    #         else:\n",
    "    #             padding = jnp.repeat(data[-1:], pad_size, axis=0)\n",
    "    #         data_padded = jnp.concatenate([data, padding])\n",
    "    #     else:\n",
    "    #         data_padded = data\n",
    "        \n",
    "        # Reshape for devices\n",
    "        device_data[key] = data.reshape(n_devices, -1, *data.shape[1:])\n",
    "    print(f\"device_data: {device_data['tau_batch'].shape}, {device_data['stim_batch'].shape}, {device_data['param_batch'].shape}\")\n",
    "\n",
    "\n",
    "    batch_results = device_data['tau_batch'][:,:,None,None]\n",
    "    batch_results_flat = batch_results.reshape(-1, *batch_results.shape[2:])\n",
    "    batch_results_trimmed = batch_results_flat[:actual_batch_size]\n",
    "    batch_results_trimmed = jax.device_put(batch_results_trimmed, jax.devices('cpu')[0])\n",
    "    batch_results_trimmed = jnp.where(\n",
    "            jnp.isinf(batch_results_trimmed) | jnp.isnan(batch_results_trimmed), \n",
    "            0, batch_results_trimmed\n",
    "        )\n",
    "    all_results.extend(batch_results_trimmed)\n",
    "    all_metadata.extend(batch_metadata)\n",
    "    print(f'batch:{batch_idx}, {batch_results_trimmed.squeeze()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size % n_devices, batch_size, n_devices\n",
    "# batch_params['tau_batch'], len(work_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_by_stim = {}\n",
    "results_by_stim_total_ind = {}\n",
    "# Initialize batch_results_trimmed containers\n",
    "for stim_idx in range(n_stim_configs):\n",
    "    results_by_stim[stim_idx] = [None] * n_param_sets\n",
    "    results_by_stim_total_ind[stim_idx] = [None] * n_param_sets\n",
    "\n",
    "# Place results in correct positions using metadata\n",
    "for batch_results_trimmed, metadata in zip(all_results, all_metadata):\n",
    "    param_idx = metadata['param_idx']\n",
    "    stim_idx = metadata['stim_idx']\n",
    "    \n",
    "    # Validate indices\n",
    "    if param_idx >= n_param_sets or stim_idx >= n_stim_configs:\n",
    "        print(f\"Warning: Invalid indices param_idx={param_idx}, stim_idx={stim_idx}\")\n",
    "        continue\n",
    "    results_by_stim_total_ind[stim_idx][param_idx] = metadata['total_count']\n",
    "    results_by_stim[stim_idx][param_idx] = batch_results_trimmed\n",
    "\n",
    "# Convert to arrays and validate completeness\n",
    "for stim_idx in results_by_stim:\n",
    "    results_list = results_by_stim[stim_idx]\n",
    "    result_inds = results_by_stim_total_ind[stim_idx]\n",
    "    if (jnp.diff(jnp.array(results_by_stim_total_ind[stim_idx])) > 1).any():\n",
    "        print(f\"Warning: Inconsistent results for stimulus {stim_idx}, indices: {result_inds}\")\n",
    "    # Check for missing results\n",
    "    missing_indices = [i for i, batch_results_trimmed in enumerate(results_list) if batch_results_trimmed is None]\n",
    "    if missing_indices:\n",
    "        print(f\"Warning: Missing results for stimulus {stim_idx} at parameter indices: {missing_indices}\")\n",
    "        # Fill missing with zeros (same shape as other results)\n",
    "        ref_shape = next(r.shape for r in results_list if r is not None)\n",
    "        for idx in missing_indices:\n",
    "            results_list[idx] = jnp.zeros(ref_shape)\n",
    "    \n",
    "    results_by_stim[stim_idx] = jnp.array(results_list)\n",
    "results2 = jnp.stack([results_by_stim[n] for n in results_by_stim.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.all(np.sum(results,axis=-1)==0,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[0][0]\n",
    "\n",
    "\n",
    "wTable = pd.read_csv(\"../data/manc t1 connectome data/wTable_20231020_DNtoMN_unsorted_withModules.csv\",index_col=0)\n",
    "nonMns = wTable.loc[(wTable[\"bodyId\"]==10093) | (wTable[\"bodyId\"]==10707) | (wTable[\"bodyId\"]==13905) | (wTable[\"bodyId\"]==11751)]\n",
    "mnIdxs = wTable.loc[wTable[\"class\"]==\"motor neuron\"].index\n",
    "\n",
    "\n",
    "for i in nonMns.index:\n",
    "# for i in mnIdxs:\n",
    "    plt.plot(R[i])\n",
    "    #plt.plot(Rtsp[i])\n",
    "\n",
    "print(np.mean(R))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing osc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparse.load_npz(cfg.paths.ckpt_dir  / \"bdn2.npz\").todense().astype(np.float32)\n",
    "\n",
    "wTable = pd.read_csv(\"../data/manc t1 connectome data/wTable_20231020_DNtoMN_unsorted_withModules.csv\",index_col=0)\n",
    "nonMns = (wTable.loc[(wTable[\"bodyId\"]==10093) | (wTable[\"bodyId\"]==10707) | (wTable[\"bodyId\"]==13905) | (wTable[\"bodyId\"]==11751)]).values\n",
    "mn_idxs = wTable.loc[wTable[\"class\"]==\"motor neuron\"].index.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "def neuron_oscillation_score_helper_old(activity,prominence):\n",
    "    activity = activity-np.min(activity)\n",
    "    activity = 2 * activity/np.max(activity) - 1\n",
    "\n",
    "    autocorr = np.correlate(activity,activity,mode=\"full\") / np.inner(activity,activity)\n",
    "    lags = signal.correlation_lags(len(activity),len(activity))\n",
    "    autocorr = autocorr[lags>0]\n",
    "    lags = lags[lags>0]\n",
    "\n",
    "    peaks, peakProperties = signal.find_peaks(autocorr,height=(None,None),prominence=prominence)\n",
    "    if len(peaks) > 0:\n",
    "        score = np.min([np.max(peakProperties[\"peak_heights\"]),np.max(peakProperties[\"prominences\"])])\n",
    "        frequency = 1 / peaks[np.argmax(peakProperties[\"prominences\"])]\n",
    "    else:\n",
    "        score = 0\n",
    "        frequency = 0\n",
    "\n",
    "    return score, frequency\n",
    "\n",
    "def neuron_oscillation_score_old(activity, returnFrequency=False,prominence=0.05):\n",
    "    rawScore, frequency = neuron_oscillation_score_helper_old(activity,prominence)\n",
    "    # normalize to sine wave of the same frequency and duration\n",
    "    if rawScore == 0:\n",
    "        score = 0\n",
    "    else:\n",
    "        refSinScore, _ = neuron_oscillation_score_helper_old(np.sin(2*np.pi*frequency*np.arange(len(activity))),prominence)\n",
    "        refCosScore, _ = neuron_oscillation_score_helper_old(np.cos(2*np.pi*frequency*np.arange(len(activity))),prominence)\n",
    "        refScore = np.max((refSinScore,refCosScore))\n",
    "        score = rawScore / refScore\n",
    "\n",
    "    if returnFrequency:\n",
    "        return score, frequency\n",
    "    else:\n",
    "        return score\n",
    "\n",
    "def sim_oscillation_score_old(R,activeMnIdxs,start=None,end=None,returnFrequency=False):\n",
    "    \"\"\"calculate oscillation score for a simulation\"\"\"\n",
    "    if start is None:\n",
    "        start = 0\n",
    "    if end is None:\n",
    "        end = -1\n",
    "\n",
    "    if returnFrequency:\n",
    "        neuronOscillationScores = []\n",
    "        frequencies = []\n",
    "\n",
    "        for j in activeMnIdxs:\n",
    "            score, freq = neuron_oscillation_score_old(R[j][start:end],returnFrequency=True)\n",
    "            neuronOscillationScores.append(score)\n",
    "            frequencies.append(freq)\n",
    "        return np.mean(neuronOscillationScores), np.nanmean(frequencies)\n",
    "        \n",
    "    else:\n",
    "        neuronOscillationScores = [neuron_oscillation_score_old(R[j][start:end]) for j in activeMnIdxs] # scores for each neuron\n",
    "        return np.mean(neuronOscillationScores) # average for the simulation\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[0][19]\n",
    "np_R = np.asarray(R)\n",
    "maxFrs = np.max(np_R,axis=-1)\n",
    "activeMnIdxs = mnIdxs[maxFrs[mnIdxs]>0]\n",
    "plt.plot(np_R[activeMnIdxs].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results[1][1]\n",
    "\n",
    "score, freq = sim_oscillation_score_old(R,activeMnIdxs,start=250,end=None,returnFrequency=True)\n",
    "print(f\"Score: {score}, Frequency: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sim_utils import neuron_oscillation_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "R = results[0][0]\n",
    "\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "\n",
    "score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "print(f\"Score: {jnp.nanmean(score)}, Frequency: {jnp.nanmean(frequency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sim_utils import neuron_oscillation_score\n",
    "\n",
    "experiment='prune_test'\n",
    "with initialize(version_base=None, config_path=\"../configs\"):\n",
    "    cfg=compose(config_name='config.yaml', overrides= [f\"experiment={experiment}\", \"paths=glados\", \"version=debug\", f'run_id=Testing'],return_hydra_config=True,)\n",
    "    HydraConfig.instance().set_config(cfg)\n",
    "\n",
    "for k in cfg.paths.keys():\n",
    "    if (k != 'user'):\n",
    "        cfg.paths[k] = Path(cfg.paths[k])\n",
    "        cfg.paths[k].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def print_inds(arr, name=''):\n",
    "    print(f\"Indices for {name}: {jnp.where(arr)[0].shape}\")\n",
    "    return jnp.where(arr)[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temp parames testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_vnc_simulation_optimized(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nth_filtered_pytree(pytree, n, path_filter, key_list=['tau', 'threshold', 'a', 'fr_cap', 'W_mask']):\n",
    "    \"\"\"\n",
    "    path_filter: function that takes key_path tuple and returns True/False\n",
    "    \"\"\"\n",
    "    def process_leaf(key_path, leaf):\n",
    "        if path_filter(key_path, key_list):\n",
    "            return leaf[n:n+1]\n",
    "        return leaf\n",
    "\n",
    "    return jax.tree.map_with_path(process_leaf, pytree)\n",
    "\n",
    "def path_filter(key_path, key_list):\n",
    "    \"\"\"\n",
    "    Filter function that checks if the key_path contains specific keys.\n",
    "    \"\"\"\n",
    "    return key_path[0].name in key_list and key_path != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_params = extract_nth_filtered_pytree(neuron_params, 0, path_filter)\n",
    "for att in temp_params:\n",
    "    if jnp.ndim(att) > 0:\n",
    "        print(att.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sims = 1\n",
    "batch_size = calculate_optimal_batch_size(sim_params.n_neurons, len(sim_params.t_axis))\n",
    "start_idx = i * batch_size\n",
    "end_idx = min((i + 1) * batch_size, total_sims)\n",
    "\n",
    "batch_indices = jnp.arange(start_idx, end_idx)\n",
    "\n",
    "temp_params = extract_nth_filtered_pytree(neuron_params, 0, path_filter)\n",
    "\n",
    "batch_results = process_batch_baseline(temp_params, sim_params, jnp.zeros(1,dtype=jnp.int32)).squeeze() # Single simulation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "\n",
    "# Prepare parameters\n",
    "neuron_params = prepare_neuron_params(cfg, W_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "\n",
    "# results = sparse.load_npz(cfg.paths.ckpt_dir  / \"bdn2.npz\").todense().astype(np.float32)\n",
    "\n",
    "W_table = pd.read_csv(\"../data/manc t1 connectome data/wTable_20231020_DNtoMN_unsorted_withModules.csv\",index_col=0)\n",
    "nonMns = (W_table.loc[(W_table[\"bodyId\"]==10093) | (W_table[\"bodyId\"]==10707) | (W_table[\"bodyId\"]==13905) | (W_table[\"bodyId\"]==11751)]).values\n",
    "mnIdxs = W_table.loc[W_table[\"class\"]==\"motor neuron\"].index.values\n",
    "\n",
    "# n_sims = results.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neurons = np.arange(sim_params.n_neurons)\n",
    "mn_idxs = jnp.asarray(W_table.loc[W_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "removed_stim_neurons = jnp.full([n_sims, neuron_params.removed_neurons.shape[-1]], -1, dtype=jnp.int32)\n",
    "prev_neurons_put_back = jnp.full([n_sims, neuron_params.removed_neurons.shape[-1]], -1, dtype=jnp.int32)\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "\"\"\"JAX-compatible version of run_pruning_from_params\"\"\"\n",
    "max_neurons = 4561  # Maximum neurons to put back in a single iteration\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "\n",
    "# Initialize state arrays\n",
    "level = jnp.zeros(n_sims, dtype=jnp.int32)\n",
    "last_removed = jnp.full([n_sims, neuron_params.removed_neurons.shape[-1]], -1, dtype=jnp.int32)  # Use -1 for None\n",
    "neurons_put_back = jnp.full([n_sims, neuron_params.removed_neurons.shape[-1]], -1, dtype=jnp.int32)\n",
    "min_circuit = jnp.full(n_sims, False)\n",
    "\n",
    "# Initialize probabilities\n",
    "p_arrays = []\n",
    "for i in range(n_sims):\n",
    "    exclude_mask = jnp.isin(in_idxs, jnp.concatenate([removed_stim_neurons[i]]))\n",
    "    p_i = removal_probability(jnp.ones_like(in_idxs), exclude_mask)\n",
    "    p_arrays.append(p_i)\n",
    "\n",
    "p_arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscillation_threshold=0.1\n",
    "iter_start = 0  # Starting iteration\n",
    "# Create master random key\n",
    "# master_key = random.PRNGKey(neuron_params.seeds, 42)\n",
    "\n",
    "# Main pruning loop\n",
    "iteration = iter_start\n",
    "max_iterations = 1000  # Safety limit\n",
    "\n",
    "# while not jnp.all(min_circuit) and iteration < max_iterations:\n",
    "print(f\"Iteration {iteration}\")\n",
    "\n",
    "# Resample seeds for non-converged simulations\n",
    "resample_idxs = jnp.where(~min_circuit)[0]\n",
    "\n",
    "# Run simulation (this would call your simulation function)\n",
    "# For now, creating dummy data - replace with actual simulation results\n",
    "Rs = [jnp.ones((len(in_idxs) + len(mn_idxs), 1000)) for _ in range(n_sims)]\n",
    "# Update each simulation state\n",
    "# for i in range(n_sims):\n",
    "i = 0  # Example index, replace with actual loop\n",
    "# if min_circuit[i]:\n",
    "#     continue\n",
    "    \n",
    "state = (\n",
    "    neuron_params.removed_neurons,  # array for removed neurons\n",
    "    neurons_put_back[i],\n",
    "    last_removed[i],\n",
    "    p_arrays[i],\n",
    "    level[i],\n",
    "    removed_stim_neurons[i],\n",
    "    neuron_params.seeds[i],\n",
    ")\n",
    "state\n",
    "# new_state = update_single_sim_state(\n",
    "#     state, Rs[i], mn_idxs, in_idxs, oscillation_threshold\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jax.jit\n",
    "def compute_oscillation_score(activity, active_mask, prominence=0.05):\n",
    "    # Compute scores for all neurons (will be NaN for inactive ones)\n",
    "    scores = jax.vmap(\n",
    "        lambda activity_row, mask: jax.lax.cond(\n",
    "            mask,\n",
    "            lambda x: neuron_oscillation_score(x, prominence=prominence),\n",
    "            lambda x: (jnp.nan, jnp.nan),\n",
    "            activity_row\n",
    "        ),\n",
    "        in_axes=(0, 0)\n",
    "    )(activity, active_mask)\n",
    "    score_values, frequencies = scores\n",
    "    # Compute mean of valid scores\n",
    "    oscillation_score = jnp.nanmean(score_values)\n",
    "    frequencies = jnp.nanmean(frequencies)\n",
    "    return oscillation_score, frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "active_mask = ((max_frs>0) & mn_mask)  # Combine max_frs with mn_mask to get active neurons\n",
    "\n",
    "oscillation_score, frequencies = compute_oscillation_score(R, active_mask, prominence=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(cfg.sim.pulseStart/cfg.sim.dt) + 100\n",
    "\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "active_mn_idxs = mn_idxs[max_frs[...,mn_idxs] > 0]\n",
    "activity = R[active_mn_idxs][..., start:]  # Adjusted to match the original code's start index\n",
    "\n",
    "score, frequency = jax.vmap(neuron_oscillation_score, in_axes=(0, None))(activity, 0.05)\n",
    "print(f\"Score: {jnp.nanmean(score)}, Frequency: {jnp.nanmean(frequency)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_p = removal_probability(max_frs[in_idxs], exclude_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_remove_neurons = jnp.setdiff1d(remove_neurons, jnp.array([last_removed]), size=len(remove_neurons), fill_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(remove_neurons, neurons_put_back, last_removed, p, level, removed_stim_neurons, key) = state\n",
    "\n",
    "@jax.jit\n",
    "def get_pos_val_indices(arr, max_indices=None):\n",
    "    if max_indices is None:\n",
    "        max_indices = arr.shape[0]  # Use full array size as max\n",
    "    \n",
    "    indices = jnp.where(arr >= 0, size=max_indices, fill_value=-1)[0]\n",
    "    return indices\n",
    "\n",
    "@jax.jit\n",
    "def continue_branch(key):\n",
    "    # Get max firing rates for all neurons\n",
    "    max_frs = jnp.max(R, axis=1)\n",
    "    \n",
    "    # Remove silent interneurons\n",
    "    silent_mask = (max_frs == 0)\n",
    "    silent_in_mask = silent_mask[in_idxs]\n",
    "    silent_ins = jnp.where(silent_in_mask, in_idxs, -1)\n",
    "    # silent_ins = silent_ins[silent_ins >= 0]  # Filter out -1 values\n",
    "\n",
    "    new_remove_neurons = get_pos_val_indices(silent_ins)\n",
    "\n",
    "    # Update probabilities based on firing rates\n",
    "    exclude_mask = jnp.isin(in_idxs, neurons_put_back) | jnp.isin(in_idxs, removed_stim_neurons)\n",
    "    new_p = removal_probability(max_frs[in_idxs], exclude_mask)\n",
    "    \n",
    "    # Check if we can continue\n",
    "    p_sum = jnp.sum(new_p)\n",
    "    converged = p_sum <= 1e-10\n",
    "    \n",
    "    key, subkey = random.split(key)\n",
    "    neuron_idx = jax_choice(subkey, jnp.arange(len(in_idxs)), new_p)\n",
    "    new_neuron_to_remove = neurons_put_back.at[in_idxs[neuron_idx]].set(1)\n",
    "\n",
    "    new_remove_neurons = jnp.where((new_remove_neurons>0 )| (new_neuron_to_remove>0), 1, -1)\n",
    "\n",
    "    return (new_remove_neurons, neurons_put_back, new_neuron_to_remove,\n",
    "            new_p, level, removed_stim_neurons, key, converged)\n",
    "    \n",
    "@jax.jit\n",
    "def reset_branch(key):\n",
    "    # Put back the last removed neuron\n",
    "    new_remove_neurons = jnp.setdiff1d(remove_neurons, jnp.array([last_removed]), size=len(remove_neurons), fill_value=-1)\n",
    "    # Combine neurons_put_back and last_removed into a single mask\n",
    "    new_neurons_put_back = jnp.where((neurons_put_back >= 0) & (last_removed >= 0), 1, -1)\n",
    "\n",
    "\n",
    "    # Update probabilities to exclude put-back neurons\n",
    "    exclude_mask = jnp.isin(in_idxs, new_neurons_put_back) | jnp.isin(in_idxs, removed_stim_neurons)\n",
    "    new_p = removal_probability(jnp.ones(len(in_idxs)), exclude_mask)\n",
    "    \n",
    "    # Check if we can continue\n",
    "    p_sum = jnp.sum(new_p)\n",
    "    converged = p_sum <= 1e-10\n",
    "    \n",
    "    key, subkey = random.split(key)\n",
    "    neuron_idx = jax_choice(subkey, jnp.arange(len(in_idxs)), new_p)\n",
    "    new_neuron_to_remove = neurons_put_back.at[in_idxs[neuron_idx]].set(1)\n",
    "    \n",
    "    new_remove_neurons = jnp.where((new_remove_neurons>0 )| (new_neuron_to_remove>0), 1, -1)\n",
    "    \n",
    "    return (new_remove_neurons, new_neurons_put_back, new_neuron_to_remove, \n",
    "            new_p, level, removed_stim_neurons, key, converged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pytree(pytree):\n",
    "    \"\"\"\n",
    "    path_filter: function that takes key_path tuple and returns True/False\n",
    "    \"\"\"\n",
    "    def process_leaf(key_path, leaf):\n",
    "       print(f\"Key Path: {key_path[0]}, Leaf: {leaf.shape}\")\n",
    "\n",
    "    return jax.tree.map_with_path(process_leaf, pytree)\n",
    "print_pytree(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state = update_single_sim_state(state, R, mn_idxs, in_idxs, oscillation_threshold)\n",
    "print('Next state:')\n",
    "for att in new_state:\n",
    "    if jnp.ndim(att) > 0:\n",
    "        print(jnp.where(att>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (remove_neurons, neurons_put_back, last_removed, p, level, removed_stim_neurons, key)\n",
    "next_state = continue_branch(key)\n",
    "reset_state = reset_branch(key)\n",
    "next_state, reset_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_remove_neurons, new_neurons_put_back, new_neuron_to_remove,new_p, new_level, new_removed_stim_neurons, new_key, cnew_onverged) = next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(reset_remove_neurons, reset_neurons_put_back, reset_neuron_to_remove, reset_p, reset_level, reset_removed_stim_neurons, reset_key, reset_converged) = reset_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Next state:')\n",
    "for att in next_state:\n",
    "    if jnp.ndim(att) > 0:\n",
    "        print(jnp.where(att>0))\n",
    "print('Reset state:')\n",
    "for att in reset_state:\n",
    "    if jnp.ndim(att) > 0:\n",
    "        print(jnp.where(att>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_type = \"baseline\"\n",
    "Rs = run_simulation_batched(\n",
    "    neuron_params, sim_params, simulation_type,\n",
    "    batch_size=getattr(cfg.experiment, \"batch_size\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get active MN activity using JAX-compatible approach\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "active_mask = ((max_frs>0) & mn_mask)  # Combine max_frs with mn_mask to get active neurons\n",
    "\n",
    "oscillation_score, _ = compute_oscillation_score(R[..., start:], active_mask, prominence=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscillation_threshold = 0.1\n",
    "# Load data (this part stays on CPU)\n",
    "w_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "\n",
    "## Initialize parameters\n",
    "neuron_params = prepare_neuron_params(cfg, w_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "all_neurons = w_table.index.to_numpy()\n",
    "\n",
    "\n",
    "# Initialize state\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "removed_stim_neurons = jnp.full([n_sims, neuron_params.removed_neurons.shape[-1]], -1, dtype=jnp.int32)\n",
    "prev_neurons_put_back = jnp.full([n_sims, neuron_params.removed_neurons.shape[-1]], -1, dtype=jnp.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full pipeline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prune_net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscillation_threshold = 0.2\n",
    "# Load data (this part stays on CPU)\n",
    "w_table = load_wTable(cfg.experiment.dfPath)\n",
    "n_stim_configs = len(cfg.experiment.stimNeurons)\n",
    "## Initialize parameters\n",
    "neuron_params = prepare_neuron_params(cfg, w_table)\n",
    "sim_params = prepare_sim_params(cfg, n_stim_configs, neuron_params.W.shape[0])\n",
    "all_neurons = w_table.index.to_numpy()\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "mn_idxs = jnp.asarray(w_table.loc[w_table[\"class\"]==\"motor neuron\"].index.values)\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "clip_start = int(cfg.sim.pulseStart / cfg.sim.dt) + 100\n",
    "\n",
    "total_sims = sim_params.n_stim_configs * sim_params.n_param_sets\n",
    "batch_size = getattr(cfg.experiment, \"batch_size\", None)\n",
    "if batch_size is None:\n",
    "    batch_size = calculate_optimal_batch_size(\n",
    "        sim_params.n_neurons, len(sim_params.t_axis)\n",
    "    )\n",
    "    \n",
    "batch_func = process_batch_prune\n",
    "# Create parallel version for multiple devices\n",
    "if jax.device_count() > 1:\n",
    "    batch_func = pmap(batch_func, axis_name=\"device\", in_axes=(None, None, 0))\n",
    "    batch_size = (batch_size // jax.device_count()) * jax.device_count()\n",
    "\n",
    "print(f\"Running {total_sims} simulations with batch size {batch_size}\")\n",
    "\n",
    "# Process in batches\n",
    "all_results = []\n",
    "n_batches = (total_sims + batch_size - 1) // batch_size\n",
    "\n",
    "# for i in range(n_batches):\n",
    "i = 0 \n",
    "start_idx = i * batch_size\n",
    "end_idx = min((i + 1) * batch_size, total_sims)\n",
    "\n",
    "batch_indices = jnp.arange(start_idx, end_idx)\n",
    "\n",
    "# Pad if necessary for pmap\n",
    "if jax.device_count() > 1 and len(batch_indices) < batch_size:\n",
    "    pad_size = batch_size - len(batch_indices)\n",
    "    batch_indices = jnp.concatenate([\n",
    "        batch_indices, \n",
    "        jnp.repeat(batch_indices[-1], pad_size)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mn_idxs = neuron_params.mn_idxs\n",
    "all_neurons = jnp.arange(neuron_params.W.shape[-1])\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "\n",
    "clip_start = int(sim_params.pulse_start / sim_params.dt) + 100\n",
    "# Initialize state\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "W_mask = jnp.full((n_sims, neuron_params.W.shape[0], neuron_params.W.shape[1]), 1, dtype=jnp.float32)\n",
    "interneuron_mask = jnp.full((n_sims, W_mask.shape[-1]),fill_value=False, dtype=jnp.bool_)\n",
    "interneuron_mask = interneuron_mask.at[:,in_idxs].set(True)\n",
    "level = jnp.zeros((n_sims,1), dtype=jnp.int32)\n",
    "total_removed_neurons = jnp.full((n_sims, W_mask.shape[-1]), False, dtype=jnp.bool)\n",
    "removed_stim_neurons = jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "neurons_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "prev_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "last_removed =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool) # Use False for None\n",
    "min_circuit = jnp.full((n_sims,1), False)\n",
    "\n",
    "# Initialize probabilities\n",
    "exclude_mask = (~interneuron_mask)\n",
    "p_arrays = jax.vmap(removal_probability)(jnp.ones(len(interneuron_mask)), exclude_mask)\n",
    "\n",
    "# initialize pruning state\n",
    "state = Pruning_state(\n",
    "    W_mask=W_mask,\n",
    "    interneuron_mask=interneuron_mask,\n",
    "    level=level,\n",
    "    total_removed_neurons=total_removed_neurons,\n",
    "    removed_stim_neurons=removed_stim_neurons,\n",
    "    neurons_put_back=neurons_put_back,\n",
    "    prev_put_back=prev_put_back,\n",
    "    last_removed=last_removed,\n",
    "    remove_p=p_arrays,\n",
    "    min_circuit=min_circuit,\n",
    "    keys=neuron_params.seeds\n",
    ")\n",
    "\n",
    "iter_start = 0  # Starting iteration\n",
    "# Main pruning loop\n",
    "iteration = iter_start\n",
    "max_iterations = 3  # Safety limit\n",
    "while not jnp.all(min_circuit) and (iteration < max_iterations):\n",
    "    start_time = time.time()\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    # Update neuron parameters W_mask based on the current state\n",
    "    neuron_params = neuron_params._replace(W_mask=state.W_mask)\n",
    "    # Run simulation (this would call your simulation function)\n",
    "    # Reshape for devices if using pmap\n",
    "    if jax.device_count() > 1:\n",
    "        batch_indices = batch_indices.reshape(jax.device_count(), -1)\n",
    "        batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "        batch_results = batch_results.reshape(-1, *batch_results.shape[2:])\n",
    "        batch_results = batch_results[:end_idx - start_idx]  # Remove padding\n",
    "    else:\n",
    "        batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "    \n",
    "    n = 0 \n",
    "    state = jax.vmap(update_single_sim_state, in_axes=(0, 0, None, None, None))(state, batch_results, mn_idxs, oscillation_threshold, clip_start)\n",
    "    iteration += 1\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  Total time: {elapsed:.2f} seconds\")\n",
    "\n",
    "# batch_results = jax.device_put(batch_results, jax.devices(\"cpu\")[0])\n",
    "# all_results.append(batch_results)\n",
    "# print(f\"Batch {i + 1}/{n_batches} completed\")\n",
    "\n",
    "# del batch_results  # Free memory\n",
    "# gc.collect()  # Force garbage collection\n",
    "\n",
    "# Combine results\n",
    "# results = jnp.concatenate(all_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mn_idxs = neuron_params.mn_idxs\n",
    "all_neurons = jnp.arange(neuron_params.W.shape[-1])\n",
    "in_idxs = jnp.setdiff1d(all_neurons, mn_idxs)\n",
    "\n",
    "clip_start = int(sim_params.pulse_start / sim_params.dt) + 100\n",
    "# Initialize state\n",
    "n_sims = sim_params.n_param_sets * sim_params.n_stim_configs\n",
    "W_mask = jnp.full((n_sims, neuron_params.W.shape[0], neuron_params.W.shape[1]), 1, dtype=jnp.float32)\n",
    "interneuron_mask = jnp.full((n_sims, W_mask.shape[-1]),fill_value=False, dtype=jnp.bool_)\n",
    "interneuron_mask = interneuron_mask.at[:,in_idxs].set(True)\n",
    "level = jnp.zeros((n_sims,1), dtype=jnp.int32)\n",
    "total_removed_neurons = jnp.full((n_sims, W_mask.shape[-1]), False, dtype=jnp.bool)\n",
    "removed_stim_neurons = jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "neurons_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "prev_put_back =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool)\n",
    "last_removed =  jnp.full([n_sims, total_removed_neurons.shape[-1]], False, dtype=jnp.bool) # Use False for None\n",
    "min_circuit = jnp.full((n_sims,1), False)\n",
    "\n",
    "# Initialize probabilities\n",
    "exclude_mask = (~interneuron_mask)\n",
    "p_arrays = jax.vmap(removal_probability)(jnp.ones(len(interneuron_mask)), exclude_mask)\n",
    "\n",
    "# initialize pruning state\n",
    "state = Pruning_state(\n",
    "    W_mask=W_mask[0],\n",
    "    interneuron_mask=interneuron_mask[0],\n",
    "    level=level[0],\n",
    "    total_removed_neurons=total_removed_neurons[0],\n",
    "    removed_stim_neurons=removed_stim_neurons[0],\n",
    "    neurons_put_back=neurons_put_back[0],\n",
    "    prev_neurons_put_back=prev_put_back[0],\n",
    "    last_removed=last_removed[0],\n",
    "    remove_p=p_arrays[0],\n",
    "    min_circuit=min_circuit[0],\n",
    "    keys=neuron_params.seeds[0],\n",
    ")\n",
    "R = batch_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "((~interneuron_mask) == mn_mask).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unpack state\n",
    "(W_mask, interneuron_mask, level, total_removed_neurons, removed_stim_neurons,\n",
    "    neurons_put_back, last_removed, remove_p, min_circuit, key) = state\n",
    "\n",
    "# Get active MN activity using JAX-compatible approach\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "active_mask = ((max_frs>0) & mn_mask)\n",
    "\n",
    "# Compute oscillation score\n",
    "oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "\n",
    "# Check if oscillation is below threshold or NaN\n",
    "reset_condition = (oscillation_score < oscillation_threshold) | jnp.isnan(oscillation_score)\n",
    "\n",
    "# Identify currently silent interneurons (these will be permanently removed)\n",
    "silent_interneurons = interneuron_mask & (max_frs <= 0)\n",
    "\n",
    "key_next, subkey_continue, subkey_reset = random.split(key, 3)\n",
    "\n",
    "# === CONTINUE BRANCH: Normal pruning (oscillation is good) ===\n",
    "# Permanently remove silent interneurons\n",
    "total_removed_continue = total_removed_neurons | silent_interneurons\n",
    "\n",
    "# Update probabilities - exclude non-interneurons and removed neurons\n",
    "exclude_mask_continue = (~interneuron_mask) | total_removed_continue\n",
    "p_continue = removal_probability(max_frs, exclude_mask_continue)\n",
    "\n",
    "# Sample new neuron to remove (only from available interneurons)\n",
    "neuron_idx_continue = jax_choice(subkey_continue, jnp.arange(len(max_frs)), p_continue)\n",
    "\n",
    "# Update removed neurons\n",
    "removed_stim_continue = removed_stim_neurons.at[neuron_idx_continue].set(True)\n",
    "total_removed_continue = total_removed_continue.at[neuron_idx_continue].set(True)\n",
    "\n",
    "# Track what was removed this iteration (both silent and stimulated)\n",
    "newly_silent_continue = silent_interneurons & (~total_removed_neurons)  # Only newly silent\n",
    "last_removed_continue = jnp.full(last_removed.shape, False, dtype=jnp.bool_)\n",
    "last_removed_continue = last_removed_continue.at[neuron_idx_continue].set(True)  # Stimulated removal\n",
    "last_removed_continue = last_removed_continue | newly_silent_continue  # Add newly silent\n",
    "\n",
    "# Update other state\n",
    "level_continue = level + 1\n",
    "neurons_put_back_continue = neurons_put_back  # Unchanged\n",
    "min_circuit_continue = False  # Not converged yet\n",
    "\n",
    "# === RESET BRANCH: Restore last removed and try again ===\n",
    "# Restore ALL neurons from last_removed (both stimulated and those that went silent)\n",
    "# This includes neurons that went silent due to the last stimulated removal\n",
    "\n",
    "# Restore stimulated neurons from last removal\n",
    "removed_stim_reset = removed_stim_neurons & (~last_removed)\n",
    "\n",
    "# For total_removed: keep permanent removals from before last iteration, \n",
    "# add current silent neurons, but restore all last_removed neurons\n",
    "permanent_before_last = total_removed_neurons & (~last_removed)\n",
    "# Current silent neurons are those silent now (may include some that weren't silent before)\n",
    "# But we need to be careful not to restore neurons that are currently silent due to OTHER reasons\n",
    "# Only add neurons to total_removed if they are silent AND were not in last_removed\n",
    "currently_silent_not_restored = silent_interneurons & (~last_removed)\n",
    "total_removed_reset = permanent_before_last | currently_silent_not_restored\n",
    "\n",
    "# Track neurons being put back - ALL neurons from last_removed\n",
    "# This includes both the stimulated neuron and any neurons that went silent due to that removal\n",
    "restored_neurons = last_removed  # All neurons from last_removed are being restored\n",
    "neurons_put_back_reset = neurons_put_back | restored_neurons\n",
    "\n",
    "# Now select a different neuron to remove (avoid the restored ones)\n",
    "exclude_mask_reset = (~interneuron_mask) | total_removed_reset | restored_neurons\n",
    "p_reset = removal_probability(max_frs, exclude_mask_reset)\n",
    "\n",
    "# Check how many neurons are available\n",
    "available_neurons_reset = jnp.sum(interneuron_mask & (~exclude_mask_reset))\n",
    "\n",
    "# Select neuron to remove\n",
    "neuron_idx_reset = jax_choice(subkey_reset, jnp.arange(len(max_frs)), p_reset)\n",
    "\n",
    "# Only update if we have available neurons (otherwise keep current state)\n",
    "should_remove_new = available_neurons_reset > 0\n",
    "removed_stim_reset = jax.lax.select(\n",
    "    should_remove_new,\n",
    "    removed_stim_reset.at[neuron_idx_reset].set(True),\n",
    "    removed_stim_reset\n",
    ")\n",
    "total_removed_reset = jax.lax.select(\n",
    "    should_remove_new,\n",
    "    total_removed_reset.at[neuron_idx_reset].set(True),\n",
    "    total_removed_reset\n",
    ")\n",
    "\n",
    "# Track what was newly removed this iteration\n",
    "last_removed_reset = jnp.full(last_removed.shape, False, dtype=jnp.bool_)\n",
    "last_removed_reset = jax.lax.select(\n",
    "    should_remove_new,\n",
    "    last_removed_reset.at[neuron_idx_reset].set(True),\n",
    "    last_removed_reset\n",
    ")\n",
    "\n",
    "# Add any newly silent neurons (those that are silent now but weren't in total_removed_neurons before)\n",
    "# These are neurons that became silent due to current network state, not due to last removal\n",
    "newly_silent_reset = silent_interneurons & (~total_removed_neurons) & (~last_removed)\n",
    "last_removed_reset = last_removed_reset | newly_silent_reset\n",
    "\n",
    "# Keep level the same (we're trying again, not progressing)\n",
    "level_reset = level\n",
    "\n",
    "# Check if we've converged - either no more neurons to remove OR we're oscillating\n",
    "# Oscillation detection: if we're restoring neurons we've put back before, we're in a loop\n",
    "oscillation_detected = jnp.any(restored_neurons & neurons_put_back)\n",
    "min_circuit_reset = (available_neurons_reset <= 2) | oscillation_detected\n",
    "\n",
    "# === SELECT BETWEEN BRANCHES ===\n",
    "# Use jax.lax.select to choose between continue and reset results\n",
    "final_total_removed = jax.lax.select(reset_condition, total_removed_reset, total_removed_continue)\n",
    "final_removed_stim = jax.lax.select(reset_condition, removed_stim_reset, removed_stim_continue)\n",
    "final_last_removed = jax.lax.select(reset_condition, last_removed_reset, last_removed_continue)\n",
    "final_neurons_put_back = jax.lax.select(reset_condition, neurons_put_back_reset, neurons_put_back_continue)\n",
    "final_level = jax.lax.select(reset_condition, level_reset, level_continue)\n",
    "final_p = jax.lax.select(reset_condition, p_reset, p_continue)\n",
    "final_min_circuit = jax.lax.select(reset_condition, min_circuit_reset, min_circuit_continue)\n",
    "\n",
    "# Calculate available neurons and check for convergence\n",
    "available_neurons = jnp.sum(interneuron_mask & (~final_total_removed))\n",
    "\n",
    "# Check for oscillation: if we're in reset mode and detected oscillation, we've converged\n",
    "oscillation_converged = reset_condition & final_min_circuit\n",
    "size_converged = available_neurons <= 2\n",
    "final_converged = oscillation_converged | size_converged\n",
    "\n",
    "# Update W_mask to reflect removed neurons\n",
    "W_mask_init = jnp.ones_like(W_mask, dtype=jnp.float32)\n",
    "removed_float = final_total_removed.astype(jnp.float32)\n",
    "kept_mask = 1.0 - removed_float\n",
    "W_mask_new = W_mask_init * kept_mask[:, None] * kept_mask[None, :]\n",
    "\n",
    "# Convert to scalar for jax.lax.select\n",
    "final_converged_scalar = jnp.squeeze(final_converged)\n",
    "\n",
    "# Debug information\n",
    "jax.debug.print(\"Oscillation score: {score}\", score=oscillation_score)\n",
    "jax.debug.print(\"Reset condition (below threshold): {condition}\", condition=reset_condition)\n",
    "jax.debug.print(\"Available neurons: {count}\", count=available_neurons)\n",
    "jax.debug.print(\"Level: {level}\", level=final_level)\n",
    "jax.debug.print(\"Oscillation detected: {detected}\", detected=reset_condition & (final_min_circuit & ~size_converged))\n",
    "jax.debug.print(\"Final converged: {converged}\", converged=final_converged)\n",
    "jax.debug.print(\"Silent neurons removed: {count}\", count=jnp.sum(silent_interneurons))\n",
    "print('\\n')\n",
    "\n",
    "# When converged, preserve current state (don't make further changes)\n",
    "state = Pruning_state(\n",
    "    W_mask=jax.lax.select(final_converged_scalar, W_mask, W_mask_new),\n",
    "    interneuron_mask=interneuron_mask,\n",
    "    level=jax.lax.select(final_converged_scalar, level, final_level),\n",
    "    total_removed_neurons=jax.lax.select(final_converged_scalar, total_removed_neurons, final_total_removed),\n",
    "    neurons_put_back=jax.lax.select(final_converged_scalar, neurons_put_back, final_neurons_put_back),\n",
    "    removed_stim_neurons=jax.lax.select(final_converged_scalar, removed_stim_neurons, final_removed_stim),\n",
    "    last_removed=jax.lax.select(final_converged_scalar, last_removed, final_last_removed),\n",
    "    remove_p=jax.lax.select(final_converged_scalar, remove_p, final_p),\n",
    "    min_circuit=final_converged_scalar,\n",
    "    keys=key_next,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_inds(~load_state.total_removed_neurons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_inds = print_inds(exclude_mask_continue)\n",
    "in_idxs.shape[0] - exclude_inds.shape[0]  # Number of interneurons left after pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_inds(~exclude_mask_continue), print_inds(~exclude_mask_reset), print_inds(~final_total_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pytree(pytree):\n",
    "    \"\"\"\n",
    "    path_filter: function that takes key_path tuple and returns True/False\n",
    "    \"\"\"\n",
    "    def process_leaf(key_path, leaf):\n",
    "       print(f\"Key Path: {key_path[0]}, Leaf: {leaf.shape} dype: {leaf.dtype}\")\n",
    "\n",
    "    return jax.tree.map_with_path(process_leaf, pytree)\n",
    "print_pytree(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from src.sim_utils import compute_oscillation_score\n",
    "from src.optimized_vnc import update_params\n",
    "\n",
    "@dataclass\n",
    "class Pruning_state:\n",
    "    W_mask: jnp.ndarray\n",
    "    interneuron_mask: jnp.ndarray\n",
    "    level: int\n",
    "    total_removed_neurons: jnp.ndarray\n",
    "    neurons_put_back_current: jnp.ndarray\n",
    "    neurons_put_back_prev: jnp.ndarray\n",
    "    removed_stim_neurons: jnp.ndarray\n",
    "    last_removed: jnp.ndarray\n",
    "    remove_p: jnp.ndarray\n",
    "    round_complete: bool\n",
    "    converged: bool\n",
    "    round_number: int\n",
    "    keys: jax.random.PRNGKey\n",
    "    steps_in_current_round: int  # Track steps within current round\n",
    "    total_iterations: int        # Track total iterations for safety\n",
    "\n",
    "def safe_choice(key, logits, exclude_mask):\n",
    "    \"\"\"Safe choice function that works with vmap\"\"\"\n",
    "    # Set excluded neurons to very negative logits\n",
    "    safe_logits = jnp.where(exclude_mask, -1e10, logits)\n",
    "    # Use gumbel trick for sampling\n",
    "    gumbel_noise = jax.random.gumbel(key, safe_logits.shape)\n",
    "    return jnp.argmax(safe_logits + gumbel_noise)\n",
    "\n",
    "def removal_probability_safe(max_frs, exclude_mask):\n",
    "    \"\"\"Safe removal probability that works with vmap\"\"\"\n",
    "    # Create base probabilities (higher firing rate = lower removal probability)\n",
    "    base_probs = 1.0 / (max_frs + 1e-6)  # Add epsilon to avoid division by zero\n",
    "    # Zero out excluded neurons\n",
    "    probs = jnp.where(exclude_mask, 0.0, base_probs)\n",
    "    # Normalize (with safety for all-zero case)\n",
    "    total_prob = jnp.sum(probs)\n",
    "    return jnp.where(total_prob > 0, probs / total_prob, probs)\n",
    "\n",
    "def pruning_step_dynamic(state, R, mn_idxs, clip_start, oscillation_threshold):\n",
    "    \"\"\"\n",
    "    Single pruning step with dynamic convergence checking.\n",
    "    Works with vmap and continues until natural convergence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Safety check - stop if max iterations reached\n",
    "    max_iterations_reached = state.total_iterations >= 200\n",
    "    already_converged = state.converged\n",
    "    \n",
    "    # If we should stop, return unchanged state\n",
    "    should_stop = already_converged | max_iterations_reached\n",
    "    \n",
    "    def stopped_computation():\n",
    "        return state._replace(\n",
    "            converged=True,  # Mark as converged if we hit max iterations\n",
    "            total_iterations=state.total_iterations + 1\n",
    "        )\n",
    "    \n",
    "    def active_computation():\n",
    "        # Get neural activity\n",
    "        max_frs = jnp.max(R, axis=-1)\n",
    "        mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "        active_mask = (max_frs > 0) & mn_mask\n",
    "\n",
    "        # Compute oscillation score\n",
    "        oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n",
    "        reset_condition = (oscillation_score < oscillation_threshold) | jnp.isnan(oscillation_score)\n",
    "\n",
    "        # Identify silent interneurons (permanent removal)\n",
    "        silent_interneurons = state.interneuron_mask & (max_frs <= 0)\n",
    "        \n",
    "        # Generate key for this iteration\n",
    "        key = jax.random.fold_in(state.keys, state.total_iterations)\n",
    "        key_continue, key_reset = jax.random.split(key)\n",
    "        \n",
    "        # Check if we need to start a new round\n",
    "        def check_new_round():\n",
    "            \"\"\"Check if current round is complete and handle round transition\"\"\"\n",
    "            \n",
    "            # Current round is complete if no interneurons available for removal\n",
    "            exclude_mask = (~state.interneuron_mask) | state.total_removed_neurons | state.neurons_put_back_current\n",
    "            available_neurons = jnp.sum(state.interneuron_mask & (~exclude_mask))\n",
    "            current_round_done = available_neurons <= 0\n",
    "            \n",
    "            def start_new_round():\n",
    "                # Compare current and previous put-back lists for convergence\n",
    "                lists_identical = jnp.allclose(state.neurons_put_back_current, \n",
    "                                             state.neurons_put_back_prev, atol=1e-6)\n",
    "                \n",
    "                # If lists are identical, we've converged\n",
    "                new_converged = lists_identical\n",
    "                \n",
    "                # Start new round\n",
    "                return state._replace(\n",
    "                    neurons_put_back_prev=state.neurons_put_back_current,\n",
    "                    neurons_put_back_current=jnp.zeros_like(state.neurons_put_back_current),\n",
    "                    removed_stim_neurons=jnp.zeros_like(state.removed_stim_neurons),\n",
    "                    last_removed=jnp.zeros_like(state.last_removed),\n",
    "                    level=0,\n",
    "                    round_complete=False,\n",
    "                    converged=new_converged,\n",
    "                    round_number=state.round_number + 1,\n",
    "                    steps_in_current_round=0\n",
    "                )\n",
    "            \n",
    "            def continue_current_round():\n",
    "                return state\n",
    "            \n",
    "            # Start new round if current one is complete\n",
    "            return jax.lax.cond(current_round_done, start_new_round, continue_current_round)\n",
    "        \n",
    "        # Check for round transition first\n",
    "        state_after_round_check = check_new_round()\n",
    "        \n",
    "        # If we just converged in round transition, return that state\n",
    "        def handle_convergence():\n",
    "            return state_after_round_check._replace(\n",
    "                total_iterations=state.total_iterations + 1\n",
    "            )\n",
    "        \n",
    "        def normal_pruning_step():\n",
    "            \"\"\"Normal within-round pruning step\"\"\"\n",
    "            \n",
    "            # === CONTINUE BRANCH: Normal removal ===\n",
    "            total_removed_continue = state_after_round_check.total_removed_neurons | silent_interneurons\n",
    "            exclude_mask_continue = (~state_after_round_check.interneuron_mask) | total_removed_continue | state_after_round_check.neurons_put_back_current\n",
    "            \n",
    "            # Check if any neurons available for removal in continue branch\n",
    "            available_neurons_continue = jnp.sum(state_after_round_check.interneuron_mask & (~exclude_mask_continue))\n",
    "            \n",
    "            # Sample neuron to remove\n",
    "            p_continue = removal_probability_safe(max_frs, exclude_mask_continue)\n",
    "            neuron_idx_continue = safe_choice(key_continue, p_continue, exclude_mask_continue)\n",
    "            \n",
    "            # Update for continue branch (only if neurons available)\n",
    "            can_remove_continue = available_neurons_continue > 0\n",
    "            \n",
    "            removed_stim_continue = jnp.where(\n",
    "                can_remove_continue,\n",
    "                state_after_round_check.removed_stim_neurons.at[neuron_idx_continue].set(True),\n",
    "                state_after_round_check.removed_stim_neurons\n",
    "            )\n",
    "            total_removed_continue = jnp.where(\n",
    "                can_remove_continue,\n",
    "                total_removed_continue.at[neuron_idx_continue].set(True),\n",
    "                total_removed_continue\n",
    "            )\n",
    "            \n",
    "            # Track last removed\n",
    "            last_removed_continue = jnp.zeros_like(state_after_round_check.last_removed)\n",
    "            last_removed_continue = jnp.where(\n",
    "                can_remove_continue,\n",
    "                last_removed_continue.at[neuron_idx_continue].set(True),\n",
    "                last_removed_continue\n",
    "            )\n",
    "            # Add newly silent neurons\n",
    "            newly_silent = silent_interneurons & (~state_after_round_check.total_removed_neurons)\n",
    "            last_removed_continue = last_removed_continue | newly_silent\n",
    "            \n",
    "            # === RESET BRANCH: Restore and try different neuron ===\n",
    "            # Restore last removed neurons to put_back list\n",
    "            neurons_put_back_reset = state_after_round_check.neurons_put_back_current | state_after_round_check.last_removed\n",
    "            removed_stim_reset = state_after_round_check.removed_stim_neurons & (~state_after_round_check.last_removed)\n",
    "            total_removed_reset = (state_after_round_check.total_removed_neurons & (~state_after_round_check.last_removed)) | silent_interneurons\n",
    "            \n",
    "            exclude_mask_reset = (~state_after_round_check.interneuron_mask) | total_removed_reset | neurons_put_back_reset\n",
    "            available_neurons_reset = jnp.sum(state_after_round_check.interneuron_mask & (~exclude_mask_reset))\n",
    "            \n",
    "            # Sample different neuron\n",
    "            p_reset = removal_probability_safe(max_frs, exclude_mask_reset)\n",
    "            neuron_idx_reset = safe_choice(key_reset, p_reset, exclude_mask_reset)\n",
    "            \n",
    "            can_remove_reset = available_neurons_reset > 0\n",
    "            \n",
    "            removed_stim_reset = jnp.where(\n",
    "                can_remove_reset,\n",
    "                removed_stim_reset.at[neuron_idx_reset].set(True),\n",
    "                removed_stim_reset\n",
    "            )\n",
    "            total_removed_reset = jnp.where(\n",
    "                can_remove_reset,\n",
    "                total_removed_reset.at[neuron_idx_reset].set(True),\n",
    "                total_removed_reset\n",
    "            )\n",
    "            \n",
    "            last_removed_reset = jnp.zeros_like(state_after_round_check.last_removed)\n",
    "            last_removed_reset = jnp.where(\n",
    "                can_remove_reset,\n",
    "                last_removed_reset.at[neuron_idx_reset].set(True),\n",
    "                last_removed_reset\n",
    "            )\n",
    "            # Add newly silent neurons (excluding those already in last_removed)\n",
    "            newly_silent_reset = silent_interneurons & (~state_after_round_check.total_removed_neurons) & (~state_after_round_check.last_removed)\n",
    "            last_removed_reset = last_removed_reset | newly_silent_reset\n",
    "            \n",
    "            # Choose between branches based on reset condition\n",
    "            final_total_removed = jnp.where(reset_condition, total_removed_reset, total_removed_continue)\n",
    "            final_removed_stim = jnp.where(reset_condition, removed_stim_reset, removed_stim_continue)\n",
    "            final_last_removed = jnp.where(reset_condition, last_removed_reset, last_removed_continue)\n",
    "            final_neurons_put_back = jnp.where(reset_condition, neurons_put_back_reset, state_after_round_check.neurons_put_back_current)\n",
    "            final_remove_p = jnp.where(reset_condition, p_reset, p_continue)\n",
    "            \n",
    "            # Update W_mask based on removed neurons\n",
    "            removed_float = final_total_removed.astype(jnp.float32)\n",
    "            kept_mask = 1.0 - removed_float\n",
    "            W_mask_new = kept_mask[:, None] * kept_mask[None, :]\n",
    "            \n",
    "            return state_after_round_check._replace(\n",
    "                W_mask=W_mask_new,\n",
    "                level=state_after_round_check.level + 1,\n",
    "                total_removed_neurons=final_total_removed,\n",
    "                neurons_put_back_current=final_neurons_put_back,\n",
    "                removed_stim_neurons=final_removed_stim,\n",
    "                last_removed=final_last_removed,\n",
    "                remove_p=final_remove_p,\n",
    "                steps_in_current_round=state_after_round_check.steps_in_current_round + 1,\n",
    "                total_iterations=state.total_iterations + 1\n",
    "            )\n",
    "        \n",
    "        # Choose between convergence handling and normal step\n",
    "        return jax.lax.cond(\n",
    "            state_after_round_check.converged, \n",
    "            handle_convergence, \n",
    "            normal_pruning_step\n",
    "        )\n",
    "    \n",
    "    # Main conditional: stop or continue\n",
    "    return jax.lax.cond(should_stop, stopped_computation, active_computation)\n",
    "\n",
    "# Vmap-compatible version\n",
    "@partial(jax.vmap, in_axes=(0, 0, None, None, None))\n",
    "def pruning_step_batched(state_batch, R_batch, mn_idxs, clip_start, oscillation_threshold):\n",
    "    \"\"\"Vectorized pruning step that works across a batch\"\"\"\n",
    "    return pruning_step_dynamic(state_batch, R_batch, mn_idxs, clip_start, oscillation_threshold)\n",
    "\n",
    "def run_pruning_algorithm_batched(neuron_params, sim_params, initial_states, Rs, mn_idxs, clip_start, oscillation_threshold):\n",
    "    \"\"\"\n",
    "    Run pruning algorithm on batch until convergence or max iterations (200).\n",
    "    \n",
    "    Args:\n",
    "        initial_states: Batched Pruning_state \n",
    "        Rs: Batch of neural activity [batch_size, neurons, time]\n",
    "        mn_idxs: Motor neuron indices\n",
    "        clip_start: Start index for oscillation analysis\n",
    "        oscillation_threshold: Threshold for oscillation score\n",
    "    \n",
    "    Returns:\n",
    "        final_states: Final states for each batch element\n",
    "        iterations_used: Number of iterations each element used\n",
    "    \"\"\"\n",
    "    \n",
    "    def should_continue(state_batch):\n",
    "        \"\"\"Check if any element in batch needs to continue\"\"\"\n",
    "        return jnp.any(~state_batch.converged)\n",
    "    \n",
    "    def iteration_step(state_batch):\n",
    "        \"\"\"Single iteration across the batch\"\"\"\n",
    "        neuron_params = neuron_params._replace(W_mask=state.W_mask)\n",
    "        batch_results = batch_func(neuron_params, sim_params, batch_indices)\n",
    "        return pruning_step_batched(state_batch, Rs, mn_idxs, clip_start, oscillation_threshold)\n",
    "    \n",
    "    # Run until all converged or max iterations reached\n",
    "    current_states = initial_states\n",
    "    max_iterations = 200\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Take one step for all batch elements\n",
    "        current_states = iteration_step(current_states)\n",
    "        \n",
    "        # Check if all converged - optional early stopping for efficiency\n",
    "        if not should_continue(current_states):\n",
    "            break\n",
    "    \n",
    "    return current_states\n",
    "\n",
    "def create_batched_initial_state(batch_size, n_neurons, key=None):\n",
    "    \"\"\"Helper to create batched initial states\"\"\"\n",
    "    if key is None:\n",
    "        key = jax.random.PRNGKey(42)\n",
    "    \n",
    "    keys = jax.random.split(key, batch_size)\n",
    "    \n",
    "    return Pruning_state(\n",
    "        W_mask=jnp.ones((batch_size, n_neurons, n_neurons)),\n",
    "        interneuron_mask=jnp.ones((batch_size, n_neurons), dtype=bool),\n",
    "        level=jnp.zeros(batch_size, dtype=int),\n",
    "        total_removed_neurons=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        neurons_put_back_current=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        neurons_put_back_prev=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        removed_stim_neurons=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        last_removed=jnp.zeros((batch_size, n_neurons), dtype=bool),\n",
    "        remove_p=jnp.ones((batch_size, n_neurons)) / n_neurons,\n",
    "        round_complete=jnp.zeros(batch_size, dtype=bool),\n",
    "        converged=jnp.zeros(batch_size, dtype=bool),\n",
    "        round_number=jnp.zeros(batch_size, dtype=int),\n",
    "        keys=keys,\n",
    "        steps_in_current_round=jnp.zeros(batch_size, dtype=int),\n",
    "        total_iterations=jnp.zeros(batch_size, dtype=int)\n",
    "    )\n",
    "\n",
    "# Usage example:\n",
    "\n",
    "# Create batch\n",
    "batch_size = 16\n",
    "n_neurons = 100\n",
    "initial_states = create_batched_initial_state(batch_size, n_neurons)\n",
    "\n",
    "# Your neural activity data\n",
    "Rs = jnp.ones((batch_size, n_neurons, 1000))  # [batch, neurons, time]\n",
    "mn_idxs = jnp.array([0, 1, 2])  # Motor neuron indices\n",
    "\n",
    "# Run algorithm\n",
    "final_states = run_pruning_algorithm_batched(\n",
    "    neuron_params, sim_params,\n",
    "    initial_states, Rs, mn_idxs, \n",
    "    clip_start=100, oscillation_threshold=0.5\n",
    ")\n",
    "\n",
    "# Check results\n",
    "print(f\"Converged: {jnp.sum(final_states.converged)} / {batch_size}\")\n",
    "print(f\"Iterations used: {final_states.total_iterations}\")\n",
    "print(f\"Hit max iterations: {jnp.sum(final_states.total_iterations >= 200)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparse.load_npz(cfg.paths.ckpt_dir  / f\"{cfg.experiment.name}_Rs.npz\").todense().astype(np.float32)\n",
    "# W_mask = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_W_mask.npz\").todense().astype(np.float32)\n",
    "# total_removed_neurons = sparse.load_npz(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_total_removed.npz\").todense().astype(np.bool_)\n",
    "# load_state = load_state(cfg.paths.ckpt_dir / f\"{cfg.experiment.name}_state.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_mask_init = jnp.ones_like(W_mask, dtype=jnp.float32)\n",
    "removed_float = (~load_state.neurons_put_back[0]).astype(jnp.float32)\n",
    "kept_mask = 1.0 - removed_float # set removed neurons to 0 and kept neurons to 1\n",
    "W_mask_new = W_mask_init * kept_mask[:, None] * kept_mask[None, :] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_params = update_neuron_params(neuron_params, W_mask=W_mask_new)\n",
    "\n",
    "batch_results = batch_func(neuron_params, sim_params, batch_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_inds(~load_state.total_removed_neurons[0] & ~interneuron_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_inds((~load_state.total_removed_neurons[1]& ~interneuron_mask[1]))\n",
    "available_neurons = jnp.where(interneuron_mask[1] & (~load_state.total_removed_neurons[1]) & (~load_state.neurons_put_back[1]))\n",
    "available_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.isin(available_neurons[0],in_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_neurons = jnp.where(jnp.sum(R,axis=-1)>0)[0]\n",
    "plt.plot(R[active_neurons].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get active MN activity using JAX-compatible approach\n",
    "max_frs = jnp.max(R, axis=-1)\n",
    "mn_mask = jnp.isin(jnp.arange(R.shape[0]), mn_idxs)\n",
    "active_mask = ((max_frs>0) & mn_mask)\n",
    "\n",
    "# Compute oscillation score\n",
    "oscillation_score, _ = compute_oscillation_score(R[..., clip_start:], active_mask, prominence=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a6662942050>,\n",
       " <matplotlib.lines.Line2D at 0x7a665c7a8050>,\n",
       " <matplotlib.lines.Line2D at 0x7a666297c210>,\n",
       " <matplotlib.lines.Line2D at 0x7a66629d0950>,\n",
       " <matplotlib.lines.Line2D at 0x7a66629c8410>,\n",
       " <matplotlib.lines.Line2D at 0x7a665c388750>,\n",
       " <matplotlib.lines.Line2D at 0x7a6662990c50>,\n",
       " <matplotlib.lines.Line2D at 0x7a66629d90d0>,\n",
       " <matplotlib.lines.Line2D at 0x7a6662929510>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# R = batch_results[0]\n",
    "R = results[0,1]\n",
    "\n",
    "\n",
    "wTable = pd.read_csv(\"../data/manc t1 connectome data/wTable_20231020_DNtoMN_unsorted_withModules.csv\",index_col=0)\n",
    "nonMns = wTable.loc[(wTable[\"bodyId\"]==10093) | (wTable[\"bodyId\"]==10707) | (wTable[\"bodyId\"]==13905) | (wTable[\"bodyId\"]==11751)]\n",
    "mnIdxs = wTable.loc[wTable[\"class\"]==\"motor neuron\"].index\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax = axs[0]\n",
    "ax.plot(R[mnIdxs].T)\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(R[nonMns.index].T)\n",
    "# for i in nonMns.index:\n",
    "# # for i in mnIdxs:\n",
    "#     plt.plot(R[i])\n",
    "ax = axs[2]\n",
    "active_neurons = jnp.where((jnp.sum(results[0,0],axis=-1) > 0))[0]\n",
    "ax.plot(R[active_neurons].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stim Adjustment Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_with_stim_adjustment(self,maxIters=10,clampedNeurons=[],clampedRates=None,nActiveUpper=500,nActiveLower=5,nHighFrUpper=100):\n",
    "    nextHighest = None\n",
    "    nextLowest = None\n",
    "\n",
    "    for i in range(maxIters):\n",
    "        self.run(clampedNeurons=clampedNeurons,clampedRates=clampedRates)\n",
    "        R = self.R\n",
    "\n",
    "        nActive = sum(np.sum(R,1)>0)\n",
    "        nHighFr = sum(np.max(R,1)>100)\n",
    "\n",
    "        currInputs = self.inputs.copy()\n",
    "\n",
    "        print(f\"Run {i}\")\n",
    "        print(f\"max stimI = {np.max(currInputs)}\")\n",
    "        print(f\"nActive: {nActive}\")\n",
    "        print(f\"nHighFr: {nHighFr}\")\n",
    "\n",
    "        if (nActive > nActiveUpper) or (nHighFr > nHighFrUpper): # too strong\n",
    "            if nextLowest is None:\n",
    "                newInputs = currInputs/2\n",
    "            else:\n",
    "                newInputs = (currInputs+nextLowest)/2\n",
    "            nextHighest = currInputs\n",
    "        elif (nActive < nActiveLower): # too weak\n",
    "            if nextHighest is None:\n",
    "                newInputs = currInputs*2\n",
    "            else:\n",
    "                newInputs = (currInputs+nextHighest)/2\n",
    "            nextLowest = currInputs\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        self.set_input(newInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note: The run_with_stim_adjustment function cannot be easily JIT-compiled\n",
    "# because it involves loops with data-dependent control flow and side effects.\n",
    "# Here's a restructured version that separates the JIT-able parts:\n",
    "\n",
    "@jit\n",
    "def compute_activity_metrics(R):\n",
    "    \"\"\"JIT-compatible function to compute activity metrics.\"\"\"\n",
    "    n_active = jnp.sum(jnp.sum(R, axis=1) > 0)\n",
    "    n_high_fr = jnp.sum(jnp.max(R, axis=1) > 100)\n",
    "    return n_active, n_high_fr\n",
    "\n",
    "@jit\n",
    "def update_inputs_binary_search(curr_inputs, next_lowest, next_highest, \n",
    "                               n_active, n_high_fr, n_active_upper, \n",
    "                               n_active_lower, n_high_fr_upper):\n",
    "    \"\"\"JIT-compatible input update logic.\"\"\"\n",
    "    \n",
    "    # Determine if stimulation is too strong\n",
    "    too_strong = (n_active > n_active_upper) | (n_high_fr > n_high_fr_upper)\n",
    "    too_weak = n_active < n_active_lower\n",
    "    \n",
    "    # Update inputs based on binary search logic\n",
    "    def update_for_too_strong():\n",
    "        new_inputs = jnp.where(\n",
    "            next_lowest is None,\n",
    "            curr_inputs / 2,\n",
    "            (curr_inputs + next_lowest) / 2\n",
    "        )\n",
    "        new_next_highest = curr_inputs\n",
    "        return new_inputs, next_lowest, new_next_highest\n",
    "    \n",
    "    def update_for_too_weak():\n",
    "        new_inputs = jnp.where(\n",
    "            next_highest is None,\n",
    "            curr_inputs * 2,\n",
    "            (curr_inputs + next_highest) / 2\n",
    "        )\n",
    "        new_next_lowest = curr_inputs\n",
    "        return new_inputs, new_next_lowest, next_highest\n",
    "    \n",
    "    def no_update():\n",
    "        return curr_inputs, next_lowest, next_highest\n",
    "    \n",
    "    # Apply updates conditionally\n",
    "    new_inputs, new_next_lowest, new_next_highest = jax.lax.cond(\n",
    "        too_strong,\n",
    "        update_for_too_strong,\n",
    "        lambda: jax.lax.cond(\n",
    "            too_weak,\n",
    "            update_for_too_weak,\n",
    "            no_update\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    converged = ~too_strong & ~too_weak\n",
    "    \n",
    "    return new_inputs, new_next_lowest, new_next_highest, converged\n",
    "\n",
    "# Example usage:\n",
    "def run_with_stim_adjustment_jax(simulation_runner, max_iters=10, \n",
    "                                clamped_neurons=None, clamped_rates=None,\n",
    "                                n_active_upper=500, n_active_lower=5, \n",
    "                                n_high_fr_upper=100):\n",
    "    \"\"\"\n",
    "    JAX-compatible version of run_with_stim_adjustment.\n",
    "    Note: This requires the simulation_runner to be compatible with JAX.\n",
    "    \"\"\"\n",
    "    next_highest = None\n",
    "    next_lowest = None\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        # Run simulation (this part depends on your simulation framework)\n",
    "        R = simulation_runner.run(clamped_neurons=clamped_neurons, \n",
    "                                 clamped_rates=clamped_rates)\n",
    "        \n",
    "        # Compute metrics (JIT-compiled)\n",
    "        n_active, n_high_fr = compute_activity_metrics(R)\n",
    "        curr_inputs = simulation_runner.get_inputs()\n",
    "        \n",
    "        print(f\"Run {i}\")\n",
    "        print(f\"max stimI = {jnp.max(curr_inputs)}\")\n",
    "        print(f\"nActive: {n_active}\")\n",
    "        print(f\"nHighFr: {n_high_fr}\")\n",
    "        \n",
    "        # Update inputs (JIT-compiled)\n",
    "        new_inputs, next_lowest, next_highest, converged = update_inputs_binary_search(\n",
    "            curr_inputs, next_lowest, next_highest, n_active, n_high_fr,\n",
    "            n_active_upper, n_active_lower, n_high_fr_upper\n",
    "        )\n",
    "        \n",
    "        if converged:\n",
    "            break\n",
    "            \n",
    "        simulation_runner.set_input(new_inputs)\n",
    "\n",
    "# Additional utility functions for JAX compatibility:\n",
    "\n",
    "@jit\n",
    "def safe_divide(x, y, default=0.0):\n",
    "    \"\"\"Safe division that handles division by zero.\"\"\"\n",
    "    return jnp.where(y == 0, default, x / y)\n",
    "\n",
    "@jit\n",
    "def safe_max(x, default=0.0):\n",
    "    \"\"\"Safe max that handles empty arrays.\"\"\"\n",
    "    return jnp.where(len(x) == 0, default, jnp.max(x))\n",
    "\n",
    "@jit\n",
    "def safe_min(x, default=0.0):\n",
    "    \"\"\"Safe min that handles empty arrays.\"\"\"\n",
    "    return jnp.where(len(x) == 0, default, jnp.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnc-closedloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
